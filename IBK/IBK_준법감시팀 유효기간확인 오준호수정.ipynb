{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65eea3ce",
   "metadata": {},
   "source": [
    "# IBK 준법감시팀 유효기간 확인 도구\n",
    "\n",
    "## 주요 기능 상세 설명\n",
    "\n",
    "### 1. 다양한 문서 형식 지원\n",
    "다음 파일 형식을 자동으로 인식하고 처리합니다:\n",
    "- **문서 파일**: DOC, DOCX (Microsoft Word)\n",
    "- **스프레드시트**: XLS, XLSX (Microsoft Excel)\n",
    "- **프레젠테이션**: PPT, PPTX (Microsoft PowerPoint)\n",
    "- **한글 문서**: HWP (한글과컴퓨터 한글)\n",
    "- **PDF 문서**: PDF\n",
    "- **텍스트 파일**: TXT, CSV\n",
    "\n",
    "각 파일 형식에 맞는 라이브러리(python-docx, openpyxl, python-pptx, olefile, PyPDF2 등)를 사용하여 텍스트를 추출합니다.\n",
    "\n",
    "### 2. 정교한 준법감시 정보 추출\n",
    "\n",
    "#### 2.1. 파일명 기반 추출\n",
    "파일명에서 준법감시 관련 정보를 추출하는 패턴:\n",
    "- `제2024-4806호(2024.08.21) 유효기간(2025.08.20).hwp` 형식\n",
    "- `준법감시-2024-123_유효기간_20250820.docx` 형식\n",
    "- `심의필-2024-456_만료일_2025년08월20일.pptx` 형식\n",
    "\n",
    "#### 2.2. 문서 내용 기반 추출\n",
    "문서 내용에서 추출할 수 있는 패턴:\n",
    "- 준법감시필 번호: `준법감시-2024-123`, `제2024-4806호`, `심의필-2024-456`\n",
    "- 유효기간 표현: `유효기간: 2025.08.20`, `2025년 8월 20일까지 유효`, `만료일: 2025-08-20`\n",
    "\n",
    "### 3. 단계적 분석 프로세스\n",
    "\n",
    "#### 3.1. 실제 구현된 분석 과정\n",
    "1. **파일 수집**: 파일명에 키워드가 포함된 문서 파일 식별\n",
    "2. **파일명 분석**: 파일명에서 유효기간 및 준법감시필 번호 추출\n",
    "3. **문서 내용 분석**: 파일 내용에서 정규식 패턴 매칭을 통한 정보 추출\n",
    "4. **결과 통합**: 파일명과 내용에서 추출한 정보 통합 및 우선순위 적용\n",
    "\n",
    "#### 3.2. N-gram 기반 텍스트 분석\n",
    "- 코드에서는 `AIEnhancedComplianceExtractor` 클래스에서 단순화된 N-gram 분석 구현\n",
    "- 2-gram, 3-gram, 4-gram을 사용하여 텍스트의 관련성 점수 계산\n",
    "- 설명된 완전한 자카드 유사도 계산은 `EnhancedTextComparison` 클래스에 구현되어 있으나, 기본 파이프라인에서는 제한적으로 활용됨\n",
    "\n",
    "### 4. 성능 최적화 기법\n",
    "\n",
    "#### 4.1. 병렬 처리\n",
    "- `ThreadPoolExecutor`를 사용한 다중 스레드 병렬 처리\n",
    "- 파일 검색 및 분석 단계에서 병렬화 적용\n",
    "- 배치 처리 방식으로 메모리 사용량 관리\n",
    "\n",
    "#### 4.2. 선택적 문서 처리\n",
    "- 우선순위 파일 먼저 처리 (키워드 기반)\n",
    "- 대용량 파일(20MB 초과) 분석 생략 옵션\n",
    "- 배치 단위 처리로 자원 관리\n",
    "\n",
    "#### 4.3. 청크 단위 처리\n",
    "- 대용량 문서의 경우 `create_semantic_chunks()` 함수를 통해 청크로 분할 처리\n",
    "- 관련성 높은 섹션 선별적 분석으로 효율성 향상\n",
    "- `score_chunks_by_relevance()` 함수로 관련성 높은 청크 선별\n",
    "\n",
    "### 5. 유효기간 상태 분석 로직\n",
    "\n",
    "#### 5.1. 상태 분류 체계\n",
    "- **만료됨**: 유효기간이 현재 날짜보다 이전인 문서\n",
    "- **30일 이내 만료**: 유효기간이 현재로부터 30일 이내인 문서\n",
    "- **유효함**: 유효기간이 현재로부터 30일 이상 남은 문서 \n",
    "- **상태 불명**: 유효기간을 추출할 수 없는 문서\n",
    "\n",
    "#### 5.2. 정보 신뢰도\n",
    "- 파일명에서 추출한 정보를 우선적으로 활용\n",
    "- 파일 내용에서 발견된 정보는 보조적으로 활용\n",
    "- 두 정보가 일치할 경우 신뢰도 향상\n",
    "\n",
    "### 6. 유사 문서 기능\n",
    "\n",
    "#### 6.1. 제한적 유사도 분석\n",
    "- `EnhancedTextComparison` 클래스에 유사도 계산 알고리즘 구현\n",
    "- N-gram 및 해시 기반 비교 방식 지원\n",
    "- 메인 파이프라인에서는 선택적으로 활성화됨\n",
    "\n",
    "#### 6.2. 유사도 기반 기능\n",
    "- `SimilarityBasedInfoPropagation` 클래스를 통해 유사 문서 간 정보 전파 구현\n",
    "- 유사도가 높은 문서 관계 식별\n",
    "- 유효기간 정보가 없는 문서에 유사 문서의 정보 전파 가능\n",
    "\n",
    "### 7. 오류 처리 및 예외 상황 관리\n",
    "\n",
    "#### 7.1. 오류 날짜 필터링\n",
    "- 알려진 오류 날짜 목록을 통한 필터링 (`ERROR_DATES` 변수)\n",
    "- 2020-12-31, 2024-11-30 등 오류로 추출되는 날짜 자동 제외\n",
    "\n",
    "#### 7.2. 유효성 검증\n",
    "- 날짜 형식 및 범위 유효성 검증 (2000~2100년, 1~12월, 1~31일)\n",
    "- 파일명과 내용에서 추출한 정보의 신뢰도 비교\n",
    "- 정규식 매칭 오류에 대한 예외 처리\n",
    "\n",
    "#### 7.3. 파일 처리 오류 대응\n",
    "- 파일 읽기 오류 발생 시 해당 파일 스킵\n",
    "- 대용량 파일 처리 중 메모리 오류 방지를 위한 한계 설정\n",
    "- 배치 처리 방식으로 중간 결과 주기적 저장\n",
    "\n",
    "### 8. 결과 시각화 및 보고서 생성\n",
    "\n",
    "#### 8.1. Excel 보고서 자동 포맷팅\n",
    "- 열 너비 자동 조정\n",
    "- 헤더 행 스타일 설정 (굵은 글꼴, 배경색)\n",
    "- 상태별 조건부 서식 적용:\n",
    "  - 만료됨: 밝은 빨강 (#FFC7CE)\n",
    "  - 30일 이내 만료: 밝은 노랑 (#FFEB9C)\n",
    "  - 유효함: 밝은 녹색 (#C6EFCE)\n",
    "  - 상태 불명: 회색 (#DDDDDD)\n",
    "\n",
    "#### 8.2. 분석 통계 제공\n",
    "- 상태별 문서 수 및 비율\n",
    "- 정보 출처 통계 (파일명에서만 발견, 파일 내용에서만 발견, 양쪽 모두, 어디에서도 없음)\n",
    "- 오류 날짜 포함 문서 목록\n",
    "\n",
    "### 9. 확장 가능성\n",
    "\n",
    "#### 9.1. AI 기반 분석 선택적 활성화\n",
    "- `AIEnhancedComplianceExtractor` 클래스에 API 연동 구조 마련\n",
    "- 실제 구현에서는 API 호출 비활성화 (주석 처리)\n",
    "- 필요 시 외부 AI API 연동 가능한 구조\n",
    "\n",
    "#### 9.2. 배치 처리 및 자동화\n",
    "- 전체 프로세스 배치 처리 지원\n",
    "- 분석 중간 결과 저장 기능\n",
    "- Windows 작업 스케줄러나 Linux cron으로 연동 가능한 구조\n",
    "\n",
    "## 코드 구현 상세 설명\n",
    "\n",
    "### 다양한 문서 형식 지원 (셀 #3)\n",
    "\n",
    "```python\n",
    "def read_file_content(file_path):\n",
    "    \"\"\"다양한 파일 형식에서 텍스트 추출\"\"\"\n",
    "    content = \"\"\n",
    "    ext = file_path.suffix.lower()\n",
    "    \n",
    "    try:\n",
    "        # 텍스트 파일\n",
    "        if ext == '.txt':\n",
    "            # UTF-8 및 CP949 인코딩 처리\n",
    "            # ...\n",
    "        \n",
    "        # Word 문서\n",
    "        elif ext == '.docx':\n",
    "            import docx\n",
    "            # 문단 추출\n",
    "            # ...\n",
    "        \n",
    "        # Excel 파일\n",
    "        elif ext in ['.xlsx', '.xls']:\n",
    "            # 시트 및 셀 데이터 처리\n",
    "            # ...\n",
    "        \n",
    "        # PowerPoint 파일\n",
    "        elif ext == '.pptx':\n",
    "            # 슬라이드 텍스트 추출\n",
    "            # ...\n",
    "        \n",
    "        # HWP 파일\n",
    "        elif ext == '.hwp':\n",
    "            # olefile로 미리보기 텍스트 추출\n",
    "            # ...\n",
    "                \n",
    "        # PDF 파일\n",
    "        elif ext == '.pdf':\n",
    "            # 페이지별 텍스트 추출\n",
    "            # ...\n",
    "\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        log_debug(f\"파일 {file_path.name} 읽기 오류: {str(e)}\")\n",
    "        return \"\"\n",
    "```\n",
    "\n",
    "### 준법감시 정보 추출 (셀 #2 및 셀 #4)\n",
    "\n",
    "파일명에서 유효기간 추출:\n",
    "\n",
    "```python\n",
    "def extract_expiry_from_filename_improved(filename):\n",
    "    \"\"\"파일명에서 유효기간 정보를 추출 - 개선된 버전\"\"\"\n",
    "    # 다양한 정규식 패턴으로 유효기간 추출\n",
    "    ibk_patterns = [\n",
    "        r'유효기간\\(([0-9]{4})[\\\\.\\\\-]([0-9]{2})[\\\\.\\\\-]([0-9]{2})\\)',  # 유효기간(2025.08.20)\n",
    "        r'유효기간\\(([0-9]{4})([0-9]{2})([0-9]{2})\\)',  # 유효기간(20250820)\n",
    "        # 여러 패턴 등록...\n",
    "    ]\n",
    "    \n",
    "    # 패턴 검색 및 날짜 검증\n",
    "    # ...\n",
    "```\n",
    "\n",
    "문서 내용에서 정보 추출:\n",
    "\n",
    "```python\n",
    "def extract_with_regex(self, text):\n",
    "    \"\"\"정규식으로 준법감시 정보 추출\"\"\"\n",
    "    # 준법감시필 번호 추출 패턴\n",
    "    compliance_patterns = [\n",
    "        r'제(\\d{4})-(\\d+)호',  # 제2024-4806호\n",
    "        # ...\n",
    "    ]\n",
    "    \n",
    "    # 유효기간 추출 패턴\n",
    "    expiry_patterns = [\n",
    "        r'유효기간[^0-9]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?',  # 유효기간: 2025.08.20\n",
    "        # ...\n",
    "    ]\n",
    "    # ...\n",
    "```\n",
    "\n",
    "### 청크 단위 처리 (셀 #4)\n",
    "\n",
    "```python\n",
    "def create_semantic_chunks(self, text):\n",
    "    \"\"\"의미론적 청크 생성 - 문장/단락 단위 분할\"\"\"\n",
    "    # 단락 기반 분할\n",
    "    paragraphs = re.split(r'\\n\\s*\\n', text)\n",
    "    \n",
    "    # 청크 생성 로직\n",
    "    # ...\n",
    "    \n",
    "    # 청크 중첩 처리로 맥락 유지\n",
    "    # ...\n",
    "```\n",
    "\n",
    "### 유효기간 분석 (셀 #7)\n",
    "\n",
    "```python\n",
    "class ExpiryAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.today = datetime.now()\n",
    "        \n",
    "    def predict_expiry_date(self, dates, approval_numbers, validity_sentences):\n",
    "        \"\"\"다양한 정보를 종합하여 유효기간 예측\"\"\"\n",
    "        potential_expiry_dates = []\n",
    "        \n",
    "        # 1. 명시적 유효기간 또는 만료일이 있는 경우\n",
    "        # 2. 유효기간 문장에 포함된 날짜 활용\n",
    "        # 3. 준법감시/심의필 번호 기준 추정\n",
    "        # 4. 일반 날짜 중 미래 날짜 고려\n",
    "        # ...\n",
    "```\n",
    "\n",
    "### 유사 문서 분석 (셀 #6)\n",
    "\n",
    "```python\n",
    "class EnhancedTextComparison:\n",
    "    def __init__(self, min_ngram_size=3, max_ngram_size=5, threshold=0.6):\n",
    "        self.min_ngram_size = min_ngram_size\n",
    "        self.max_ngram_size = max_ngram_size\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def calculate_similarity(self, text1, text2):\n",
    "        \"\"\"두 텍스트 간 유사도 계산 (지문 기반)\"\"\"\n",
    "        fingerprints1 = self._create_fingerprints(text1)\n",
    "        fingerprints2 = self._create_fingerprints(text2)\n",
    "        \n",
    "        return self._calculate_jaccard_similarity(fingerprints1, fingerprints2)\n",
    "    \n",
    "    # ...\n",
    "```\n",
    "\n",
    "### Excel 보고서 생성 (셀 #5)\n",
    "\n",
    "```python\n",
    "def save_formatted_excel(df, excel_file):\n",
    "    \"\"\"결과를 서식이 적용된 Excel로 저장\"\"\"\n",
    "    # ...\n",
    "    # 열 너비 자동 조정\n",
    "    for i, column in enumerate(df.columns):\n",
    "        # 열 너비 계산 로직\n",
    "        # ...\n",
    "        \n",
    "    # 헤더 행 스타일 설정\n",
    "    header_font = Font(bold=True)\n",
    "    header_fill = PatternFill(start_color='E6E6E6', end_color='E6E6E6', fill_type='solid')\n",
    "    \n",
    "    # 데이터 행에 조건부 서식 설정\n",
    "    status_colors = {\n",
    "        '만료됨': 'FFC7CE',  # 밝은 빨강\n",
    "        '30일 이내 만료': 'FFEB9C',  # 밝은 노랑\n",
    "        '유효함': 'C6EFCE',  # 밝은 녹색\n",
    "        '상태 불명': 'DDDDDD'  # 회색\n",
    "    }\n",
    "    # ...\n",
    "```\n",
    "\n",
    "### 배치 처리 (셀 #11)\n",
    "\n",
    "```python\n",
    "def process_documents_in_batches(file_paths, batch_size=50, max_workers=8):\n",
    "    \"\"\"파일 배치 처리 및 병렬화 - 메모리 효율성 개선\"\"\"\n",
    "    # 배치로 나누기\n",
    "    batches = [file_paths[i:i+batch_size] for i in range(0, len(file_paths), batch_size)]\n",
    "    \n",
    "    # 배치별 병렬 처리\n",
    "    for batch_idx, batch in enumerate(batches):\n",
    "        # ThreadPoolExecutor로 병렬 처리\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # ...\n",
    "```\n",
    "\n",
    "## 설치 및 환경 설정 상세 가이드\n",
    "\n",
    "### 1. 필수 패키지 설치\n",
    "```bash\n",
    "pip install pandas numpy matplotlib seaborn scikit-learn nltk tqdm\n",
    "pip install openpyxl python-docx olefile python-pptx PyPDF2\n",
    "```\n",
    "\n",
    "### 2. 추가 NLTK 리소스 다운로드\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)  # quiet=True 파라미터 추가로 다운로드 출력 최소화\n",
    "```\n",
    "\n",
    "### 3. 경로 설정\n",
    "코드 내에서 `BASE_PATH` 변수를 분석할 문서가 있는 디렉토리로 설정합니다:\n",
    "```python\n",
    "# 사용자 환경에 맞게 수정 필요\n",
    "BASE_PATH = Path(r\"C:\\Users\\your_username\\Desktop\\IBK_Documents\")\n",
    "```\n",
    "\n",
    "### 4. 환경 확인 기능 활용\n",
    "코드에 포함된 `prepare_environment()` 함수를 사용하여 필요한 라이브러리가 올바르게 설치되었는지 확인할 수 있습니다:\n",
    "\n",
    "```python\n",
    "# 환경 준비 확인\n",
    "if prepare_environment():\n",
    "    print(\"모든 필수 라이브러리가 설치되어 있습니다.\")\n",
    "else:\n",
    "    print(\"일부 라이브러리가 설치되지 않았습니다. 위 안내에 따라 설치해주세요.\")\n",
    "```\n",
    "\n",
    "### 5. 추가 패키지 요구사항\n",
    "코드 실행을 위해 다음 openpyxl 스타일 관련 모듈이 필요합니다:\n",
    "\n",
    "```python\n",
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "from openpyxl.formatting.rule import CellIsRule\n",
    "from openpyxl.utils import get_column_letter\n",
    "```\n",
    "\n",
    "### 6. 병렬 처리 최적화\n",
    "대량의 파일을 처리하는 경우, 코드에서 사용되는 병렬 처리 설정을 조정할 수 있습니다:\n",
    "\n",
    "```python\n",
    "# 병렬 처리 스레드 수 조정 (CPU 코어 수에 따라 최적화)\n",
    "max_workers = min(os.cpu_count() or 4, 8)  # 최대 8개 워커\n",
    "```\n",
    "\n",
    "### 7. 메모리 관리\n",
    "대용량 파일 처리 시 메모리 사용량을 관리하기 위한 설정:\n",
    "\n",
    "```python\n",
    "# 대용량 파일 처리 크기 제한 설정\n",
    "batch_size = 200  # 한 번에 처리할 파일 수\n",
    "max_text_size = 100000  # 파일당 최대 처리 텍스트 크기\n",
    "```\n",
    "\n",
    "## 코드 실행 및 커스터마이징 가이드\n",
    "\n",
    "### 1. 전체 분석 실행\n",
    "노트북의 마지막 셀을 실행하면 모든 분석이 자동으로 진행됩니다:\n",
    "```python\n",
    "# 계층적 하이브리드 방식 적용 - 준법감시필 번호 및 유효기간 추출\n",
    "try:\n",
    "    # 라이브러리 임포트\n",
    "    # 파일 분석 및 결과 처리\n",
    "    # 보고서 생성 및 통계 출력\n",
    "    # ...\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n",
    "    print(traceback.format_exc())\n",
    "```\n",
    "\n",
    "### 2. 키워드 및 패턴 커스터마이징\n",
    "준법감시 관련 키워드와 패턴을 수정하려면 다음 부분을 변경합니다:\n",
    "```python\n",
    "# 키워드 설정\n",
    "self.compliance_keywords = [\n",
    "    '준법감시', '준법감시인', '준법감사', '심의필', '제호', \n",
    "    '승인', '결재', '법규', '컴플라이언스'\n",
    "    # 여기에 추가 키워드 입력\n",
    "]\n",
    "\n",
    "self.validity_keywords = [\n",
    "    '유효기간', '만료일', '유효', '만료', '기간', \n",
    "    '까지', '효력', '사용기한'\n",
    "    # 여기에 추가 키워드 입력\n",
    "]\n",
    "```\n",
    "\n",
    "### 3. 정규식 패턴 수정\n",
    "파일명이나 문서 내용에서 유효기간을 추출하는 패턴을 수정하려면 다음 부분을 수정합니다:\n",
    "```python\n",
    "expiry_patterns = [\n",
    "    r'유효기간\\((\\d{4})\\.(\\d{2})\\.(\\d{2})\\)',  # 유효기간(2025.08.20)\n",
    "    # 여기에 추가 패턴 입력\n",
    "]\n",
    "```\n",
    "\n",
    "### 4. 오류 날짜 추가\n",
    "특정 날짜가 오류로 판단되면 `ERROR_DATES` 목록에 추가합니다:\n",
    "```python\n",
    "ERROR_DATES = ['2024-11-30', '2020-12-31', '추가할_오류_날짜']\n",
    "```\n",
    "\n",
    "### 5. 디버깅 모드 설정\n",
    "디버깅 정보를 상세하게 기록하려면 다음 설정을 활용합니다:\n",
    "```python\n",
    "# 디버깅 모드 활성화\n",
    "DEBUG_MODE = True\n",
    "DEBUG_FILE = \"debug_log.txt\"\n",
    "\n",
    "def log_debug(message):\n",
    "    if DEBUG_MODE:\n",
    "        with open(DEBUG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}\\n\")\n",
    "```\n",
    "\n",
    "## 결과 해석 상세 가이드\n",
    "\n",
    "### 1. Excel 보고서 구조\n",
    "생성된 Excel 파일은 다음 열들을 포함합니다:\n",
    "\n",
    "| 열 이름 | 설명 |\n",
    "|--------|------|\n",
    "| 파일명 | 분석된 문서 파일명 |\n",
    "| 상태 | 유효기간 기준 문서 상태 (만료됨, 30일 이내 만료, 유효함, 상태 불명) |\n",
    "| 만료일 | 추출된 유효기간 날짜 (YYYY-MM-DD 형식) |\n",
    "| 남은 일수 | 현재 날짜 기준 만료일까지 남은 일수 |\n",
    "| 파일명_준법감시필 | 파일명에서 추출한 준법감시필 번호 |\n",
    "| 파일명_유효기간 | 파일명에서 추출한 유효기간 날짜 |\n",
    "| 파일명_유효기간_상태 | 파일명 기준 유효기간 상태 |\n",
    "| 파일명_남은일수 | 파일명 기준 남은 일수 |\n",
    "| 파일내_준법감시필_번호 | 문서 내용에서 추출한 준법감시필 번호 |\n",
    "| 파일내_유효기간_날짜 | 문서 내용에서 추출한 유효기간 날짜 |\n",
    "| 파일내_유효기간_상태 | 문서 내용 기준 유효기간 상태 |\n",
    "| 파일내_남은일수 | 문서 내용 기준 남은 일수 |\n",
    "| 파일경로 | 파일이 위치한 경로 |\n",
    "\n",
    "### 2. 분석 통계 해석\n",
    "프로그램 실행이 완료되면 다음과 같은 통계 정보가 표시됩니다:\n",
    "\n",
    "```\n",
    "=== 분석 결과 통계 ===\n",
    "- 만료됨: 267개\n",
    "- 30일 이내 만료: 0개\n",
    "- 유효함: 392개\n",
    "- 상태 불명: 0개\n",
    "- 총 파일 수: 659개\n",
    "\n",
    "=== 정보 출처 통계 ===\n",
    "- 파일명에서만 발견: 583개 (88.5%)\n",
    "- 파일 내용에서만 발견: 0개 (0.0%)\n",
    "- 파일명과 내용 모두에서 발견: 76개 (11.5%)\n",
    "- 어디에서도 발견되지 않음: 0개 (0.0%)\n",
    "```\n",
    "\n",
    "이 통계는 분석된 문서의 전반적인 상태와 정보 출처를 보여줍니다.\n",
    "\n",
    "## 문제 해결 및 디버깅\n",
    "\n",
    "### 1. 디버그 로그 활용\n",
    "코드에는 상세한 디버그 로그 기능이 포함되어 있습니다:\n",
    "```python\n",
    "DEBUG_MODE = True\n",
    "DEBUG_FILE = \"debug_log.txt\"\n",
    "\n",
    "def log_debug(message):\n",
    "    if DEBUG_MODE:\n",
    "        with open(DEBUG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}\\n\")\n",
    "```\n",
    "\n",
    "이 로그 파일을 확인하여 파일 처리 과정과, 추출 결과 등을 자세히 확인할 수 있습니다.\n",
    "\n",
    "### 2. 특정 파일 분석 오류\n",
    "특정 파일에서 오류가 발생하면 디버그 로그에서 해당 파일 처리 과정을 확인할 수 있습니다. 파일 인덱스 정보도 함께 저장되므로 문제가 발생한 파일을 쉽게 식별할 수 있습니다.\n",
    "\n",
    "### 3. 메모리 사용량 최적화\n",
    "대용량 파일이나 많은 수의 파일 처리 시 메모리 부족 오류가 발생할 수 있습니다. 이런 경우 `batch_size` 변수를 줄이거나, `max_normal_files` 값을 조정하여 처리할 파일 수를 제한할 수 있습니다.\n",
    "\n",
    "이 도구를 통해 IBK 준법감시 문서의 유효기간을 효율적으로 관리하고, 만료되었거나 만료 예정인 문서를 사전에 식별하여 규제 준수 및 리스크 관리를 강화할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a63569",
   "metadata": {},
   "source": [
    "1. 필요한 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import hashlib\n",
    "import concurrent.futures\n",
    "import traceback\n",
    "import json\n",
    "import gc\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "from openpyxl.formatting.rule import CellIsRule\n",
    "from openpyxl.utils import get_column_letter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# API 키 가져오기\n",
    "api_key = os.getenv(\"api_key\")\n",
    "# 경고 메시지 설정\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLTK 필요 패키지 다운로드\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# 기본 경로 설정\n",
    "BASE_PATH = Path(r\"C:\\Users\\markcloud\\Desktop\\오준호\\IBK\")\n",
    "\n",
    "# 디버깅 모드 활성화\n",
    "DEBUG_MODE = True\n",
    "DEBUG_FILE = \"debug_log.txt\"\n",
    "\n",
    "# 오류 날짜 목록 - 이 날짜들은 검사에서 제외됩니다\n",
    "ERROR_DATES = ['2024-11-30', '2020-12-31']\n",
    "\n",
    "# 디버깅 로그 함수\n",
    "def log_debug(message):\n",
    "    if DEBUG_MODE:\n",
    "        with open(DEBUG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}\\n\")\n",
    "            \n",
    "# 디버그 로그 파일 초기화\n",
    "with open(DEBUG_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"=== 디버그 로그 시작: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba6e184",
   "metadata": {},
   "source": [
    "#2. 파일 이름 분석 및 사전 필터링 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_keywords_in_name(filename):\n",
    "    \"\"\"파일명에 준법감시 관련 키워드가 있는지 확인\"\"\"\n",
    "    keywords = ['유효기간', '준법감시', '심의필', '만료일', '법무', '결재', '승인']\n",
    "    return any(keyword in filename for keyword in keywords)\n",
    "\n",
    "def extract_expiry_from_filename_improved(filename):\n",
    "    \"\"\"파일명에서 유효기간 정보를 추출 - 개선된 버전\"\"\"\n",
    "    import re\n",
    "    from datetime import datetime\n",
    "    \n",
    "    log_debug(f\"파일명 분석 시작: {filename}\")\n",
    "    \n",
    "    # IBK 파일명 패턴에 맞는 정규식\n",
    "    ibk_patterns = [\n",
    "        r'유효기간\\(([0-9]{4})[\\.\\\\-]([0-9]{2})[\\.\\\\-]([0-9]{2})\\)',  # 유효기간(2025.08.20)\n",
    "        r'유효기간\\(([0-9]{4})([0-9]{2})([0-9]{2})\\)',  # 유효기간(20250820)\n",
    "        r'유효기간\\(([0-9]{4})[-/.]([0-9]{1,2})[-/.]([0-9]{1,2})\\)',  # 유효기간(2025-08-20)\n",
    "        r'제[0-9]{4}-[0-9]+호\\([^)]+\\)\\s*유효기간\\((\\d{4})[./-](\\d{1,2})[./-](\\d{1,2})\\)',  # 제2024-4806호(날짜) 유효기간(2025.08.20)\n",
    "        r'유효기간[_\\s]([0-9]{4})[./-]([0-9]{1,2})[./-]([0-9]{1,2})',  # 유효기간_2025.08.20\n",
    "        r'([0-9]{4})[./-]([0-9]{1,2})[./-]([0-9]{1,2})[_\\s]유효기간',  # 2025.08.20_유효기간\n",
    "        r'만료일[_\\s]([0-9]{4})[./-]([0-9]{1,2})[./-]([0-9]{1,2})'   # 만료일_2025.08.20\n",
    "    ]\n",
    "    \n",
    "    # 패턴 검색\n",
    "    for i, pattern in enumerate(ibk_patterns):\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            try:\n",
    "                # 패턴에 따라 그룹 인덱스 조정\n",
    "                if '제' in pattern and len(match.groups()) >= 3:  # 제2024-4806호 형식\n",
    "                    year, month, day = map(int, match.groups()[-3:])\n",
    "                else:  # 일반 형식\n",
    "                    year, month, day = map(int, match.groups())\n",
    "                    \n",
    "                if 2000 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                    expiry_date = datetime(year, month, day)\n",
    "                    log_debug(f\"유효기간 추출 성공: {expiry_date.strftime('%Y-%m-%d')} (패턴 {i+1})\")\n",
    "                    \n",
    "                    # 오류 날짜 필터링\n",
    "                    date_str = expiry_date.strftime('%Y-%m-%d')\n",
    "                    if date_str in ERROR_DATES:\n",
    "                        log_debug(f\"오류 날짜 감지: {date_str}\")\n",
    "                        continue\n",
    "                        \n",
    "                    return expiry_date\n",
    "            except (ValueError, IndexError) as e:\n",
    "                log_debug(f\"패턴 {i+1} 매칭 오류: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # 확장 패턴 시도 (날짜 형식이 다른 경우)\n",
    "    extended_patterns = [\n",
    "        r'유효기간[:\\s]*([12]\\d{3})[년\\.\\-]?([01]?\\d)[월\\.\\-]?([0-3]?\\d)[일]?',  # 유효기간: 2025년6월3일\n",
    "        r'([12]\\d{3})년?[^0-9]+([01]?\\d)월?[^0-9]+([0-3]?\\d)일?[^0-9]*유효',  # 2025년 6월 3일 유효\n",
    "        r'유효[^0-9]*([12]\\d{3})년?[^0-9]+([01]?\\d)월?[^0-9]+([0-3]?\\d)일?'   # 유효 2025년 6월 3일\n",
    "    ]\n",
    "    \n",
    "    for i, pattern in enumerate(extended_patterns):\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            try:\n",
    "                groups = match.groups()\n",
    "                log_debug(f\"확장 패턴 {i+1} 매치: {pattern} -> {groups}\")\n",
    "                \n",
    "                year, month, day = map(int, groups)\n",
    "                if 2000 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                    expiry_date = datetime(year, month, day)\n",
    "                    date_str = expiry_date.strftime('%Y-%m-%d')\n",
    "                    \n",
    "                    if date_str in ERROR_DATES:\n",
    "                        log_debug(f\"오류 날짜 감지: {date_str}\")\n",
    "                        continue\n",
    "                        \n",
    "                    log_debug(f\"확장 패턴으로 유효기간 추출 성공: {date_str}\")\n",
    "                    return expiry_date\n",
    "            except (ValueError, IndexError) as e:\n",
    "                log_debug(f\"확장 패턴 {i+1} 매칭 오류: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    log_debug(f\"파일명에서 유효기간 추출 실패: {filename}\")\n",
    "    return None\n",
    "\n",
    "def extract_info_from_filename(filename):\n",
    "    \"\"\"파일명에서 준법감시 정보 추출 (준법감시필 번호 + 유효기간)\"\"\"\n",
    "    # 유효기간 추출\n",
    "    expiry_date = extract_expiry_from_filename_improved(filename)\n",
    "    \n",
    "    # 준법감시필 번호 추출\n",
    "    compliance_number = extract_compliance_number(filename)\n",
    "    \n",
    "    # 유효기간 상태 계산\n",
    "    if expiry_date:\n",
    "        today = datetime.now().date()\n",
    "        expiry_date_obj = expiry_date.date()\n",
    "        days_to_expiry = (expiry_date_obj - today).days\n",
    "        \n",
    "        if days_to_expiry < 0:\n",
    "            status = '만료됨'\n",
    "        elif days_to_expiry <= 30:\n",
    "            status = '30일 이내 만료'\n",
    "        else:\n",
    "            status = '유효함'\n",
    "    else:\n",
    "        days_to_expiry = None\n",
    "        status = '상태 불명'\n",
    "    \n",
    "    return {\n",
    "        'filename': filename,\n",
    "        'expiry_date': expiry_date.strftime('%Y-%m-%d') if expiry_date else None,\n",
    "        'compliance_number': compliance_number,\n",
    "        'days_to_expiry': days_to_expiry,\n",
    "        'status': status,\n",
    "        'source': '파일명'\n",
    "    }\n",
    "\n",
    "def extract_compliance_number(filename):\n",
    "    \"\"\"파일명에서 준법감시필 번호 추출\"\"\"\n",
    "    log_debug(f\"준법감시필 번호 추출 시작: {filename}\")\n",
    "    \n",
    "    compliance_patterns = [\n",
    "        r'제(\\d{4})-(\\d+)호',  # 제2024-4806호\n",
    "        r'준법감시[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)',  # 준법감시-2024-123\n",
    "        r'심의필[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)',    # 심의필-2024-123\n",
    "        r'준법[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)'       # 준법-2024-123\n",
    "    ]\n",
    "    \n",
    "    for i, pattern in enumerate(compliance_patterns):\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            try:\n",
    "                year, number = match.groups()\n",
    "                \n",
    "                # 형식에 따라 준법감시필 번호 생성\n",
    "                if pattern.startswith(r'제'):\n",
    "                    compliance_number = f\"제{year}-{number}호\"\n",
    "                elif pattern.startswith(r'준법감시'):\n",
    "                    compliance_number = f\"준법감시-{year}-{number}\"\n",
    "                elif pattern.startswith(r'심의필'):\n",
    "                    compliance_number = f\"심의필-{year}-{number}\"\n",
    "                else:\n",
    "                    compliance_number = f\"준법-{year}-{number}\"\n",
    "                \n",
    "                log_debug(f\"준법감시필 번호 추출 성공: {compliance_number} (패턴 {i+1})\")\n",
    "                return compliance_number\n",
    "            except Exception as e:\n",
    "                log_debug(f\"준법감시필 번호 추출 오류: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    log_debug(f\"파일명에서 준법감시필 번호 추출 실패: {filename}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7c566",
   "metadata": {},
   "source": [
    "#3. 문서 로드 및 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf450e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_content(file_path):\n",
    "    \"\"\"다양한 파일 형식에서 텍스트 추출\"\"\"\n",
    "    content = \"\"\n",
    "    ext = file_path.suffix.lower()\n",
    "    \n",
    "    try:\n",
    "        # 텍스트 파일\n",
    "        if ext == '.txt':\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                    content = f.read(100000)  # 최대 10만자만 읽기\n",
    "            except:\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='cp949', errors='replace') as f:\n",
    "                        content = f.read(100000)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Word 문서\n",
    "        elif ext == '.docx':\n",
    "            try:\n",
    "                import docx\n",
    "                doc = docx.Document(file_path)\n",
    "                \n",
    "                # 모든 텍스트 추출 (단락, 테이블, 헤더/푸터)\n",
    "                all_text = []\n",
    "                \n",
    "                # 1. 단락 추출\n",
    "                for para in doc.paragraphs:\n",
    "                    if para.text.strip():\n",
    "                        all_text.append(para.text)\n",
    "                \n",
    "                # 2. 테이블 추출\n",
    "                for table in doc.tables:\n",
    "                    for row in table.rows:\n",
    "                        row_text = ' | '.join([cell.text.strip() for cell in row.cells if cell.text.strip()])\n",
    "                        if row_text:\n",
    "                            all_text.append(row_text)\n",
    "                \n",
    "                # 3. 헤더/푸터 추출 (가능한 경우)\n",
    "                try:\n",
    "                    for section in doc.sections:\n",
    "                        if section.header:\n",
    "                            for p in section.header.paragraphs:\n",
    "                                if p.text.strip():\n",
    "                                    all_text.append(p.text)\n",
    "                        if section.footer:\n",
    "                            for p in section.footer.paragraphs:\n",
    "                                if p.text.strip():\n",
    "                                    all_text.append(p.text)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                content = \"\\n\".join(all_text)\n",
    "                if len(all_text) > 0:\n",
    "                    log_debug(f\"DOCX 파일 {file_path.name}에서 {len(all_text)}개 텍스트 블록 추출됨\")\n",
    "            except Exception as e:\n",
    "                log_debug(f\"DOCX 처리 오류({file_path.name}): {str(e)}\")\n",
    "        \n",
    "        # Excel 파일\n",
    "        elif ext in ['.xlsx', '.xls']:\n",
    "            try:\n",
    "                xl = pd.ExcelFile(file_path, engine='openpyxl')\n",
    "                sheet_names = xl.sheet_names[:5]  # 최대 5개 시트만 처리\n",
    "                \n",
    "                all_text = []\n",
    "                for sheet_name in sheet_names:\n",
    "                    try:\n",
    "                        sheet_df = pd.read_excel(file_path, sheet_name=sheet_name, engine='openpyxl', nrows=1000)\n",
    "                        # 데이터프레임을 문자열로 변환할 때 좀 더 철저히 처리\n",
    "                        sheet_df = sheet_df.fillna('')  # NaN 값을 빈 문자열로 변환\n",
    "                        \n",
    "                        # 모든 데이터를 문자열화\n",
    "                        for col in sheet_df.columns:\n",
    "                            sheet_df[col] = sheet_df[col].astype(str)\n",
    "                            sheet_df[col] = sheet_df[col].str.strip()\n",
    "                        \n",
    "                        # 행별로 데이터 추출\n",
    "                        for _, row in sheet_df.iterrows():\n",
    "                            # 빈 값 제외하고 결합\n",
    "                            row_values = [val for val in row.values if val and val.strip()]\n",
    "                            if row_values:\n",
    "                                all_text.append(' | '.join(row_values))\n",
    "                    except Exception as sheet_e:\n",
    "                        log_debug(f\"Excel 시트 '{sheet_name}' 처리 오류: {str(sheet_e)}\")\n",
    "                        continue\n",
    "                \n",
    "                content = '\\n'.join(all_text)\n",
    "                if len(all_text) > 0:\n",
    "                    log_debug(f\"Excel 파일 {file_path.name}에서 {len(all_text)}개 행 추출됨\")\n",
    "            except Exception as e:\n",
    "                log_debug(f\"Excel 처리 오류({file_path.name}): {str(e)}\")\n",
    "                pass\n",
    "        \n",
    "        # PowerPoint 파일\n",
    "        elif ext == '.pptx':\n",
    "            try:\n",
    "                from pptx import Presentation\n",
    "                prs = Presentation(file_path)\n",
    "                slide_texts = []\n",
    "                \n",
    "                # 슬라이드별 처리\n",
    "                for i, slide in enumerate(prs.slides):\n",
    "                    # 슬라이드 번호 추가\n",
    "                    slide_texts.append(f\"---슬라이드 {i+1}---\")\n",
    "                    \n",
    "                    # 모든 도형에서 텍스트 추출\n",
    "                    for shape in slide.shapes:\n",
    "                        # 텍스트가 있는 도형\n",
    "                        if hasattr(shape, \"text\") and shape.text.strip():\n",
    "                            slide_texts.append(shape.text)\n",
    "                        \n",
    "                        # 테이블 처리\n",
    "                        if hasattr(shape, \"has_table\") and shape.has_table:\n",
    "                            for row in shape.table.rows:\n",
    "                                row_text = ' | '.join([cell.text.strip() for cell in row.cells if cell.text.strip()])\n",
    "                                if row_text:\n",
    "                                    slide_texts.append(row_text)\n",
    "                \n",
    "                content = \"\\n\".join(slide_texts)\n",
    "                if len(slide_texts) > 0:\n",
    "                    log_debug(f\"PPTX 파일 {file_path.name}에서 {len(slide_texts)}개 텍스트 블록 추출됨\")\n",
    "            except Exception as e:\n",
    "                log_debug(f\"PPTX 처리 오류({file_path.name}): {str(e)}\")\n",
    "        \n",
    "        # HWP 파일\n",
    "        elif ext == '.hwp':\n",
    "            try:\n",
    "                import olefile\n",
    "                if olefile.isOleFile(str(file_path)):\n",
    "                    hwp_content = []\n",
    "                    \n",
    "                    with olefile.OleFile(str(file_path)) as ole:\n",
    "                        # 스트림 목록 확인\n",
    "                        streams = ole.listdir()\n",
    "                        log_debug(f\"HWP 파일 {file_path.name} 스트림: {streams}\")\n",
    "                        \n",
    "                        # PrvText 스트림 처리 (미리보기 텍스트)\n",
    "                        if ole.exists('PrvText'):\n",
    "                            try:\n",
    "                                prv_text = ole.openstream('PrvText')\n",
    "                                prv_bytes = prv_text.read()\n",
    "                                prv_text.close()\n",
    "                                \n",
    "                                # 여러 인코딩 시도\n",
    "                                for encoding in ['utf-16-le', 'cp949', 'euc-kr']:\n",
    "                                    try:\n",
    "                                        decoded = prv_bytes.decode(encoding, errors='replace')\n",
    "                                        if decoded.strip():\n",
    "                                            hwp_content.append(decoded)\n",
    "                                            log_debug(f\"HWP 미리보기 추출 성공({encoding}): {len(decoded)}자\")\n",
    "                                            break\n",
    "                                    except:\n",
    "                                        continue\n",
    "                            except Exception as e:\n",
    "                                log_debug(f\"HWP 미리보기 추출 오류: {str(e)}\")\n",
    "                        \n",
    "                        # 문서 요약 정보 처리\n",
    "                        if ole.exists('HwpSummaryInformation'):\n",
    "                            try:\n",
    "                                summary = ole.openstream('HwpSummaryInformation')\n",
    "                                summary_bytes = summary.read()\n",
    "                                summary.close()\n",
    "                                \n",
    "                                # 가능한 인코딩으로 시도\n",
    "                                for encoding in ['utf-16-le', 'cp949', 'euc-kr']:\n",
    "                                    try:\n",
    "                                        # 인코딩 변환 후 유효한 문자만 필터링\n",
    "                                        decoded = summary_bytes.decode(encoding, errors='replace')\n",
    "                                        valid_text = ''.join(ch for ch in decoded if ch.isprintable())\n",
    "                                        if valid_text.strip():\n",
    "                                            hwp_content.append(valid_text)\n",
    "                                            log_debug(f\"HWP 요약정보 추출 성공({encoding}): {len(valid_text)}자\")\n",
    "                                            break\n",
    "                                    except:\n",
    "                                        continue\n",
    "                            except Exception as e:\n",
    "                                log_debug(f\"HWP 요약정보 추출 오류: {str(e)}\")\n",
    "                    \n",
    "                    # 결과 합치기\n",
    "                    content = \"\\n\".join(hwp_content)\n",
    "                    if content:\n",
    "                        log_debug(f\"HWP 파일 {file_path.name}에서 {len(content)}자 추출됨\")\n",
    "                else:\n",
    "                    log_debug(f\"HWP 파일 {file_path.name}은 OLE 형식이 아님\")\n",
    "            except Exception as e:\n",
    "                log_debug(f\"HWP 처리 오류({file_path.name}): {str(e)}\")\n",
    "                \n",
    "        # PDF 파일\n",
    "        elif ext == '.pdf':\n",
    "            try:\n",
    "                import PyPDF2\n",
    "                with open(file_path, 'rb') as file:\n",
    "                    pdf_content = []\n",
    "                    \n",
    "                    try:\n",
    "                        # 엄격하지 않은 모드로 PDF 읽기\n",
    "                        reader = PyPDF2.PdfReader(file, strict=False)\n",
    "                        \n",
    "                        # 모든 페이지 처리\n",
    "                        for page_num, page in enumerate(reader.pages):\n",
    "                            try:\n",
    "                                page_text = page.extract_text()\n",
    "                                if page_text and page_text.strip():\n",
    "                                    pdf_content.append(f\"---페이지 {page_num+1}---\")\n",
    "                                    pdf_content.append(page_text)\n",
    "                                    log_debug(f\"PDF 페이지 {page_num+1} 추출 성공: {len(page_text)}자\")\n",
    "                            except Exception as page_e:\n",
    "                                log_debug(f\"PDF 페이지 {page_num+1} 처리 오류: {str(page_e)}\")\n",
    "                                continue\n",
    "                        \n",
    "                        content = \"\\n\".join(pdf_content)\n",
    "                        if len(pdf_content) > 0:\n",
    "                            log_debug(f\"PDF 파일 {file_path.name}에서 {len(pdf_content)}개 블록 추출됨\")\n",
    "                    except Exception as e:\n",
    "                        log_debug(f\"PDF 파일 구조 오류({file_path.name}): {str(e)}\")\n",
    "            except Exception as e:\n",
    "                log_debug(f\"PDF 처리 오류({file_path.name}): {str(e)}\")\n",
    "        \n",
    "        # 내용이 추출되었는지 확인하고 준법감시 키워드 확인\n",
    "        if content:\n",
    "            keywords = ['준법감시', '심의필', '준법감사', '유효기간', '만료일']\n",
    "            found_keywords = [kw for kw in keywords if kw in content]\n",
    "            \n",
    "            if found_keywords:\n",
    "                log_debug(f\"파일 {file_path.name}에서 키워드 발견: {', '.join(found_keywords)}\")\n",
    "            else:\n",
    "                log_debug(f\"파일 {file_path.name}에서 키워드 미발견 (내용 길이: {len(content)}자)\")\n",
    "        else:\n",
    "            log_debug(f\"파일 {file_path.name}에서 내용 추출 실패\")\n",
    "\n",
    "        return content\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_debug(f\"파일 {file_path.name} 읽기 오류: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_hwp(file_path):\n",
    "    \"\"\"향상된 HWP 파일 처리\"\"\"\n",
    "    content = \"\"\n",
    "    \n",
    "    # 방법 1: olefile 사용\n",
    "    try:\n",
    "        import olefile\n",
    "        if olefile.isOleFile(str(file_path)):\n",
    "            hwp_content = []\n",
    "            \n",
    "            try:\n",
    "                with olefile.OleFile(str(file_path)) as ole:\n",
    "                    # 모든 스트림 확인\n",
    "                    streams = ole.listdir()\n",
    "                    log_debug(f\"HWP 파일 '{file_path.name}' 스트림: {streams}\")\n",
    "                    \n",
    "                    # PrvText 스트림 (미리보기) 처리\n",
    "                    if ole.exists('PrvText'):\n",
    "                        try:\n",
    "                            stream = ole.openstream('PrvText')\n",
    "                            data = stream.read()\n",
    "                            stream.close()\n",
    "                            \n",
    "                            # 여러 인코딩 시도\n",
    "                            for encoding in ['utf-16-le', 'utf-8', 'cp949', 'euc-kr']:\n",
    "                                try:\n",
    "                                    text = data.decode(encoding, errors='replace')\n",
    "                                    if text and len(text.strip()) > 10:\n",
    "                                        hwp_content.append(f\"[미리보기 텍스트 - {encoding}]\")\n",
    "                                        hwp_content.append(text)\n",
    "                                        log_debug(f\"HWP 미리보기 텍스트 성공({encoding}): {len(text)}자\")\n",
    "                                        break\n",
    "                                except:\n",
    "                                    continue\n",
    "                        except Exception as e:\n",
    "                            log_debug(f\"HWP 미리보기 텍스트 추출 오류: {str(e)}\")\n",
    "                    \n",
    "                    # HwpSummaryInformation 스트림 처리\n",
    "                    if ole.exists('HwpSummaryInformation'):\n",
    "                        try:\n",
    "                            stream = ole.openstream('HwpSummaryInformation')\n",
    "                            data = stream.read()\n",
    "                            stream.close()\n",
    "                            \n",
    "                            # 여러 인코딩 시도\n",
    "                            for encoding in ['utf-16-le', 'utf-8', 'cp949', 'euc-kr']:\n",
    "                                try:\n",
    "                                    text = data.decode(encoding, errors='replace')\n",
    "                                    # 출력 가능한 문자만 필터링\n",
    "                                    text = ''.join(c for c in text if c.isprintable() or c in '\\n\\r\\t')\n",
    "                                    if text and len(text.strip()) > 5:\n",
    "                                        hwp_content.append(f\"[문서 요약 정보 - {encoding}]\")\n",
    "                                        hwp_content.append(text)\n",
    "                                        log_debug(f\"HWP 요약 정보 성공({encoding}): {len(text)}자\")\n",
    "                                        break\n",
    "                                except:\n",
    "                                    continue\n",
    "                        except Exception as e:\n",
    "                            log_debug(f\"HWP 요약 정보 추출 오류: {str(e)}\")\n",
    "                    \n",
    "                    # BodyText 관련 스트림 검색 \n",
    "                    body_streams = [s for s in streams if 'BodyText' in str(s) or 'Section' in str(s)]\n",
    "                    for stream_name in body_streams:\n",
    "                        try:\n",
    "                            stream_path = '/'.join(stream_name) if isinstance(stream_name, tuple) else stream_name\n",
    "                            stream = ole.openstream(stream_path)\n",
    "                            data = stream.read()\n",
    "                            stream.close()\n",
    "                            \n",
    "                            # 여러 인코딩 시도\n",
    "                            for encoding in ['utf-16-le', 'utf-8', 'cp949', 'euc-kr']:\n",
    "                                try:\n",
    "                                    text = data.decode(encoding, errors='replace')\n",
    "                                    # 출력 가능한 문자만 필터링\n",
    "                                    text = ''.join(c for c in text if c.isprintable() or c in '\\n\\r\\t')\n",
    "                                    # 의미 있는 텍스트 필터링 (너무 짧거나 의미 없는 문자열 제외)\n",
    "                                    if text and len(text.strip()) > 20 and any(c.isalpha() for c in text):\n",
    "                                        hwp_content.append(f\"[본문 스트림 - {stream_path}]\")\n",
    "                                        hwp_content.append(text)\n",
    "                                        log_debug(f\"HWP 본문 스트림 성공({encoding}): {len(text)}자\")\n",
    "                                        break\n",
    "                                except:\n",
    "                                    continue\n",
    "                        except Exception as e:\n",
    "                            log_debug(f\"HWP 본문 스트림 처리 오류({stream_name}): {str(e)}\")\n",
    "                \n",
    "                # 결과 합치기\n",
    "                if hwp_content:\n",
    "                    content = \"\\n\".join(hwp_content)\n",
    "                    log_debug(f\"HWP 파일 '{file_path.name}'에서 올리파일로 {len(hwp_content)}개 블록 추출 성공\")\n",
    "            except Exception as e:\n",
    "                log_debug(f\"HWP 올리파일 처리 오류: {str(e)}\")\n",
    "        else:\n",
    "            log_debug(f\"HWP 파일 '{file_path.name}'은 OLE 형식이 아님\")\n",
    "    except ImportError:\n",
    "        log_debug(\"olefile 라이브러리 없음, 설치 필요: pip install olefile\")\n",
    "    except Exception as e:\n",
    "        log_debug(f\"HWP 올리파일 방식 오류: {str(e)}\")\n",
    "    \n",
    "    # 방법 2: hwp-to-txt 유틸리티 사용 (필요 시)\n",
    "    if not content or len(content) < 100:\n",
    "        try:\n",
    "            # 외부 명령어 시도 (hwp5txt 필요)\n",
    "            import subprocess\n",
    "            result = subprocess.run(['hwp5txt', str(file_path)], capture_output=True, text=True, encoding='utf-8')\n",
    "            if result.stdout and len(result.stdout) > len(content):\n",
    "                content = result.stdout\n",
    "                log_debug(f\"HWP 파일 '{file_path.name}'에서 hwp5txt로 변환 성공: {len(content)}자\")\n",
    "        except Exception as e:\n",
    "            log_debug(f\"hwp5txt 변환 시도 실패: {str(e)}\")\n",
    "    \n",
    "    # 방법 3: 관련된 TXT 파일 찾기\n",
    "    if not content or len(content) < 100:\n",
    "        try:\n",
    "            # 같은 이름의 TXT 파일이 있는지 확인\n",
    "            txt_path = file_path.with_suffix('.txt')\n",
    "            if txt_path.exists():\n",
    "                with open(txt_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                    txt_content = f.read()\n",
    "                    if txt_content and len(txt_content) > len(content):\n",
    "                        content = txt_content\n",
    "                        log_debug(f\"HWP 관련 TXT 파일 '{txt_path.name}'에서 읽기 성공: {len(content)}자\")\n",
    "        except Exception as e:\n",
    "            log_debug(f\"관련 TXT 파일 읽기 실패: {str(e)}\")\n",
    "    \n",
    "    return content\n",
    "def process_txt(file_path):\n",
    "    \"\"\"향상된 TXT 파일 처리\"\"\"\n",
    "    content = \"\"\n",
    "    \n",
    "    # 여러 인코딩으로 시도\n",
    "    encodings = ['utf-8', 'cp949', 'euc-kr', 'latin1']\n",
    "    success = False\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding, errors='replace') as f:\n",
    "                text = f.read()\n",
    "                \n",
    "                if text and text.strip():\n",
    "                    # 기본적인 텍스트 정규화\n",
    "                    content = text\n",
    "                    log_debug(f\"TXT 파일 '{file_path.name}'을 {encoding} 인코딩으로 성공적으로 읽음: {len(content)}자\")\n",
    "                    success = True\n",
    "                    break\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            log_debug(f\"TXT 파일 '{file_path.name}' {encoding} 인코딩 시도 중 오류: {str(e)}\")\n",
    "    \n",
    "    if not success:\n",
    "        try:\n",
    "            # 바이너리 모드로 읽어서 인코딩 추측\n",
    "            with open(file_path, 'rb') as f:\n",
    "                raw_data = f.read()\n",
    "                \n",
    "                # 한글 인코딩 추측을 위한 간단한 휴리스틱\n",
    "                if raw_data.startswith(b'\\xff\\xfe') or raw_data.startswith(b'\\xfe\\xff'):\n",
    "                    # UTF-16 인코딩\n",
    "                    content = raw_data.decode('utf-16', errors='replace')\n",
    "                    log_debug(f\"TXT 파일 '{file_path.name}'을 UTF-16 인코딩으로 읽음: {len(content)}자\")\n",
    "                else:\n",
    "                    # 마지막 시도: 바이너리 데이터에서 텍스트 추출\n",
    "                    content = raw_data.decode('utf-8', errors='replace')\n",
    "                    log_debug(f\"TXT 파일 '{file_path.name}'을 바이너리에서 강제 변환: {len(content)}자\")\n",
    "        except Exception as e:\n",
    "            log_debug(f\"TXT 파일 '{file_path.name}' 최종 시도 오류: {str(e)}\")\n",
    "    \n",
    "    return content\n",
    "\n",
    "def process_docx(file_path):\n",
    "    \"\"\"향상된 DOCX 파일 처리\"\"\"\n",
    "    content = \"\"\n",
    "    try:\n",
    "        # 라이브러리 확인 및 설치\n",
    "        try:\n",
    "            import docx\n",
    "        except ImportError:\n",
    "            print(\"python-docx 라이브러리가 설치되지 않았습니다. 설치 중...\")\n",
    "            import subprocess\n",
    "            subprocess.check_call([\"pip\", \"install\", \"python-docx\"])\n",
    "            import docx\n",
    "        \n",
    "        # 문서 열기\n",
    "        doc = docx.Document(str(file_path))\n",
    "        \n",
    "        # 1. 모든 단락 추출 \n",
    "        paragraphs_text = []\n",
    "        for para in doc.paragraphs:\n",
    "            if para.text.strip():\n",
    "                # 텍스트 정규화 (줄바꿈 및 공백 처리)\n",
    "                clean_text = re.sub(r'\\s+', ' ', para.text).strip()\n",
    "                if clean_text:\n",
    "                    paragraphs_text.append(clean_text)\n",
    "        \n",
    "        # 2. 모든 표 추출\n",
    "        tables_text = []\n",
    "        for table in doc.tables:\n",
    "            for row in table.rows:\n",
    "                row_text = []\n",
    "                for cell in row.cells:\n",
    "                    if cell.text.strip():\n",
    "                        row_text.append(cell.text.strip())\n",
    "                if row_text:\n",
    "                    tables_text.append(' | '.join(row_text))\n",
    "        \n",
    "        # 3. 헤더 및 푸터 추출 시도\n",
    "        header_footer_text = []\n",
    "        try:\n",
    "            for section in doc.sections:\n",
    "                # 헤더 추출\n",
    "                if section.header:\n",
    "                    for p in section.header.paragraphs:\n",
    "                        if p.text.strip():\n",
    "                            header_footer_text.append(\"[헤더] \" + p.text.strip())\n",
    "                \n",
    "                # 푸터 추출\n",
    "                if section.footer:\n",
    "                    for p in section.footer.paragraphs:\n",
    "                        if p.text.strip():\n",
    "                            header_footer_text.append(\"[푸터] \" + p.text.strip())\n",
    "        except Exception as e:\n",
    "            log_debug(f\"DOCX 헤더/푸터 추출 오류: {str(e)}\")\n",
    "        \n",
    "        # 4. 수정 이력 및 코멘트 추출 시도\n",
    "        comments_text = []\n",
    "        try:\n",
    "            if hasattr(doc, 'comments'):\n",
    "                for comment in doc.comments:\n",
    "                    if comment.text.strip():\n",
    "                        comments_text.append(\"[코멘트] \" + comment.text.strip())\n",
    "        except Exception as e:\n",
    "            log_debug(f\"DOCX 코멘트 추출 오류: {str(e)}\")\n",
    "        \n",
    "        # 모든 텍스트 결합\n",
    "        all_texts = paragraphs_text + tables_text + header_footer_text + comments_text\n",
    "        \n",
    "        if all_texts:\n",
    "            content = \"\\n\".join(all_texts)\n",
    "            log_debug(f\"DOCX 파일 '{file_path.name}'에서 {len(all_texts)}개 텍스트 블록 추출 성공\")\n",
    "        else:\n",
    "            log_debug(f\"DOCX 파일 '{file_path.name}'에서 추출된 텍스트 없음\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        log_debug(f\"DOCX 파일 '{file_path.name}' 처리 중 오류: {str(e)}\")\n",
    "    \n",
    "    return content\n",
    "\n",
    "def collect_target_files(base_path):\n",
    "    \"\"\"타겟 파일 수집 - 병렬 처리 최적화\"\"\"\n",
    "    print(\"분석할 파일 찾는 중...\")\n",
    "    file_extensions = ['.docx', '.xlsx', '.pptx', '.hwp', '.txt', '.pdf']\n",
    "    \n",
    "    target_files = []\n",
    "    \n",
    "    # 디렉토리 목록 생성\n",
    "    all_dirs = []\n",
    "    try:\n",
    "        for d in Path(base_path).iterdir():\n",
    "            if d.is_dir():\n",
    "                all_dirs.append(d)\n",
    "    except Exception as e:\n",
    "        print(f\"디렉토리 목록 생성 중 오류: {e}\")\n",
    "    \n",
    "    if not all_dirs:  # 하위 디렉토리가 없으면 현재 디렉토리 검색\n",
    "        all_dirs = [Path(base_path)]\n",
    "    \n",
    "    print(f\"총 {len(all_dirs)}개 디렉토리 검색 예정\")\n",
    "    \n",
    "    # 병렬 파일 검색 - 간소화 버전\n",
    "    def search_files_in_directory(directory):\n",
    "        found_files = []\n",
    "        for ext in file_extensions:\n",
    "            try:\n",
    "                for file_path in Path(directory).glob(f'**/*{ext}'):\n",
    "                    # 키워드 필터링 조건 제거 - 모든 파일 포함\n",
    "                    found_files.append(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"디렉토리 {directory} 검색 중 오류: {e}\")\n",
    "        return found_files\n",
    "    \n",
    "    # 파일 검색 (병렬 처리)\n",
    "    target_files = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        search_results = list(executor.map(search_files_in_directory, all_dirs))\n",
    "        for result in search_results:\n",
    "            target_files.extend(result)\n",
    "    \n",
    "    print(f\"총 {len(target_files)}개 파일을 찾았습니다.\")\n",
    "    return target_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_expiry_from_filename(filename):\n",
    "    \"\"\"파일명에서 유효기간 정보를 추출 - 개선된 버전\"\"\"\n",
    "    import re\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # 디버깅 로그 함수가 없으면 간단히 구현\n",
    "    try:\n",
    "        log_debug(f\"파일명 분석 시작: {filename}\")\n",
    "    except:\n",
    "        def log_debug(msg): pass\n",
    "    \n",
    "    # IBK 파일명 패턴에 맞는 정규식\n",
    "    ibk_patterns = [\n",
    "        r'유효기간\\(([0-9]{4})[\\\\.\\\\-]([0-9]{2})[\\\\.\\\\-]([0-9]{2})\\)',  # 유효기간(2025.08.20)\n",
    "        r'유효기간\\(([0-9]{4})([0-9]{2})([0-9]{2})\\)',  # 유효기간(20250820)\n",
    "        r'유효기간\\(([0-9]{4})[-/.]([0-9]{1,2})[-/.]([0-9]{1,2})\\)',  # 유효기간(2025-08-20)\n",
    "        r'제[0-9]{4}-[0-9]+호\\([^)]+\\)\\s*유효기간\\((\\d{4})[./-](\\d{1,2})[./-](\\d{1,2})\\)',  # 제2024-4806호(날짜) 유효기간(2025.08.20)\n",
    "        r'유효기간[_\\s]([0-9]{4})[./-]([0-9]{1,2})[./-]([0-9]{1,2})',  # 유효기간_2025.08.20\n",
    "        r'([0-9]{4})[./-]([0-9]{1,2})[./-]([0-9]{1,2})[_\\s]유효기간',  # 2025.08.20_유효기간\n",
    "        r'만료일[_\\s]([0-9]{4})[./-]([0-9]{1,2})[./-]([0-9]{1,2})'   # 만료일_2025.08.20\n",
    "    ]\n",
    "    \n",
    "    # 오류 날짜 목록 - 전역변수가 없으면 기본값 설정\n",
    "    try:\n",
    "        ERROR_DATES\n",
    "    except NameError:\n",
    "        ERROR_DATES = ['2024-11-30', '2020-12-31']\n",
    "    \n",
    "    # 패턴 검색\n",
    "    for i, pattern in enumerate(ibk_patterns):\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            try:\n",
    "                # 패턴에 따라 그룹 인덱스 조정\n",
    "                if '제' in pattern and len(match.groups()) >= 3:  # 제2024-4806호 형식\n",
    "                    year, month, day = map(int, match.groups()[-3:])\n",
    "                else:  # 일반 형식\n",
    "                    year, month, day = map(int, match.groups())\n",
    "                    \n",
    "                if 2000 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                    expiry_date = datetime(year, month, day)\n",
    "                    try:\n",
    "                        log_debug(f\"유효기간 추출 성공: {expiry_date.strftime('%Y-%m-%d')} (패턴 {i+1})\")\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    # 오류 날짜 필터링\n",
    "                    date_str = expiry_date.strftime('%Y-%m-%d')\n",
    "                    if date_str in ERROR_DATES:\n",
    "                        try:\n",
    "                            log_debug(f\"오류 날짜 감지: {date_str}\")\n",
    "                        except:\n",
    "                            pass\n",
    "                        continue\n",
    "                        \n",
    "                    return expiry_date\n",
    "            except (ValueError, IndexError) as e:\n",
    "                try:\n",
    "                    log_debug(f\"패턴 {i+1} 매칭 오류: {str(e)}\")\n",
    "                except:\n",
    "                    pass\n",
    "                continue\n",
    "    \n",
    "    # 확장 패턴 시도 (날짜 형식이 다른 경우)\n",
    "    extended_patterns = [\n",
    "        r'유효기간[:\\s]*([12]\\d{3})[년\\.\\-]?([01]?\\d)[월\\.\\-]?([0-3]?\\d)[일]?',  # 유효기간: 2025년6월3일\n",
    "        r'([12]\\d{3})년?[^0-9]+([01]?\\d)월?[^0-9]+([0-3]?\\d)일?[^0-9]*유효',  # 2025년 6월 3일 유효\n",
    "        r'유효[^0-9]*([12]\\d{3})년?[^0-9]+([01]?\\d)월?[^0-9]+([0-3]?\\d)일?'   # 유효 2025년 6월 3일\n",
    "    ]\n",
    "    \n",
    "    for i, pattern in enumerate(extended_patterns):\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            try:\n",
    "                groups = match.groups()\n",
    "                try:\n",
    "                    log_debug(f\"확장 패턴 {i+1} 매치: {pattern} -> {groups}\")\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                year, month, day = map(int, groups)\n",
    "                if 2000 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                    expiry_date = datetime(year, month, day)\n",
    "                    date_str = expiry_date.strftime('%Y-%m-%d')\n",
    "                    \n",
    "                    if date_str in ERROR_DATES:\n",
    "                        try:\n",
    "                            log_debug(f\"오류 날짜 감지: {date_str}\")\n",
    "                        except:\n",
    "                            pass\n",
    "                        continue\n",
    "                        \n",
    "                    try:\n",
    "                        log_debug(f\"확장 패턴으로 유효기간 추출 성공: {date_str}\")\n",
    "                    except:\n",
    "                        pass\n",
    "                    return expiry_date\n",
    "            except (ValueError, IndexError) as e:\n",
    "                try:\n",
    "                    log_debug(f\"확장 패턴 {i+1} 매칭 오류: {str(e)}\")\n",
    "                except:\n",
    "                    pass\n",
    "                continue\n",
    "    \n",
    "    try:\n",
    "        log_debug(f\"파일명에서 유효기간 추출 실패: {filename}\")\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def has_keywords_in_name(filename):\n",
    "    \"\"\"파일명에 준법감시 관련 키워드가 있는지 확인\"\"\"\n",
    "    keywords = ['유효기간', '준법감시', '심의필', '만료일', '법무', '결재', '승인']\n",
    "    return any(keyword in filename for keyword in keywords)\n",
    "\n",
    "def load_documents(directory_path, file_extensions=['.txt', '.docx', '.hwp', '.xlsx', '.xls', '.pptx', '.ppt', '.csv', '.pdf']):\n",
    "    \"\"\"다양한 파일 형식에서 텍스트 추출 (PDF 제외)\"\"\"\n",
    "    documents = []\n",
    "    filenames = []\n",
    "    file_contents = {}\n",
    "    expiry_dates = {}  # 파일명에서 추출한 유효기간 정보 저장\n",
    "    \n",
    "    # 우선순위 파일과 일반 파일 분리\n",
    "    priority_files = []\n",
    "    normal_files = []\n",
    "    \n",
    "    print(\"파일 목록 수집 중...\")\n",
    "    # 모든 파일 탐색 및 분류\n",
    "    for file_path in Path(directory_path).glob('**/*'):\n",
    "        if not file_path.is_file():\n",
    "            continue\n",
    "            \n",
    "        # 파일 확장자 확인\n",
    "        ext = file_path.suffix.lower()\n",
    "        if ext not in file_extensions:\n",
    "            continue\n",
    "                    \n",
    "        # 임시 파일 건너뛰기\n",
    "        if file_path.name.startswith('~$') or file_path.name.startswith('.~'):\n",
    "            continue\n",
    "        \n",
    "        # 파일명에서 키워드 확인 및 우선순위 부여\n",
    "        if has_keywords_in_name(file_path.name):\n",
    "            priority_files.append(file_path)\n",
    "            \n",
    "            # 파일명에서 유효기간 정보 추출\n",
    "            expiry_date = extract_expiry_from_filename(file_path.name)\n",
    "            if expiry_date:\n",
    "                expiry_dates[file_path.name] = expiry_date\n",
    "        else:\n",
    "            normal_files.append(file_path)\n",
    "    \n",
    "    print(f\"우선 처리할 파일: {len(priority_files)}개\")\n",
    "    print(f\"일반 처리할 파일: {len(normal_files)}개\")\n",
    "    print(f\"파일명에서 유효기간 정보 추출: {len(expiry_dates)}개\")\n",
    "    \n",
    "    # 처리할 파일 목록 준비 (우선순위 파일 + 일부 일반 파일)\n",
    "    max_normal_files = min(5000, len(normal_files))  # 최대 5000개 일반 파일만 처리\n",
    "    all_files = priority_files + normal_files[:max_normal_files]\n",
    "    \n",
    "    # 진행 상황 표시\n",
    "    for file_path in tqdm(all_files, desc=\"파일 처리 중\"):\n",
    "        try:\n",
    "            content = \"\"\n",
    "            \n",
    "            # 1. 텍스트 파일 처리\n",
    "            if file_path.suffix.lower() == '.txt':\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "                    content = file.read()\n",
    "            \n",
    "            # 2. CSV 파일 처리\n",
    "            elif file_path.suffix.lower() == '.csv':\n",
    "                try:\n",
    "                    # 다양한 옵션으로 시도\n",
    "                    for encoding in ['utf-8', 'cp949']:\n",
    "                        for sep in [',', '\\t', ';']:\n",
    "                            try:\n",
    "                                df = pd.read_csv(file_path, encoding=encoding, sep=sep)\n",
    "                                if not df.empty:\n",
    "                                    text_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "                                    if text_cols:\n",
    "                                        content = '\\n'.join(df[text_cols].fillna('').astype(str).apply(' '.join, axis=1).tolist())\n",
    "                                    else:\n",
    "                                        content = '\\n'.join(df.fillna('').astype(str).apply(' '.join, axis=1).tolist())\n",
    "                                    break\n",
    "                            except:\n",
    "                                continue\n",
    "                        if content:\n",
    "                            break\n",
    "                except Exception as e:\n",
    "                    print(f\"CSV 파일 처리 오류: {file_path.name} - {e}\")\n",
    "            \n",
    "            # 3. Word 파일 처리\n",
    "            elif file_path.suffix.lower() == '.docx':\n",
    "                try:\n",
    "                    import docx\n",
    "                    doc = docx.Document(file_path)\n",
    "                    content = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs if paragraph.text])\n",
    "                except ImportError:\n",
    "                    print(\"python-docx 라이브러리가 필요합니다.\")\n",
    "                    # 주피터 노트북에서 라이브러리 설치를 시도\n",
    "                    import sys\n",
    "                    !{sys.executable} -m pip install python-docx\n",
    "                    # 설치 후 다시 시도\n",
    "                    try:\n",
    "                        import docx\n",
    "                        doc = docx.Document(file_path)\n",
    "                        content = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs if paragraph.text])\n",
    "                    except ImportError:\n",
    "                        print(\"python-docx 설치 실패. 수동으로 설치해 주세요.\")\n",
    "                        content = \"\"\n",
    "            \n",
    "            # 4. HWP 파일 처리 부분 수정\n",
    "            elif ext == '.hwp':\n",
    "                try:\n",
    "                    import olefile\n",
    "                    if olefile.isOleFile(str(file_path)):\n",
    "                        print(f\"HWP 파일 처리 시작: {file_path.name}\")\n",
    "                        with olefile.OleFile(str(file_path)) as ole:\n",
    "                            # 스트림 목록 확인 (디버깅용)\n",
    "                            streams = ole.listdir()\n",
    "                            print(f\"HWP 스트림: {streams}\")\n",
    "                            \n",
    "                            # 여러 가능한 스트림 이름 시도\n",
    "                            hwp_streams = ['PrvText', 'HwpSummaryInformation', 'DocInfo', 'BodyText']\n",
    "                            content_parts = []\n",
    "                            \n",
    "                            for stream_name in hwp_streams:\n",
    "                                if ole.exists(stream_name):\n",
    "                                    try:\n",
    "                                        stream = ole.openstream(stream_name)\n",
    "                                        stream_data = stream.read()\n",
    "                                        \n",
    "                                        # 여러 인코딩 시도\n",
    "                                        for encoding in ['utf-16-le', 'cp949', 'euc-kr']:\n",
    "                                            try:\n",
    "                                                decoded = stream_data.decode(encoding, errors='replace')\n",
    "                                                if not decoded.isspace() and decoded.strip():\n",
    "                                                    content_parts.append(decoded)\n",
    "                                                    print(f\"HWP 스트림 '{stream_name}' 읽기 성공 ({encoding})\")\n",
    "                                                break\n",
    "                                            except:\n",
    "                                                continue\n",
    "                                        \n",
    "                                        stream.close()\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"HWP 스트림 '{stream_name}' 읽기 오류: {str(e)}\")\n",
    "                            \n",
    "                            content = \"\\n\".join(content_parts)\n",
    "                            \n",
    "                            # 내용이 적거나 없으면 pyhwp 등 다른 라이브러리 사용 고려\n",
    "                            if len(content) < 100:\n",
    "                                print(f\"HWP 파일 '{file_path.name}'에서 내용 추출 제한적임 ({len(content)} 자)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"HWP 처리 오류: {str(e)}\")\n",
    "                    content = \"\"\n",
    "\n",
    "            # 5. Excel 파일 처리 부분 수정\n",
    "            elif file_path.suffix.lower() in ['.xlsx', '.xls']:\n",
    "                try:\n",
    "                    import openpyxl\n",
    "                    # ExcelFile 객체 사용\n",
    "                    xl = pd.ExcelFile(file_path, engine='openpyxl')\n",
    "                    sheet_names = xl.sheet_names\n",
    "                    \n",
    "                    all_text = []\n",
    "                    for sheet_name in sheet_names:\n",
    "                        sheet_df = pd.read_excel(file_path, sheet_name=sheet_name, engine='openpyxl')\n",
    "                        text_cols = [col for col in sheet_df.columns if sheet_df[col].dtype == 'object']\n",
    "                        if text_cols:\n",
    "                            sheet_text = '\\n'.join(sheet_df[text_cols].fillna('').astype(str).apply(' '.join, axis=1).tolist())\n",
    "                            all_text.append(sheet_text)\n",
    "                    \n",
    "                    content = '\\n'.join(all_text)\n",
    "                except Exception as xl_e:\n",
    "                    print(f\"Excel 파일 처리 오류: {file_path.name} - {xl_e}\")\n",
    "                    content = f\"[Excel 오류: {file_path.name}]\"\n",
    "            \n",
    "            # 6. PowerPoint 파일 처리\n",
    "            elif file_path.suffix.lower() in ['.pptx', '.ppt']:\n",
    "                try:\n",
    "                    import pptx\n",
    "                    presentation = pptx.Presentation(file_path)\n",
    "                    text_runs = []\n",
    "                    \n",
    "                    # 슬라이드 별 텍스트 추출\n",
    "                    for slide in presentation.slides:\n",
    "                        for shape in slide.shapes:\n",
    "                            if hasattr(shape, \"text\") and shape.text:\n",
    "                                text_runs.append(shape.text)\n",
    "                    \n",
    "                    content = \"\\n\".join(text_runs)\n",
    "                except ImportError:\n",
    "                    print(\"PowerPoint 파일 처리를 위해 python-pptx 라이브러리가 필요합니다.\")\n",
    "                except Exception as ppt_e:\n",
    "                    print(f\"PowerPoint 파일 처리 오류: {file_path.name} - {ppt_e}\")\n",
    "            \n",
    "            # 내용이 있는 경우만 추가\n",
    "            if content:\n",
    "                documents.append(content)\n",
    "                filenames.append(file_path.name)\n",
    "                file_contents[file_path.name] = content\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"파일 {file_path.name} 처리 중 오류: {e}\")\n",
    "    \n",
    "    print(f\"총 {len(documents)}개 파일에서 텍스트 추출 완료\")\n",
    "    return documents, filenames, file_contents, expiry_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab715bce",
   "metadata": {},
   "source": [
    "#4. IBK 준법감시 패턴 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedComplianceExtractor:\n",
    "    def __init__(self, api_key=None, use_ngram=True, use_ai=False):\n",
    "        self.api_key = api_key\n",
    "        self.use_ngram = use_ngram\n",
    "        self.use_ai = use_ai\n",
    "        self.chunk_size = 1000  # 최적 청크 크기 (GPT API 토큰 한도 고려)\n",
    "        self.chunk_overlap = 200  # 맥락 유지를 위한 중첩 크기\n",
    "        \n",
    "        # 키워드 및 패턴 정의\n",
    "        self.compliance_keywords = [\n",
    "            '준법감시', '준법감시인', '준법감사', '심의필', '제호', \n",
    "            '승인', '결재', '법규', '컴플라이언스'\n",
    "        ]\n",
    "        \n",
    "        self.validity_keywords = [\n",
    "            '유효기간', '만료일', '유효', '만료', '기간', \n",
    "            '까지', '효력', '사용기한'\n",
    "        ]\n",
    "        \n",
    "    def create_semantic_chunks(self, text):\n",
    "        \"\"\"의미론적 청크 생성 - 문장/단락 단위 분할\"\"\"\n",
    "        if not text or len(text) < self.chunk_size:\n",
    "            return [text] if text else []\n",
    "        \n",
    "        # 단락 기반 분할 (더 의미있는 청크)\n",
    "        paragraphs = re.split(r'\\n\\s*\\n', text)\n",
    "        \n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for para in paragraphs:\n",
    "            # 단일 단락이 청크 크기보다 크면 문장으로 분할\n",
    "            if len(para) > self.chunk_size:\n",
    "                sentences = re.split(r'(?<=[.!?])\\s+', para)\n",
    "                for sentence in sentences:\n",
    "                    if len(current_chunk) + len(sentence) <= self.chunk_size:\n",
    "                        current_chunk += sentence + \" \"\n",
    "                    else:\n",
    "                        chunks.append(current_chunk.strip())\n",
    "                        current_chunk = sentence + \" \"\n",
    "            # 청크 크기 이내면 단락 단위로 추가\n",
    "            elif len(current_chunk) + len(para) <= self.chunk_size:\n",
    "                current_chunk += para + \"\\n\\n\"\n",
    "            else:\n",
    "                chunks.append(current_chunk.strip())\n",
    "                current_chunk = para + \"\\n\\n\"\n",
    "        \n",
    "        # 마지막 청크 추가\n",
    "        if current_chunk.strip():\n",
    "            chunks.append(current_chunk.strip())\n",
    "        \n",
    "        # 청크 중첩 처리로 맥락 유지\n",
    "        overlapped_chunks = []\n",
    "        for i in range(len(chunks)):\n",
    "            if i < len(chunks) - 1:\n",
    "                # 현재 청크와 다음 청크의 일부를 중첩\n",
    "                overlap_size = min(self.chunk_overlap, len(chunks[i]), len(chunks[i+1]))\n",
    "                \n",
    "                if i == 0:\n",
    "                    overlapped_chunks.append(chunks[i])\n",
    "                \n",
    "                # 중첩 청크: 현재 청크의 끝 + 다음 청크의 시작\n",
    "                current_end = chunks[i][-overlap_size:] if overlap_size > 0 else \"\"\n",
    "                next_start = chunks[i+1][:overlap_size] if overlap_size > 0 else \"\"\n",
    "                \n",
    "                overlapped_chunks.append(current_end + next_start)\n",
    "            \n",
    "            if i == len(chunks) - 1:\n",
    "                overlapped_chunks.append(chunks[i])\n",
    "        \n",
    "        return overlapped_chunks if overlapped_chunks else chunks\n",
    "        \n",
    "    def score_chunks_by_relevance(self, chunks):\n",
    "        \"\"\"준법감시 관련성 기준으로 청크 점수화 및 필터링\"\"\"\n",
    "        scored_chunks = []\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            # 키워드 기반 점수\n",
    "            keyword_score = 0\n",
    "            for keyword in self.compliance_keywords:\n",
    "                keyword_score += chunk.lower().count(keyword.lower()) * 5\n",
    "            \n",
    "            for keyword in self.validity_keywords:\n",
    "                keyword_score += chunk.lower().count(keyword.lower()) * 5\n",
    "            \n",
    "            # 정규식 패턴 기반 점수\n",
    "            pattern_score = 0\n",
    "            compliance_patterns = [\n",
    "                r'제\\d{4}-\\d+호',  # 제2024-4806호\n",
    "                r'준법감시[_\\-\\s]*\\d{4}[_\\-\\s]*\\d+',  # 준법감시-2024-123\n",
    "                r'심의필[_\\-\\s]*\\d{4}[_\\-\\s]*\\d+',    # 심의필-2024-123\n",
    "            ]\n",
    "            \n",
    "            date_patterns = [\n",
    "                r'유효기간[^0-9]*\\d{4}[-/.년\\s]\\d{1,2}[-/.월\\s]\\d{1,2}일?',\n",
    "                r'만료일[^0-9]*\\d{4}[-/.년\\s]\\d{1,2}[-/.월\\s]\\d{1,2}일?'\n",
    "            ]\n",
    "            \n",
    "            for pattern in compliance_patterns + date_patterns:\n",
    "                if re.search(pattern, chunk):\n",
    "                    pattern_score += 20\n",
    "            \n",
    "            # 종합 점수 및 저장\n",
    "            total_score = keyword_score + pattern_score\n",
    "            if total_score > 0:  # 관련성 있는 청크만 저장\n",
    "                scored_chunks.append((i, chunk, total_score))\n",
    "        \n",
    "        # 점수 기준 정렬 및 상위 청크 선택\n",
    "        scored_chunks.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # 상위 청크 반환 (최대 5개, 또는 점수 30 이상인 모든 청크)\n",
    "        top_chunks = [(idx, chunk) for idx, chunk, score in scored_chunks if score >= 30]\n",
    "        if len(top_chunks) > 5:\n",
    "            top_chunks = top_chunks[:5]\n",
    "        \n",
    "        return top_chunks\n",
    "    \n",
    "    def call_gpt_api(self, chunk):\n",
    "        \"\"\"GPT API 호출하여 준법감시 정보 추출\"\"\"\n",
    "        if not self.use_ai or not self.api_key:\n",
    "            return None\n",
    "        \n",
    "        # API 호출 코드 (실제 사용 시 활성화)\n",
    "        log_debug(\"GPT API 호출 (가정)\")\n",
    "        return {\n",
    "            \"compliance_number\": None, \n",
    "            \"expiry_date\": None,\n",
    "            \"confidence\": 0.0,\n",
    "            \"context\": None\n",
    "        }\n",
    "    \n",
    "    def extract_ngram_features(self, text, n=3):\n",
    "        \"\"\"N-gram 특성 추출\"\"\"\n",
    "        from nltk.util import ngrams\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        \n",
    "        # 토큰화\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        \n",
    "        # n-gram 생성\n",
    "        n_grams = list(ngrams(tokens, n))\n",
    "        return ['_'.join(gram) for gram in n_grams]\n",
    "    \n",
    "    def extract_with_regex(self, text):\n",
    "        \"\"\"정규식으로 준법감시 정보 추출\"\"\"\n",
    "        log_debug(\"정규식으로 준법감시 정보 추출 시작\")\n",
    "        result = {\"compliance_number\": None, \"expiry_date\": None}\n",
    "        \n",
    "        # 준법감시필 번호 추출\n",
    "        compliance_patterns = [\n",
    "            r'제(\\d{4})-(\\d+)호',  # 제2024-4806호\n",
    "            r'준법감시[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)',  # 준법감시-2024-123\n",
    "            r'심의필[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)',    # 심의필-2024-123\n",
    "            r'준법[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)'       # 준법-2024-123\n",
    "        ]\n",
    "        \n",
    "        for pattern in compliance_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                try:\n",
    "                    year, number = match.groups()\n",
    "                    \n",
    "                    # 형식에 따라 준법감시필 번호 생성\n",
    "                    if pattern.startswith(r'제'):\n",
    "                        result[\"compliance_number\"] = f\"제{year}-{number}호\"\n",
    "                    elif pattern.startswith(r'준법감시'):\n",
    "                        result[\"compliance_number\"] = f\"준법감시-{year}-{number}\"\n",
    "                    elif pattern.startswith(r'심의필'):\n",
    "                        result[\"compliance_number\"] = f\"심의필-{year}-{number}\"\n",
    "                    else:\n",
    "                        result[\"compliance_number\"] = f\"준법-{year}-{number}\"\n",
    "                    \n",
    "                    log_debug(f\"정규식으로 준법감시필 번호 추출: {result['compliance_number']}\")\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # 유효기간 추출\n",
    "        expiry_patterns = [\n",
    "            r'유효기간[^0-9]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?',  # 유효기간: 2025.08.20\n",
    "            r'만료일[^0-9]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?',   # 만료일: 2025.08.20\n",
    "            r'(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?[^0-9]*까지',  # 2025.08.20까지\n",
    "            r'(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?[^0-9]*만료',  # 2025.08.20 만료\n",
    "            r'유효[^0-9]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?'   # 유효: 2025.08.20\n",
    "        ]\n",
    "        \n",
    "        for pattern in expiry_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                try:\n",
    "                    year, month, day = map(int, match.groups())\n",
    "                    if 2000 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                        date_str = f\"{year}-{month:02d}-{day:02d}\"\n",
    "                        \n",
    "                        # 오류 날짜 필터링\n",
    "                        if date_str in ERROR_DATES:\n",
    "                            log_debug(f\"오류 날짜 감지: {date_str}\")\n",
    "                            continue\n",
    "                        \n",
    "                        result[\"expiry_date\"] = date_str\n",
    "                        log_debug(f\"정규식으로 유효기간 추출: {date_str}\")\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "        return result\n",
    "    \n",
    "    def combine_results(self, regex_result, gpt_result, ngram_features):\n",
    "        \"\"\"여러 추출 결과 통합 - 가중치 기반\"\"\"\n",
    "        # 초기화\n",
    "        final_result = {\n",
    "            \"compliance_number\": None,\n",
    "            \"expiry_date\": None,\n",
    "            \"confidence\": 0.0,\n",
    "            \"context\": None,\n",
    "            \"ngram_result\": {},\n",
    "            \"gpt_result\": {}\n",
    "        }\n",
    "        \n",
    "        # 정규식 결과 처리 (가중치: 0.6)\n",
    "        if regex_result:\n",
    "            final_result[\"compliance_number\"] = regex_result.get(\"compliance_number\")\n",
    "            final_result[\"expiry_date\"] = regex_result.get(\"expiry_date\")\n",
    "            final_result[\"confidence\"] = 0.6\n",
    "            final_result[\"ngram_result\"] = regex_result\n",
    "        \n",
    "        # GPT 결과 처리 (가중치: 0.8) - GPT API가 활성화된 경우\n",
    "        if gpt_result:\n",
    "            gpt_confidence = gpt_result.get(\"confidence\", 0.0) * 0.8\n",
    "            \n",
    "            # 신뢰도가 높은 경우에만 기존 결과 대체\n",
    "            if gpt_confidence > final_result[\"confidence\"]:\n",
    "                final_result[\"compliance_number\"] = gpt_result.get(\"compliance_number\")\n",
    "                final_result[\"expiry_date\"] = gpt_result.get(\"expiry_date\")\n",
    "                final_result[\"confidence\"] = gpt_confidence\n",
    "                final_result[\"context\"] = gpt_result.get(\"context\")\n",
    "            \n",
    "            # 일치하는 경우 신뢰도 상승\n",
    "            elif (final_result[\"compliance_number\"] == gpt_result.get(\"compliance_number\") or\n",
    "                  final_result[\"expiry_date\"] == gpt_result.get(\"expiry_date\")):\n",
    "                final_result[\"confidence\"] += 0.2\n",
    "                \n",
    "            final_result[\"gpt_result\"] = gpt_result\n",
    "        \n",
    "        # N-gram 결과 활용 (신뢰도 미세 조정)\n",
    "        if ngram_features and (final_result[\"compliance_number\"] or final_result[\"expiry_date\"]):\n",
    "            final_result[\"confidence\"] = min(1.0, final_result[\"confidence\"] + 0.1)\n",
    "        \n",
    "        return final_result\n",
    "    \n",
    "    def process_document(self, content):\n",
    "        \"\"\"문서 내용에서 준법감시필 번호와 유효기간 추출\"\"\"\n",
    "        log_debug(\"문서 내용 분석 시작\")\n",
    "        \n",
    "        if not content or not isinstance(content, str):\n",
    "            return {\"compliance_number\": None, \"expiry_date\": None, \"confidence\": 0.0}\n",
    "        \n",
    "        # 1. 텍스트 청크 분할\n",
    "        chunks = self.create_semantic_chunks(content)\n",
    "        \n",
    "        # 2. 관련성 높은 청크 선별\n",
    "        relevant_chunks = self.score_chunks_by_relevance(chunks)\n",
    "        \n",
    "        # 청크가 없으면 전체 텍스트에 대해 간단 분석\n",
    "        if not relevant_chunks and content:\n",
    "            mini_chunk = content[:500]\n",
    "            regex_result = self.extract_with_regex(mini_chunk)\n",
    "            ai_result = self.call_gpt_api(mini_chunk) if self.use_ai else None\n",
    "            ngram_features = self.extract_ngram_features(mini_chunk) if self.use_ngram else None\n",
    "            return self.combine_results(regex_result, ai_result, ngram_features)\n",
    "        \n",
    "        # 청크별 결과 저장\n",
    "        chunk_results = []\n",
    "        \n",
    "        # 3. 각 청크별 분석\n",
    "        for idx, chunk in relevant_chunks:\n",
    "            regex_result = self.extract_with_regex(chunk)\n",
    "            ai_result = self.call_gpt_api(chunk) if self.use_ai else None\n",
    "            ngram_features = self.extract_ngram_features(chunk) if self.use_ngram else None\n",
    "            \n",
    "            combined = self.combine_results(regex_result, ai_result, ngram_features)\n",
    "            combined[\"chunk_index\"] = idx\n",
    "            chunk_results.append(combined)\n",
    "        \n",
    "        # 결과가 없으면 빈 결과 반환\n",
    "        if not chunk_results:\n",
    "            return {\"compliance_number\": None, \"expiry_date\": None, \"confidence\": 0.0}\n",
    "        \n",
    "        # 4. 최종 결과 선택 (신뢰도 기준)\n",
    "        chunk_results.sort(key=lambda x: x.get(\"confidence\", 0.0), reverse=True)\n",
    "        return chunk_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe464167",
   "metadata": {},
   "source": [
    "5. IBK 준법감시 정보 및 유효기간 추출 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_file(file_path, target_files=None):\n",
    "    \"\"\"파일 정보를 분석하여 결과 딕셔너리 반환 - 강화된 버전\"\"\"\n",
    "    try:\n",
    "        filename = file_path.name\n",
    "        \n",
    "        # target_files가 제공된 경우에만 인덱스 계산, 아니면 -1 사용\n",
    "        if target_files is not None:\n",
    "            file_index = target_files.index(file_path) if file_path in target_files else -1\n",
    "            total_files = len(target_files)\n",
    "        else:\n",
    "            file_index = -1\n",
    "            total_files = 0\n",
    "        \n",
    "        # 파일 순번 로깅\n",
    "        log_debug(f\"{'='*50}\")\n",
    "        log_debug(f\"파일 분석 시작 [{file_index+1}/{total_files}]: {filename}\")\n",
    "        \n",
    "        # 파일명에서 정보 추출\n",
    "        filename_info = extract_info_from_filename(filename)\n",
    "        \n",
    "        # 파일 내용 확인 변수 초기화\n",
    "        content_result = {\n",
    "            \"compliance_number\": None,\n",
    "            \"expiry_date\": None,\n",
    "            \"confidence\": 0.0,\n",
    "            \"context\": None\n",
    "        }\n",
    "        \n",
    "        # 파일 확장자 확인\n",
    "        ext = file_path.suffix.lower()\n",
    "        \n",
    "        # 파일 크기 확인\n",
    "        try:\n",
    "            file_size = file_path.stat().st_size / (1024 * 1024)  # MB 단위\n",
    "            is_large_file = file_size > 10  # 10MB 초과\n",
    "            \n",
    "            if is_large_file:\n",
    "                log_debug(f\"대용량 파일 감지: {file_size:.2f}MB - 내용 분석 제한\")\n",
    "                content = read_file_content(file_path)[:20000]  # 처음 2만자만 분석\n",
    "            else:\n",
    "                content = read_file_content(file_path)\n",
    "                \n",
    "            # 내용이 있는 경우 분석\n",
    "            if content:\n",
    "                # AI 추출기 인스턴스 생성\n",
    "                extractor = EnhancedComplianceExtractor(\n",
    "                    api_key=api_key,\n",
    "                    use_ngram=True,\n",
    "                    use_ai=False  # API 키가 없으면 AI 사용 안함\n",
    "                )\n",
    "                \n",
    "                # 문서 처리\n",
    "                content_result = extractor.process_document(content)\n",
    "        except Exception as e:\n",
    "            log_debug(f\"파일 크기 확인 또는 내용 분석 오류: {str(e)}\")\n",
    "        \n",
    "        # 결과 통합\n",
    "        combined_result = combine_file_results(\n",
    "            filename=filename,\n",
    "            content_result=content_result,\n",
    "            filename_result=filename_info\n",
    "        )\n",
    "        \n",
    "        # 파일 경로 추가\n",
    "        combined_result['파일경로'] = str(file_path.parent)\n",
    "        \n",
    "        # 파일 인덱스 안전하게 추가\n",
    "        if target_files is not None:\n",
    "            try:\n",
    "                combined_result['파일인덱스'] = target_files.index(file_path) + 1 if file_path in target_files else -1\n",
    "            except:\n",
    "                combined_result['파일인덱스'] = -1\n",
    "        else:\n",
    "            combined_result['파일인덱스'] = -1\n",
    "        \n",
    "        return combined_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_debug(f\"파일 분석 중 오류: {str(e)}\")\n",
    "        log_debug(traceback.format_exc())\n",
    "        # 오류 발생 시 기본 정보만 반환\n",
    "        return {\n",
    "            '파일명': file_path.name,\n",
    "            '상태': '상태 불명',\n",
    "            '만료일': '알 수 없음',\n",
    "            '남은 일수': None,\n",
    "            '파일명_준법감시필': None, \n",
    "            '파일명_유효기간': None,\n",
    "            '파일명_유효기간_상태': '정보 없음',\n",
    "            '파일명_남은일수': None,\n",
    "            '파일내_준법감시필_번호': None,\n",
    "            '파일내_유효기간_날짜': None,\n",
    "            '파일내_유효기간_상태': '정보 없음',\n",
    "            '파일내_남은일수': None,\n",
    "            '파일경로': str(file_path.parent),\n",
    "            '파일인덱스': -1\n",
    "        }\n",
    "\n",
    "def combine_file_results(filename, content_result, filename_result):\n",
    "    \"\"\"파일명과 내용에서 추출한 결과 통합\"\"\"\n",
    "    # 기본값 설정\n",
    "    result = {\n",
    "        '파일명': filename,\n",
    "        '상태': '상태 불명',\n",
    "        '만료일': '알 수 없음',\n",
    "        '남은 일수': None,\n",
    "        \n",
    "        # 파일명 정보\n",
    "        '파일명_준법감시필': filename_result.get('compliance_number'),\n",
    "        '파일명_유효기간': filename_result.get('expiry_date'),\n",
    "        '파일명_유효기간_상태': filename_result.get('status', '정보 없음'),\n",
    "        '파일명_남은일수': filename_result.get('days_to_expiry'),\n",
    "        \n",
    "        # 파일 내용 정보\n",
    "        '파일내_준법감시필_번호': content_result.get('compliance_number'),\n",
    "        '파일내_유효기간_날짜': content_result.get('expiry_date'),\n",
    "        '파일내_유효기간_상태': '정보 없음',\n",
    "        '파일내_남은일수': None,\n",
    "        \n",
    "        '신뢰도': content_result.get('confidence', 0.0),\n",
    "        '파일경로': None\n",
    "    }\n",
    "    \n",
    "    # 파일 내용에서 유효기간 상태 계산\n",
    "    content_expiry = content_result.get('expiry_date')\n",
    "    if content_expiry:\n",
    "        try:\n",
    "            today = datetime.now().date()\n",
    "            content_date_obj = datetime.strptime(content_expiry, '%Y-%m-%d').date()\n",
    "            content_days_left = (content_date_obj - today).days\n",
    "            \n",
    "            result['파일내_남은일수'] = content_days_left\n",
    "            \n",
    "            if content_days_left < 0:\n",
    "                result['파일내_유효기간_상태'] = '만료됨'\n",
    "            elif content_days_left <= 30:\n",
    "                result['파일내_유효기간_상태'] = '30일 이내 만료'\n",
    "            else:\n",
    "                result['파일내_유효기간_상태'] = '유효함'\n",
    "        except Exception as e:\n",
    "            log_debug(f\"내용 유효기간 상태 계산 오류: {e}\")\n",
    "    \n",
    "    # 최종 만료일 및 상태 결정 (파일명 우선, 내용 차선)\n",
    "    if filename_result.get('expiry_date'):\n",
    "        result['만료일'] = filename_result.get('expiry_date')\n",
    "        result['상태'] = filename_result.get('status')\n",
    "        result['남은 일수'] = filename_result.get('days_to_expiry')\n",
    "    elif content_expiry:\n",
    "        result['만료일'] = content_expiry\n",
    "        result['상태'] = result['파일내_유효기간_상태']\n",
    "        result['남은 일수'] = result['파일내_남은일수']\n",
    "    \n",
    "    return result\n",
    "\n",
    "def save_interim_results(results, batch_idx):\n",
    "    \"\"\"중간 결과 저장 함수\"\"\"\n",
    "    try:\n",
    "        interim_df = pd.DataFrame(results)\n",
    "        interim_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        interim_file = f\"interim_results_{batch_idx}_{interim_timestamp}.csv\"\n",
    "        interim_df.to_csv(interim_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"중간 결과 저장됨: {interim_file}\")\n",
    "        return interim_file\n",
    "    except Exception as e:\n",
    "        print(f\"중간 결과 저장 중 오류: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_formatted_excel(df, excel_file):\n",
    "    \"\"\"결과를 서식이 적용된 Excel로 저장\"\"\"\n",
    "    try:\n",
    "        # ExcelWriter 사용\n",
    "        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "            # DataFrame을 Excel로 변환\n",
    "            df.to_excel(writer, index=False, sheet_name='준법감시')\n",
    "            \n",
    "            # 워크북과 워크시트 가져오기\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets['준법감시']\n",
    "            \n",
    "            # 열 너비 자동 조정\n",
    "            for i, column in enumerate(df.columns):\n",
    "                # 열 이름의 길이 확인\n",
    "                column_width = max(len(str(column)), 10)  # 최소 너비 10\n",
    "                \n",
    "                # 열의 데이터 중 가장 긴 값의 길이 확인 (최대 100행까지만 확인)\n",
    "                max_length = 0\n",
    "                for j in range(min(len(df), 100)):  # 처리 시간 단축을 위해 최대 100행까지만 확인\n",
    "                    cell_value = str(df.iloc[j, i])\n",
    "                    max_length = max(max_length, len(cell_value))\n",
    "                \n",
    "                # 최종 열 너비 결정 (최대 100자, 기본 폰트 기준)\n",
    "                column_width = min(max(column_width, max_length + 2), 100)  # +2는 여유 공간\n",
    "                \n",
    "                # 열 너비 설정\n",
    "                col_letter = get_column_letter(i + 1)\n",
    "                worksheet.column_dimensions[col_letter].width = column_width\n",
    "            \n",
    "            # 헤더 행 스타일 설정\n",
    "            header_font = Font(bold=True)\n",
    "            header_fill = PatternFill(start_color='E6E6E6', end_color='E6E6E6', fill_type='solid')\n",
    "            \n",
    "            for cell in worksheet[1]:\n",
    "                cell.font = header_font\n",
    "                cell.fill = header_fill\n",
    "            \n",
    "            # 데이터 행에 조건부 서식 설정 (상태에 따른 색상)\n",
    "            status_colors = {\n",
    "                '만료됨': 'FFC7CE',  # 밝은 빨강\n",
    "                '30일 이내 만료': 'FFEB9C',  # 밝은 노랑\n",
    "                '유효함': 'C6EFCE',  # 밝은 녹색\n",
    "                '상태 불명': 'DDDDDD'  # 회색\n",
    "            }\n",
    "            \n",
    "            # 상태 열 인덱스 찾기\n",
    "            status_col_idx = df.columns.get_loc('상태') + 1  # Excel은 1부터 시작\n",
    "            status_col_letter = get_column_letter(status_col_idx)\n",
    "            \n",
    "            # 각 상태별로 조건부 서식 설정\n",
    "            for status, color in status_colors.items():\n",
    "                rule = CellIsRule(\n",
    "                    operator='equal',\n",
    "                    formula=[f'\"{status}\"'],\n",
    "                    stopIfTrue=True,\n",
    "                    fill=PatternFill(start_color=color, end_color=color, fill_type='solid')\n",
    "                )\n",
    "                \n",
    "                # 조건부 서식 적용 범위 (상태 열만)\n",
    "                cell_range = f'{status_col_letter}2:{status_col_letter}{len(df) + 1}'\n",
    "                worksheet.conditional_formatting.add(cell_range, rule)\n",
    "                \n",
    "        print(f\"Excel 파일이 자동 열 너비 조정과 서식을 적용하여 저장되었습니다: {excel_file}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Excel 저장 오류: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad77b5",
   "metadata": {},
   "source": [
    "6. 텍스트 비교 알고리즘 (카피킬러 스타일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedTextComparison:\n",
    "    def __init__(self, min_ngram_size=3, max_ngram_size=5, threshold=0.6):\n",
    "        self.min_ngram_size = min_ngram_size\n",
    "        self.max_ngram_size = max_ngram_size\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def _create_ngrams(self, text, n):\n",
    "        \"\"\"텍스트에서 n-gram 생성\"\"\"\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        return list(ngrams(tokens, n))\n",
    "    \n",
    "    def _create_fingerprints(self, text):\n",
    "        \"\"\"텍스트에서 지문(fingerprint) 생성\"\"\"\n",
    "        fingerprints = set()\n",
    "        for n in range(self.min_ngram_size, self.max_ngram_size + 1):\n",
    "            ngram_list = self._create_ngrams(text, n)\n",
    "            for gram in ngram_list:\n",
    "                # n-gram을 문자열로 변환하고 해시 생성\n",
    "                gram_str = ' '.join(gram)\n",
    "                fingerprint = hashlib.md5(gram_str.encode()).hexdigest()\n",
    "                fingerprints.add(fingerprint)\n",
    "        return fingerprints\n",
    "    \n",
    "    def _calculate_jaccard_similarity(self, set1, set2):\n",
    "        \"\"\"두 집합의 자카드 유사도 계산\"\"\"\n",
    "        if not set1 or not set2:\n",
    "            return 0.0\n",
    "        intersection = len(set1.intersection(set2))\n",
    "        union = len(set1.union(set2))\n",
    "        return intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    def calculate_similarity(self, text1, text2):\n",
    "        \"\"\"두 텍스트 간 유사도 계산 (지문 기반)\"\"\"\n",
    "        fingerprints1 = self._create_fingerprints(text1)\n",
    "        fingerprints2 = self._create_fingerprints(text2)\n",
    "        \n",
    "        return self._calculate_jaccard_similarity(fingerprints1, fingerprints2)\n",
    "    \n",
    "    def find_similar_segments(self, text1, text2, window_size=100, step_size=50):\n",
    "        \"\"\"텍스트 내에서 유사한 세그먼트 찾기\"\"\"\n",
    "        similar_segments = []\n",
    "        \n",
    "        # 텍스트를 세그먼트로 분할\n",
    "        segments1 = [text1[i:i+window_size] for i in range(0, len(text1), step_size) if i+window_size <= len(text1)]\n",
    "        segments2 = [text2[i:i+window_size] for i in range(0, len(text2), step_size) if i+window_size <= len(text2)]\n",
    "        \n",
    "        for i, seg1 in enumerate(segments1):\n",
    "            for j, seg2 in enumerate(segments2):\n",
    "                similarity = self.calculate_similarity(seg1, seg2)\n",
    "                if similarity >= self.threshold:\n",
    "                    similar_segments.append({\n",
    "                        'segment1': seg1,\n",
    "                        'segment2': seg2,\n",
    "                        'position1': i * step_size,\n",
    "                        'position2': j * step_size,\n",
    "                        'similarity': similarity\n",
    "                    })\n",
    "        \n",
    "        return similar_segments\n",
    "    \n",
    "    def find_similar_documents(self, documents, filenames):\n",
    "        \"\"\"문서 집합에서 유사한 문서 쌍 찾기\"\"\"\n",
    "        similar_docs = []\n",
    "        \n",
    "        total_comparisons = len(documents) * (len(documents) - 1) // 2\n",
    "        print(f\"총 {total_comparisons}개의 문서 쌍을 비교합니다...\")\n",
    "        \n",
    "        comparison_count = 0\n",
    "        for i in range(len(documents)):\n",
    "            for j in range(i+1, len(documents)):\n",
    "                similarity = self.calculate_similarity(documents[i], documents[j])\n",
    "                \n",
    "                comparison_count += 1\n",
    "                if comparison_count % 100 == 0 or comparison_count == total_comparisons:\n",
    "                    progress = 100 * comparison_count / total_comparisons\n",
    "                    print(f\"진행 상황: {progress:.1f}% ({comparison_count}/{total_comparisons})\")\n",
    "                \n",
    "                if similarity >= self.threshold:\n",
    "                    similar_docs.append({\n",
    "                        'doc1': filenames[i],\n",
    "                        'doc2': filenames[j],\n",
    "                        'similarity': similarity\n",
    "                    })\n",
    "        \n",
    "        print(f\"유사도 {self.threshold} 이상인 문서 쌍: {len(similar_docs)}개\")\n",
    "        return similar_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b2252",
   "metadata": {},
   "source": [
    "#7. 유효기간 분석 및 예측 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d75f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpiryAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.today = datetime.now()\n",
    "        \n",
    "    def predict_expiry_date(self, dates, approval_numbers, validity_sentences):\n",
    "        \"\"\"다양한 정보를 종합하여 유효기간 예측\"\"\"\n",
    "        potential_expiry_dates = []\n",
    "        \n",
    "        # 1. 명시적 유효기간 또는 만료일이 있는 경우\n",
    "        for date_info in dates:\n",
    "            if date_info['date_type'] == '유효기간' or date_info['date_type'] == '만료일':\n",
    "                if 'date' in date_info:  # 단일 날짜\n",
    "                    potential_expiry_dates.append({\n",
    "                        'date': date_info['date'],\n",
    "                        'confidence': 0.9,\n",
    "                        'source': '명시적 유효기간/만료일',\n",
    "                        'context': date_info['context']\n",
    "                    })\n",
    "                elif 'end_date' in date_info:  # 날짜 범위\n",
    "                    potential_expiry_dates.append({\n",
    "                        'date': date_info['end_date'],\n",
    "                        'confidence': 0.8,\n",
    "                        'source': '유효기간 범위 종료일',\n",
    "                        'context': date_info['context']\n",
    "                    })\n",
    "        \n",
    "        # 2. 유효기간 문장에 포함된 날짜 활용\n",
    "        for sentence in validity_sentences:\n",
    "            for date_info in dates:\n",
    "                if 'date' in date_info and date_info['context'] in sentence:\n",
    "                    if date_info['date'] > self.today:  # 미래 날짜만 고려\n",
    "                        potential_expiry_dates.append({\n",
    "                            'date': date_info['date'],\n",
    "                            'confidence': 0.7,\n",
    "                            'source': '유효기간 문장 내 날짜',\n",
    "                            'context': sentence\n",
    "                        })\n",
    "        \n",
    "        # 3. 준법감시/심의필 번호 기준 추정 (통상 1년 유효기간 가정)\n",
    "        for approval in approval_numbers:\n",
    "            try:\n",
    "                approval_year = int(approval['year'])\n",
    "                # 승인일을 해당 연도의 1월 1일로 가정하고 1년 유효기간 추정\n",
    "                approval_date = datetime(approval_year, 1, 1)\n",
    "                estimated_expiry = approval_date + timedelta(days=365)\n",
    "                \n",
    "                potential_expiry_dates.append({\n",
    "                    'date': estimated_expiry,\n",
    "                    'confidence': 0.5,\n",
    "                    'source': '심의필 번호 기반 추정',\n",
    "                    'context': approval['full_text']\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # 4. 일반 날짜 중 미래 날짜 고려 (낮은 신뢰도)\n",
    "        future_dates = [date_info for date_info in dates \n",
    "                       if 'date' in date_info and date_info['date'] > self.today]\n",
    "        \n",
    "        for date_info in future_dates:\n",
    "            potential_expiry_dates.append({\n",
    "                'date': date_info['date'],\n",
    "                'confidence': 0.3,\n",
    "                'source': '문서 내 미래 날짜',\n",
    "                'context': date_info['context']\n",
    "            })\n",
    "        \n",
    "        # 결과가 없으면 None 반환\n",
    "        if not potential_expiry_dates:\n",
    "            return None\n",
    "            \n",
    "        # 신뢰도 기준 정렬\n",
    "        potential_expiry_dates.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        return potential_expiry_dates[0]  # 가장 신뢰도 높은 유효기간 반환\n",
    "    \n",
    "    def analyze_expiry_status(self, compliance_results):\n",
    "        \"\"\"추출된 정보를 기반으로 유효기간 상태 분석\"\"\"\n",
    "        expiry_status = []\n",
    "        \n",
    "        for doc_result in tqdm(compliance_results, desc=\"유효기간 분석 중\"):\n",
    "            # 유효기간 예측\n",
    "            expiry_prediction = self.predict_expiry_date(\n",
    "                doc_result['dates'], \n",
    "                doc_result['approval_numbers'],\n",
    "                doc_result['validity_sentences']\n",
    "            )\n",
    "            \n",
    "            if expiry_prediction:\n",
    "                expiry_date = expiry_prediction['date']\n",
    "                days_to_expiry = (expiry_date - self.today).days\n",
    "                \n",
    "                if days_to_expiry < 0:\n",
    "                    status = 'expired'\n",
    "                elif days_to_expiry <= 30:\n",
    "                    status = 'expiring_soon'\n",
    "                else:\n",
    "                    status = 'valid'\n",
    "                    \n",
    "                expiry_status.append({\n",
    "                    'filename': doc_result['filename'],\n",
    "                    'expiry_date': expiry_date,\n",
    "                    'days_to_expiry': days_to_expiry,\n",
    "                    'confidence': expiry_prediction['confidence'],\n",
    "                    'source': expiry_prediction['source'],\n",
    "                    'context': expiry_prediction['context'],\n",
    "                    'status': status\n",
    "                })\n",
    "            else:\n",
    "                expiry_status.append({\n",
    "                    'filename': doc_result['filename'],\n",
    "                    'expiry_date': None,\n",
    "                    'days_to_expiry': None,\n",
    "                    'confidence': 0,\n",
    "                    'source': '정보 없음',\n",
    "                    'context': '',\n",
    "                    'status': 'unknown'\n",
    "                })\n",
    "        \n",
    "        # 요약 통계\n",
    "        status_counts = {'expired': 0, 'expiring_soon': 0, 'valid': 0, 'unknown': 0}\n",
    "        for result in expiry_status:\n",
    "            status_counts[result['status']] += 1\n",
    "            \n",
    "        print(\"\\n유효기간 상태 분석 결과:\")\n",
    "        print(f\"- 만료됨: {status_counts['expired']}개 ({100*status_counts['expired']/len(expiry_status):.1f}%)\")\n",
    "        print(f\"- 30일 이내 만료 예정: {status_counts['expiring_soon']}개 ({100*status_counts['expiring_soon']/len(expiry_status):.1f}%)\")\n",
    "        print(f\"- 유효함: {status_counts['valid']}개 ({100*status_counts['valid']/len(expiry_status):.1f}%)\")\n",
    "        print(f\"- 상태 불명: {status_counts['unknown']}개 ({100*status_counts['unknown']/len(expiry_status):.1f}%)\")\n",
    "        \n",
    "        return expiry_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fadb07",
   "metadata": {},
   "source": [
    "#8. 유사도 기반 정보 전파 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3cf862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityBasedInfoPropagation:\n",
    "    def __init__(self, similarity_threshold=0.7):\n",
    "        self.text_comparator = EnhancedTextComparison(threshold=similarity_threshold)\n",
    "        \n",
    "    def propagate_expiry_info(self, documents, filenames, expiry_status, file_contents):\n",
    "        \"\"\"유사 문서 간 유효기간 정보 전파\"\"\"\n",
    "        # 유사 문서 찾기\n",
    "        similar_docs = self.text_comparator.find_similar_documents(documents, filenames)\n",
    "        \n",
    "        # 불확실한 문서에 대해 유사 문서의 정보 활용\n",
    "        unknown_docs = [status for status in expiry_status if status['status'] == 'unknown']\n",
    "        \n",
    "        updated_status = expiry_status.copy()\n",
    "        \n",
    "        if len(unknown_docs) > 0 and len(similar_docs) > 0:\n",
    "            print(f\"\\n유사 문서 간 정보 전파를 시작합니다...\")\n",
    "            print(f\"- 상태 불명 문서: {len(unknown_docs)}개\")\n",
    "            print(f\"- 유사 문서 쌍: {len(similar_docs)}개\")\n",
    "            \n",
    "            propagation_count = 0\n",
    "            for unknown in unknown_docs:\n",
    "                unknown_idx = next(i for i, s in enumerate(updated_status) if s['filename'] == unknown['filename'])\n",
    "                \n",
    "                # 유사 문서 중 유효기간 정보가 있는 문서 찾기\n",
    "                for similar in similar_docs:\n",
    "                    if similar['doc1'] == unknown['filename']:\n",
    "                        similar_doc = similar['doc2']\n",
    "                    elif similar['doc2'] == unknown['filename']:\n",
    "                        similar_doc = similar['doc1']\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    # 유사 문서의 유효기간 정보 가져오기\n",
    "                    similar_status = next((s for s in expiry_status if s['filename'] == similar_doc and s['status'] != 'unknown'), None)\n",
    "                    \n",
    "                    if similar_status and similar_status['expiry_date']:\n",
    "                        # 유사도에 따라 신뢰도 조정\n",
    "                        confidence = similar_status['confidence'] * similar['similarity'] * 0.8\n",
    "                        \n",
    "                        updated_status[unknown_idx] = {\n",
    "                            'filename': unknown['filename'],\n",
    "                            'expiry_date': similar_status['expiry_date'],\n",
    "                            'days_to_expiry': similar_status['days_to_expiry'],\n",
    "                            'confidence': confidence,\n",
    "                            'source': f\"유사 문서({similar_doc})에서 전파\",\n",
    "                            'context': f\"문서 유사도: {similar['similarity']:.2f}\",\n",
    "                            'status': similar_status['status']\n",
    "                        }\n",
    "                        propagation_count += 1\n",
    "                        break\n",
    "            \n",
    "            print(f\"정보 전파 완료: {propagation_count}개 문서에 유효기간 정보가 전파되었습니다.\")\n",
    "        \n",
    "        # 최종 상태 통계\n",
    "        status_counts = {'expired': 0, 'expiring_soon': 0, 'valid': 0, 'unknown': 0}\n",
    "        for result in updated_status:\n",
    "            status_counts[result['status']] += 1\n",
    "            \n",
    "        print(\"\\n최종 유효기간 상태:\")\n",
    "        print(f\"- 만료됨: {status_counts['expired']}개 ({100*status_counts['expired']/len(updated_status):.1f}%)\")\n",
    "        print(f\"- 30일 이내 만료 예정: {status_counts['expiring_soon']}개 ({100*status_counts['expiring_soon']/len(updated_status):.1f}%)\")\n",
    "        print(f\"- 유효함: {status_counts['valid']}개 ({100*status_counts['valid']/len(updated_status):.1f}%)\")\n",
    "        print(f\"- 상태 불명: {status_counts['unknown']}개 ({100*status_counts['unknown']/len(updated_status):.1f}%)\")\n",
    "        \n",
    "        return updated_status, similar_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb8951",
   "metadata": {},
   "source": [
    "#9. 결과 시각화 및 보고서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_report(expiry_status, similar_docs):\n",
    "    \"\"\"분석 결과 시각화 및 보고서 생성\"\"\"\n",
    "    # 1. 유효기간 상태 차트\n",
    "    status_counts = {'valid': 0, 'expiring_soon': 0, 'expired': 0, 'unknown': 0}\n",
    "    for doc in expiry_status:\n",
    "        status_counts[doc['status']] += 1\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    colors = ['green', 'orange', 'red', 'gray']\n",
    "    labels = ['유효함', '30일 이내 만료', '만료됨', '상태 불명']\n",
    "    values = [status_counts['valid'], status_counts['expiring_soon'], status_counts['expired'], status_counts['unknown']]\n",
    "    \n",
    "    plt.bar(labels, values, color=colors)\n",
    "    plt.title('문서 유효기간 상태', fontsize=14)\n",
    "    plt.ylabel('문서 수', fontsize=12)\n",
    "    \n",
    "    # 데이터 레이블 추가\n",
    "    for i, v in enumerate(values):\n",
    "        plt.text(i, v + 0.1, f\"{v}개\\n({100*v/sum(values):.1f}%)\", \n",
    "                 ha='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # 2. 만료까지 남은 일수 분포\n",
    "    plt.subplot(2, 2, 2)\n",
    "    valid_docs = [doc for doc in expiry_status if doc['status'] in ['valid', 'expiring_soon']]\n",
    "    if valid_docs:\n",
    "        days_to_expiry = [doc['days_to_expiry'] for doc in valid_docs if doc['days_to_expiry'] is not None]\n",
    "        if days_to_expiry:\n",
    "            plt.hist(days_to_expiry, bins=10, color='blue', alpha=0.7)\n",
    "            plt.title('만료까지 남은 일수 분포', fontsize=14)\n",
    "            plt.xlabel('일수', fontsize=12)\n",
    "            plt.ylabel('문서 수', fontsize=12)\n",
    "    \n",
    "    # 3. 신뢰도 분포\n",
    "    plt.subplot(2, 2, 3)\n",
    "    confidence_values = [doc['confidence'] for doc in expiry_status if doc['confidence'] > 0]\n",
    "    if confidence_values:\n",
    "        plt.hist(confidence_values, bins=10, color='purple', alpha=0.7)\n",
    "        plt.title('유효기간 예측 신뢰도 분포', fontsize=14)\n",
    "        plt.xlabel('신뢰도', fontsize=12)\n",
    "        plt.ylabel('문서 수', fontsize=12)\n",
    "    \n",
    "    # 4. 유사도 분포\n",
    "    plt.subplot(2, 2, 4)\n",
    "    if similar_docs:\n",
    "        similarities = [doc['similarity'] for doc in similar_docs]\n",
    "        plt.hist(similarities, bins=10, color='green', alpha=0.7)\n",
    "        plt.title('문서 간 유사도 분포', fontsize=14)\n",
    "        plt.xlabel('유사도', fontsize=12)\n",
    "        plt.ylabel('문서 쌍 수', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(BASE_PATH / 'compliance_analysis_report.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # 텍스트 보고서 생성\n",
    "    print(\"\\n=== IBK 준법감시 문서 분석 보고서 ===\")\n",
    "    \n",
    "    print(\"\\n[유효기간 만료 문서]\")\n",
    "    expired_docs = [doc for doc in expiry_status if doc['status'] == 'expired']\n",
    "    for doc in expired_docs[:10]:  # 상위 10개만 표시\n",
    "        print(f\"- {doc['filename']} (만료일: {doc['expiry_date'].strftime('%Y-%m-%d') if doc['expiry_date'] else '알 수 없음'}, 신뢰도: {doc['confidence']:.2f})\")\n",
    "        print(f\"  근거: {doc['source']}\")\n",
    "        print(f\"  컨텍스트: {doc['context']}\")\n",
    "    \n",
    "    if len(expired_docs) > 10:\n",
    "        print(f\"  ...외 {len(expired_docs)-10}개 더 있음\")\n",
    "    \n",
    "    print(\"\\n[30일 이내 만료 예정 문서]\")\n",
    "    expiring_soon = [doc for doc in expiry_status if doc['status'] == 'expiring_soon']\n",
    "    for doc in expiring_soon[:10]:  # 상위 10개만 표시\n",
    "        print(f\"- {doc['filename']} (만료일: {doc['expiry_date'].strftime('%Y-%m-%d')}, 남은 일수: {doc['days_to_expiry']}일, 신뢰도: {doc['confidence']:.2f})\")\n",
    "        print(f\"  근거: {doc['source']}\")\n",
    "        print(f\"  컨텍스트: {doc['context']}\")\n",
    "    \n",
    "    if len(expiring_soon) > 10:\n",
    "        print(f\"  ...외 {len(expiring_soon)-10}개 더 있음\")\n",
    "    \n",
    "    print(\"\\n[유사도 높은 문서 쌍]\")\n",
    "    # 유사도가 높은 순으로 정렬\n",
    "    sorted_similar_docs = sorted(similar_docs, key=lambda x: x['similarity'], reverse=True)\n",
    "    for pair in sorted_similar_docs[:10]:  # 상위 10개만 표시\n",
    "        print(f\"- {pair['doc1']} <-> {pair['doc2']} (유사도: {pair['similarity']:.2f})\")\n",
    "    \n",
    "    if len(sorted_similar_docs) > 10:\n",
    "        print(f\"  ...외 {len(sorted_similar_docs)-10}개 더 있음\")\n",
    "    \n",
    "    # DataFrame 반환\n",
    "    df_expiry = pd.DataFrame(expiry_status)\n",
    "    df_similarity = pd.DataFrame(similar_docs) if similar_docs else pd.DataFrame()\n",
    "    \n",
    "    # 결과 저장\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    df_expiry.to_csv(str(BASE_PATH / f'ibk_compliance_expiry_report_{timestamp}.csv'), index=False, encoding='utf-8-sig')\n",
    "    if not df_similarity.empty:\n",
    "        df_similarity.to_csv(str(BASE_PATH / f'ibk_document_similarity_report_{timestamp}.csv'), index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    return df_expiry, df_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c38999",
   "metadata": {},
   "source": [
    "#10. 필요한 환경 준비 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49bdf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_environment():\n",
    "    \"\"\"필요한 라이브러리 설치 확인\"\"\"\n",
    "    required_libraries = {\n",
    "        'PyPDF2': ('PyPDF2', 'PDF 파일 처리'),\n",
    "        'python-docx': ('docx', 'Word 문서 처리'),\n",
    "        'openpyxl': ('openpyxl', 'Excel 파일 처리'),\n",
    "        'python-pptx': ('pptx', 'PowerPoint 파일 처리'),\n",
    "        'olefile': ('olefile', 'HWP 파일 헤더 처리')\n",
    "    }\n",
    "    \n",
    "    installed = []\n",
    "    missing = []\n",
    "    \n",
    "    for display_name, (import_name, purpose) in required_libraries.items():\n",
    "        try:\n",
    "            __import__(import_name)\n",
    "            installed.append(f\"✓ {display_name} 설치됨 ({purpose})\")\n",
    "        except ImportError:\n",
    "            missing.append(f\"✗ {display_name} 미설치 ({purpose})\")\n",
    "    \n",
    "    # 결과 출력\n",
    "    for msg in installed:\n",
    "        print(msg)\n",
    "    for msg in missing:\n",
    "        print(msg)\n",
    "    \n",
    "    if missing:\n",
    "        print(\"\\n다음 라이브러리 설치가 필요합니다:\")\n",
    "        for lib, (_, _) in [(k, v) for k, v in required_libraries.items() if f\"✗ {k}\" in \" \".join(missing)]:\n",
    "            print(f\"pip install {lib}\")\n",
    "    \n",
    "    return len(missing) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd00fb",
   "metadata": {},
   "source": [
    "#11.IBK 준법감시 문서 분석 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전역 변수로 선언\n",
    "problematic_pdfs = set()\n",
    "updated_expiry_status = []  \n",
    "\n",
    "def process_pdf_safely(file_path):\n",
    "    \"\"\"안전하게 PDF 처리 - PyPDF2만 사용\"\"\"\n",
    "    if file_path in problematic_pdfs:\n",
    "        print(f\"이전에 문제가 있던 PDF 건너뜀: {file_path.name}\")\n",
    "        return \"\"\n",
    "    \n",
    "    content = \"\"\n",
    "    try:\n",
    "        import PyPDF2\n",
    "        try:\n",
    "            with open(file_path, 'rb') as file:\n",
    "                try:\n",
    "                    # strict=False로 설정하여 일부 오류 무시\n",
    "                    reader = PyPDF2.PdfReader(file, strict=False)\n",
    "                    \n",
    "                    # 페이지별로 처리하여 한 페이지에서 오류가 발생해도 계속 진행\n",
    "                    for page_num in range(len(reader.pages)):\n",
    "                        try:\n",
    "                            page_text = reader.pages[page_num].extract_text()\n",
    "                            if page_text:\n",
    "                                content += page_text + \"\\n\"\n",
    "                        except Exception as e:\n",
    "                            # 특정 페이지 처리 오류는 기록만 하고 계속 진행\n",
    "                            print(f\"페이지 {page_num} 처리 오류({file_path.name}): {type(e).__name__}\")\n",
    "                            continue\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"PDF 파일 구조 오류({file_path.name}): {type(e).__name__}\")\n",
    "                    # 오류가 있는 PDF 파일 목록에 추가\n",
    "                    problematic_pdfs.add(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"파일 열기 오류({file_path.name}): {type(e).__name__}\")\n",
    "            problematic_pdfs.add(file_path)\n",
    "    except ImportError:\n",
    "        print(\"PyPDF2 라이브러리가 필요합니다.\")\n",
    "    \n",
    "    return content\n",
    "\n",
    "def extract_expiry_date_from_filename(filename):\n",
    "    \"\"\"파일명에서 유효기간 정보를 추출\"\"\"\n",
    "    # 정규표현식을 사용하여 유효기간 패턴 찾기\n",
    "    # 예: '20240531', '2024-05-31', '유효기간_20240531' 등\n",
    "    \n",
    "    import re\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # 다양한 날짜 패턴 처리\n",
    "    patterns = [\n",
    "        r'(\\d{4})[년\\-_.]?(\\d{1,2})[월\\-_.]?(\\d{1,2})[일]?',  # 2024년05월31일, 2024-05-31, 2024_05_31\n",
    "        r'유효기간[_\\s]?(\\d{4})[년\\-_.]?(\\d{1,2})[월\\-_.]?(\\d{1,2})[일]?',  # 유효기간_20240531\n",
    "        r'expiry[_\\s]?(\\d{4})[년\\-_.]?(\\d{1,2})[월\\-_.]?(\\d{1,2})[일]?'  # expiry_20240531\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            try:\n",
    "                year = int(match.group(1))\n",
    "                month = int(match.group(2))\n",
    "                day = int(match.group(3))\n",
    "                \n",
    "                # 유효한 날짜인지 확인\n",
    "                if 2000 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                    return datetime(year, month, day)\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "def visualize_and_report(expiry_status):\n",
    "    \"\"\"결과 시각화 및 보고서 생성 함수\"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # 유효기간 상태를 데이터프레임으로 변환\n",
    "    if expiry_status and len(expiry_status) > 0:\n",
    "        df_expiry = pd.DataFrame(expiry_status)\n",
    "        \n",
    "        # 날짜 형식 변환 및 정렬\n",
    "        if 'expiry_date' in df_expiry.columns and df_expiry['expiry_date'].notna().any():\n",
    "            df_expiry['expiry_date'] = pd.to_datetime(df_expiry['expiry_date'])\n",
    "            df_expiry = df_expiry.sort_values(by='days_to_expiry')\n",
    "        \n",
    "        # 상태별 개수 통계\n",
    "        status_counts = df_expiry['status'].value_counts()\n",
    "        print(\"\\n=== 문서 상태 통계 ===\")\n",
    "        print(f\"만료됨: {status_counts.get('expired', 0)}개\")\n",
    "        print(f\"곧 만료됨(30일 이내): {status_counts.get('expiring_soon', 0)}개\")\n",
    "        print(f\"유효함: {status_counts.get('valid', 0)}개\")\n",
    "        print(f\"상태 알 수 없음: {status_counts.get('unknown', 0)}개\")\n",
    "    else:\n",
    "        df_expiry = pd.DataFrame(columns=['filename', 'expiry_date', 'days_to_expiry', 'status', 'confidence', 'source', 'context', 'has_compliance_stamp'])\n",
    "    \n",
    "    # 빈 유사도 데이터프레임 반환 (유사문서 분석 기능 제외)\n",
    "    df_similarity = pd.DataFrame()\n",
    "    \n",
    "    return df_expiry, df_similarity\n",
    "\n",
    "def load_documents(directory_path):\n",
    "    \"\"\"문서를 로드하고 전처리하는 함수\"\"\"\n",
    "    documents = []\n",
    "    filenames = []\n",
    "    file_contents = {}\n",
    "    filename_expiry_dates = {}\n",
    "    ext = file_path.suffix.lower()\n",
    "\n",
    "    # 파일 목록 수집\n",
    "    all_files = list(Path(directory_path).rglob('*'))\n",
    "    print(f\"파일 목록 수집 중...\")\n",
    "    \n",
    "    # 우선 처리해야 할 파일들 (문서 파일)\n",
    "    priority_extensions = ['.pdf', '.docx', '.doc', '.pptx', '.ppt', '.xlsx', '.xls', '.hwp']\n",
    "    priority_files = [f for f in all_files if f.suffix.lower() in priority_extensions]\n",
    "    other_files = [f for f in all_files if f.suffix.lower() not in priority_extensions]\n",
    "    \n",
    "    print(f\"우선 처리할 파일: {len(priority_files)}개\")\n",
    "    print(f\"일반 처리할 파일: {len(other_files)}개\")\n",
    "    \n",
    "    # 파일명에서 유효기간 정보 추출\n",
    "    for file_path in priority_files + other_files:\n",
    "        expiry_date = extract_expiry_date_from_filename(file_path.name)\n",
    "        if expiry_date:\n",
    "            filename_expiry_dates[file_path.name] = expiry_date\n",
    "    \n",
    "    print(f\"파일명에서 유효기간 정보 추출: {len(filename_expiry_dates)}개\")\n",
    "    \n",
    "    # 진행 상황 추적\n",
    "    processed_count = 0\n",
    "    success_count = 0\n",
    "    \n",
    "    # 문서 파일 처리\n",
    "    for file_path in priority_files:\n",
    "        processed_count += 1\n",
    "        \n",
    "        # 진행 상황 출력 (100개마다)\n",
    "        if processed_count % 100 == 0:\n",
    "            print(f\"처리 중... {processed_count}/{len(priority_files)} 파일 ({success_count} 성공)\")\n",
    "        \n",
    "        try:\n",
    "            content = \"\"\n",
    "            \n",
    "            # PDF 파일 처리\n",
    "            if file_path.suffix.lower() == '.pdf':\n",
    "                content = process_pdf_safely(file_path)\n",
    "            \n",
    "            # Word 문서 처리\n",
    "            if ext == '.docx':\n",
    "                try:\n",
    "                    import docx\n",
    "                    doc = docx.Document(file_path)\n",
    "                    \n",
    "                    # 문단 텍스트 추출\n",
    "                    paragraphs_text = []\n",
    "                    for para in doc.paragraphs:\n",
    "                        if para.text.strip():\n",
    "                            paragraphs_text.append(para.text)\n",
    "                    \n",
    "                    # 테이블 텍스트 추출 추가\n",
    "                    tables_text = []\n",
    "                    for table in doc.tables:\n",
    "                        for row in table.rows:\n",
    "                            row_text = []\n",
    "                            for cell in row.cells:\n",
    "                                if cell.text.strip():\n",
    "                                    row_text.append(cell.text)\n",
    "                            if row_text:\n",
    "                                tables_text.append(' | '.join(row_text))\n",
    "                    \n",
    "                    # 모든 텍스트 결합\n",
    "                    all_texts = paragraphs_text + tables_text\n",
    "                    content = \"\\n\".join(all_texts)\n",
    "                    \n",
    "                    # 디버깅\n",
    "                    print(f\"DOCX 처리: {len(all_texts)}개 텍스트 블록 추출됨\")\n",
    "                except Exception as e:\n",
    "                    print(f\"DOCX 처리 오류: {str(e)}\")\n",
    "                    content = \"\"\n",
    "            \n",
    "            # PowerPoint 파일 처리\n",
    "            elif file_path.suffix.lower() == '.pptx':\n",
    "                try:\n",
    "                    from pptx import Presentation\n",
    "                    prs = Presentation(file_path)\n",
    "                    for slide in prs.slides:\n",
    "                        for shape in slide.shapes:\n",
    "                            if hasattr(shape, \"text\"):\n",
    "                                content += shape.text + \"\\n\"\n",
    "                except ImportError:\n",
    "                    print(\"python-pptx 라이브러리가 필요합니다.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"PowerPoint 문서 처리 오류({file_path.name}): {type(e).__name__}\")\n",
    "            \n",
    "            # Excel 파일 처리\n",
    "            elif file_path.suffix.lower() in ['.xlsx', '.xls']:\n",
    "                try:\n",
    "                    import pandas as pd\n",
    "                    # 모든 시트 읽기\n",
    "                    sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "                    for sheet_name, df in sheets.items():\n",
    "                        content += f\"시트: {sheet_name}\\n\"\n",
    "                        content += df.to_string(index=False) + \"\\n\\n\"\n",
    "                except ImportError:\n",
    "                    print(\"pandas와 openpyxl 라이브러리가 필요합니다.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Excel 문서 처리 오류({file_path.name}): {type(e).__name__}\")\n",
    "            \n",
    "            # 내용이 있으면 추가\n",
    "            if content and content.strip():\n",
    "                documents.append(content)\n",
    "                filenames.append(file_path.name)\n",
    "                file_contents[file_path.name] = content\n",
    "                success_count += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"파일 처리 중 오류 발생({file_path.name}): {type(e).__name__}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"처리 완료: 총 {len(priority_files)}개 파일 중 {success_count}개 성공\")\n",
    "    return documents, filenames, file_contents, filename_expiry_dates\n",
    "\n",
    "def analyze_ibk_compliance_documents(directory_path, similarity_threshold=0.7):\n",
    "    \"\"\"IBK 준법감시 문서 분석 파이프라인\"\"\"\n",
    "    global updated_expiry_status\n",
    "    \n",
    "    print(\"IBK 준법감시 문서 분석을 시작합니다...\")\n",
    "    \n",
    "    # 1. 문서 로드 및 전처리 (수정된 함수 사용)\n",
    "    documents, filenames, file_contents, filename_expiry_dates = load_documents(directory_path)\n",
    "    \n",
    "    if not documents or len(documents) == 0:\n",
    "        print(\"분석할 문서가 없습니다.\")\n",
    "        return None, None\n",
    "    \n",
    "    # 2. 준법감시 정보 추출\n",
    "    extractor = IBKComplianceExtractor()\n",
    "    compliance_results = extractor.extract_compliance_info(documents, filenames)\n",
    "    \n",
    "    if not compliance_results or len(compliance_results) == 0:\n",
    "        print(\"준법감시 정보를 추출할 수 없습니다.\")\n",
    "        return None, None\n",
    "        \n",
    "    print(\"준법감시 정보 추출을 완료했습니다.\")\n",
    "    \n",
    "    # 3. 유효기간 분석\n",
    "    analyzer = ExpiryAnalyzer()\n",
    "    expiry_status = analyzer.analyze_expiry_status(compliance_results)\n",
    "    print(\"유효기간 분석을 완료했습니다.\")\n",
    "    \n",
    "    # 3.1 파일명 기반 유효기간 정보 추가 (새로 추가)\n",
    "    enhanced_expiry_status = []\n",
    "    for status in expiry_status:\n",
    "        # 파일명에서 추출한 유효기간 정보가 있으면 활용\n",
    "        if status['filename'] in filename_expiry_dates:\n",
    "            # 문서 내용에서 추출한 정보가 없거나 신뢰도가 낮은 경우\n",
    "            if status['status'] == 'unknown' or status['confidence'] < 0.5:\n",
    "                expiry_date = filename_expiry_dates[status['filename']]\n",
    "                days_to_expiry = (expiry_date - datetime.now()).days\n",
    "                \n",
    "                if days_to_expiry < 0:\n",
    "                    new_status = 'expired'\n",
    "                elif days_to_expiry <= 30:\n",
    "                    new_status = 'expiring_soon'\n",
    "                else:\n",
    "                    new_status = 'valid'\n",
    "                \n",
    "                enhanced_status = {\n",
    "                    'filename': status['filename'],\n",
    "                    'expiry_date': expiry_date,\n",
    "                    'days_to_expiry': days_to_expiry,\n",
    "                    'confidence': 0.8,  # 파일명 기반은 높은 신뢰도 부여\n",
    "                    'source': '파일명에서 추출',\n",
    "                    'context': f'파일명: {status[\"filename\"]}',\n",
    "                    'status': new_status,\n",
    "                    'has_compliance_stamp': status.get('has_compliance_stamp', False)  # 준법감사필 여부 유지\n",
    "                }\n",
    "                enhanced_expiry_status.append(enhanced_status)\n",
    "            else:\n",
    "                enhanced_expiry_status.append(status)\n",
    "        else:\n",
    "            enhanced_expiry_status.append(status)\n",
    "    \n",
    "    print(f\"파일명 기반 유효기간 정보 추가: {len(filename_expiry_dates)}개\")\n",
    "    \n",
    "    # enhanced_expiry_status를 updated_expiry_status로 복사\n",
    "    updated_expiry_status = enhanced_expiry_status.copy()\n",
    "    \n",
    "    # 4. 결과 시각화 및 보고서 생성 (유사 문서 분석 제외)\n",
    "    df_expiry, df_similarity = visualize_and_report(updated_expiry_status)\n",
    "    print(\"결과 시각화 및 보고서 생성을 완료했습니다.\")\n",
    "    \n",
    "    # 결과를 데이터프레임 형태로 반환\n",
    "    return df_expiry, df_similarity\n",
    "\n",
    "# IBKComplianceExtractor 클래스 - 준법감사필 문구 확인에 초점\n",
    "class IBKComplianceExtractor:\n",
    "    def extract_compliance_info(self, documents, filenames):\n",
    "        \"\"\"문서에서 준법감시 정보 추출\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # 준법감사필 관련 키워드\n",
    "        compliance_keywords = [\n",
    "            '준법감사필', '준법감시필', '준법심사필', '준법검토필', \n",
    "            '준법감사', '준법감시', '준법심사', '준법검토',\n",
    "            '법무감사', '법무검토', '법무심사'\n",
    "        ]\n",
    "        \n",
    "        for doc, filename in zip(documents, filenames):\n",
    "            # 준법감사필 여부 확인\n",
    "            has_compliance_stamp = any(keyword in doc for keyword in compliance_keywords)\n",
    "            \n",
    "            result = {\n",
    "                'filename': filename,\n",
    "                'content': doc[:1000],  # 내용 일부만 저장 (분석용)\n",
    "                'has_compliance_stamp': has_compliance_stamp\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "        # 준법감사필 있는 문서 통계\n",
    "        compliant_docs = sum(1 for r in results if r['has_compliance_stamp'])\n",
    "        print(f\"준법감사필 포함 문서: {compliant_docs}개 / 전체 {len(results)}개 ({(compliant_docs/len(results)*100 if len(results) > 0 else 0):.1f}%)\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# ExpiryAnalyzer 클래스 - 유효기간 확인에 초점\n",
    "class ExpiryAnalyzer:\n",
    "    def analyze_expiry_status(self, compliance_results):\n",
    "        \"\"\"준법감시 문서의 유효기간 분석\"\"\"\n",
    "        from datetime import datetime\n",
    "        import re\n",
    "        \n",
    "        expiry_statuses = []\n",
    "        \n",
    "        for result in compliance_results:\n",
    "            filename = result['filename']\n",
    "            content = result.get('content', '')\n",
    "            has_compliance_stamp = result.get('has_compliance_stamp', False)\n",
    "            \n",
    "            # 유효기간 패턴 추출\n",
    "            expiry_date = self._extract_expiry_date(content)\n",
    "            \n",
    "            if expiry_date:\n",
    "                days_to_expiry = (expiry_date - datetime.now()).days\n",
    "                \n",
    "                if days_to_expiry < 0:\n",
    "                    status = 'expired'\n",
    "                elif days_to_expiry <= 30:\n",
    "                    status = 'expiring_soon'\n",
    "                else:\n",
    "                    status = 'valid'\n",
    "                \n",
    "                # 준법감사필이 있으면 신뢰도 증가\n",
    "                confidence = 0.8 if has_compliance_stamp else 0.6\n",
    "                \n",
    "                expiry_statuses.append({\n",
    "                    'filename': filename,\n",
    "                    'expiry_date': expiry_date,\n",
    "                    'days_to_expiry': days_to_expiry,\n",
    "                    'status': status,\n",
    "                    'confidence': confidence,\n",
    "                    'source': '문서 내용에서 추출',\n",
    "                    'context': self._get_context(content, expiry_date),\n",
    "                    'has_compliance_stamp': has_compliance_stamp\n",
    "                })\n",
    "            else:\n",
    "                expiry_statuses.append({\n",
    "                    'filename': filename,\n",
    "                    'expiry_date': None,\n",
    "                    'days_to_expiry': None,\n",
    "                    'status': 'unknown',\n",
    "                    'confidence': 0.0,\n",
    "                    'source': '정보 없음',\n",
    "                    'context': '유효기간 정보를 찾을 수 없습니다.',\n",
    "                    'has_compliance_stamp': has_compliance_stamp\n",
    "                })\n",
    "        \n",
    "        return expiry_statuses\n",
    "    \n",
    "    def _extract_expiry_date(self, text):\n",
    "        \"\"\"텍스트에서 유효기간 날짜 추출\"\"\"\n",
    "        from datetime import datetime\n",
    "        import re\n",
    "        \n",
    "        # 다양한 유효기간 패턴 처리\n",
    "        patterns = [\n",
    "            r'유효기간[:\\s]*(\\d{4})[년\\-/]?(\\d{1,2})[월\\-/]?(\\d{1,2})일?',\n",
    "            r'만료일[:\\s]*(\\d{4})[년\\-/]?(\\d{1,2})[월\\-/]?(\\d{1,2})일?',\n",
    "            r'효력기간[:\\s]*~\\s*(\\d{4})[년\\-/]?(\\d{1,2})[월\\-/]?(\\d{1,2})일?',\n",
    "            r'(\\d{4})[년\\-/]?(\\d{1,2})[월\\-/]?(\\d{1,2})일?까지\\s*유효',\n",
    "            r'(\\d{4})[년\\-/]?(\\d{1,2})[월\\-/]?(\\d{1,2})일?까지',\n",
    "            r'(\\d{4})[년\\-/]?(\\d{1,2})[월\\-/]?(\\d{1,2})일?\\s*만료',\n",
    "            r'준법감사필\\s*[\\(\\［].*?(\\d{4})[년\\-/]?(\\d{1,2})[월\\-/]?(\\d{1,2})일?.*?[\\)\\］]'\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            matches = re.finditer(pattern, text)\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    year = int(match.group(1))\n",
    "                    month = int(match.group(2))\n",
    "                    day = int(match.group(3))\n",
    "                    \n",
    "                    # 유효한 날짜인지 확인\n",
    "                    if 2000 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                        return datetime(year, month, day)\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _get_context(self, text, expiry_date):\n",
    "        \"\"\"유효기간 정보가 포함된 문맥 추출\"\"\"\n",
    "        import re\n",
    "        \n",
    "        # 유효기간과 관련된 문맥 패턴들\n",
    "        context_patterns = [\n",
    "            r'([^.!?]*유효기간[^.!?]*)',\n",
    "            r'([^.!?]*만료일[^.!?]*)',\n",
    "            r'([^.!?]*효력기간[^.!?]*)',\n",
    "            r'([^.!?]*까지\\s*유효[^.!?]*)',\n",
    "            r'([^.!?]*준법감사필[^.!?]*)'\n",
    "        ]\n",
    "        \n",
    "        formatted_date = expiry_date.strftime(\"%Y년 %m월 %d일\")\n",
    "        \n",
    "        # 모든 패턴에 대해 시도\n",
    "        for pattern in context_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                context = match.group(1).strip()\n",
    "                if len(context) > 10:  # 최소 길이 확인\n",
    "                    return context\n",
    "        \n",
    "        # 특정 문맥을 찾지 못한 경우 기본값 반환\n",
    "        return f\"유효기간: {formatted_date}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7bdb11",
   "metadata": {},
   "source": [
    "#12.결과 데이터프레임 생성 및 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387bf838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result_dataframe(df_expiry):\n",
    "    \"\"\"분석 결과를 정리된 데이터프레임으로 변환\"\"\"\n",
    "    if df_expiry is None or len(df_expiry) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 상태 한글 표현 매핑\n",
    "    status_mapping = {\n",
    "        'valid': '유효함',\n",
    "        'expiring_soon': '30일 이내 만료',\n",
    "        'expired': '만료됨',\n",
    "        'unknown': '상태 불명'\n",
    "    }\n",
    "    \n",
    "    # 필요한 열만 선택하고 정렬\n",
    "    result_df = df_expiry.copy()\n",
    "    \n",
    "    # 상태 한글화\n",
    "    result_df['상태'] = result_df['status'].map(status_mapping)\n",
    "    \n",
    "    # 날짜 형식 변환\n",
    "    result_df['만료일'] = result_df['expiry_date'].apply(\n",
    "        lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else '알 수 없음'\n",
    "    )\n",
    "    \n",
    "    # 남은 일수 형식 변환\n",
    "    result_df['남은_일수'] = result_df['days_to_expiry'].apply(\n",
    "        lambda x: f\"{x}일\" if pd.notnull(x) else '알 수 없음'\n",
    "    )\n",
    "    \n",
    "    # 신뢰도 백분율 표현\n",
    "    result_df['신뢰도'] = result_df['confidence'].apply(\n",
    "        lambda x: f\"{x*100:.1f}%\" if pd.notnull(x) else '0%'\n",
    "    )\n",
    "    \n",
    "    # 열 재구성\n",
    "    columns = {\n",
    "        'filename': '파일명',\n",
    "        '상태': '상태',\n",
    "        '만료일': '만료일',\n",
    "        '남은_일수': '남은 일수',\n",
    "        '신뢰도': '신뢰도',\n",
    "        'source': '정보 출처',\n",
    "        'context': '컨텍스트'\n",
    "    }\n",
    "    \n",
    "    result_df = result_df.rename(columns=columns)\n",
    "    result_df = result_df[list(columns.values())]\n",
    "    \n",
    "    # 상태별 정렬\n",
    "    status_order = ['만료됨', '30일 이내 만료', '유효함', '상태 불명']\n",
    "    result_df['상태_순서'] = result_df['상태'].apply(lambda x: status_order.index(x))\n",
    "    result_df = result_df.sort_values(['상태_순서', '만료일']).drop('상태_순서', axis=1)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0edde6",
   "metadata": {},
   "source": [
    "#13. 메인 실행함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf5a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents_in_batches(file_paths, batch_size=50, max_workers=8):\n",
    "    \"\"\"파일 배치 처리 및 병렬화 - 메모리 효율성 개선\"\"\"\n",
    "    import concurrent.futures\n",
    "    import math\n",
    "    from tqdm.notebook import tqdm\n",
    "    \n",
    "    # 배치로 나누기\n",
    "    batches = [file_paths[i:i+batch_size] for i in range(0, len(file_paths), batch_size)]\n",
    "    total_batches = len(batches)\n",
    "    \n",
    "    all_results = []\n",
    "    extractor = EnhancedComplianceExtractor(\n",
    "        api_key=api_key,\n",
    "        use_ngram=True,\n",
    "        use_ai=True\n",
    "    )\n",
    "    \n",
    "    print(f\"총 {len(file_paths)}개 파일을 {total_batches}개 배치로 처리합니다.\")\n",
    "    \n",
    "    # 각 배치 처리\n",
    "    for batch_idx, batch in enumerate(batches):\n",
    "        print(f\"\\n배치 {batch_idx+1}/{total_batches} 처리 중 ({len(batch)}개 파일)...\")\n",
    "        batch_results = []\n",
    "        \n",
    "        # 병렬 처리 함수\n",
    "        def process_file(file_path):\n",
    "            try:\n",
    "                # 파일 읽기\n",
    "                content = read_file_content(file_path)\n",
    "                \n",
    "                if not content:\n",
    "                    return {\n",
    "                        \"filename\": file_path.name,\n",
    "                        \"status\": \"상태 불명\",\n",
    "                        \"expiry_date\": None,\n",
    "                        \"days_left\": None,\n",
    "                        \"compliance_number\": None,\n",
    "                        \"confidence\": 0.0,\n",
    "                        \"error\": \"파일 내용 없음\"\n",
    "                    }\n",
    "                \n",
    "                # 문서 분석\n",
    "                result = extractor.extract_compliance_info(content)\n",
    "                \n",
    "                # 파일명에서도 정보 추출\n",
    "                filename_info = extract_info_from_filename(file_path.name)\n",
    "                \n",
    "                # 결과 통합\n",
    "                combined_result = combine_file_results(\n",
    "                    filename=file_path.name,\n",
    "                    content_result=result,\n",
    "                    filename_result=filename_info\n",
    "                )\n",
    "                \n",
    "                return combined_result\n",
    "                \n",
    "            except Exception as e:\n",
    "                return {\n",
    "                    \"filename\": file_path.name,\n",
    "                    \"status\": \"오류\",\n",
    "                    \"expiry_date\": None,\n",
    "                    \"days_left\": None,\n",
    "                    \"compliance_number\": None,\n",
    "                    \"confidence\": 0.0,\n",
    "                    \"error\": str(e)\n",
    "                }\n",
    "        \n",
    "        # 병렬 실행\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_file = {executor.submit(process_file, file_path): file_path for file_path in batch}\n",
    "            \n",
    "            for future in tqdm(concurrent.futures.as_completed(future_to_file), \n",
    "                               total=len(batch), \n",
    "                               desc=f\"배치 {batch_idx+1} 처리\"):\n",
    "                file_path = future_to_file[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    batch_results.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"파일 {file_path.name} 처리 중 오류: {str(e)}\")\n",
    "        \n",
    "        # 배치 결과 저장\n",
    "        all_results.extend(batch_results)\n",
    "        \n",
    "        # 중간 저장\n",
    "        #if batch_idx % 2 == 1 or batch_idx == total_batches - 1:\n",
    "        #    save_interim_results(all_results, batch_idx)\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76cf708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계층적 하이브리드 방식 적용 - 준법감시필 번호 및 유효기간 추출\n",
    "try:\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import time\n",
    "    import traceback\n",
    "    from tqdm.notebook import tqdm\n",
    "    import gc\n",
    "    import concurrent.futures\n",
    "    import openpyxl  # 명시적으로 openpyxl 추가\n",
    "    from openpyxl.styles import Font, PatternFill  # 스타일 관련 모듈도 추가\n",
    "    from openpyxl.formatting.rule import CellIsRule  # 조건부 서식을 위한 모듈\n",
    "    from openpyxl.utils import get_column_letter  # 열 문자 변환 유틸리티\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 현재 디렉토리 확인\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"현재 디렉토리: {current_dir}\")\n",
    "    base_path = Path(current_dir)\n",
    "    \n",
    "    # 오류 날짜 목록 - 이 날짜들은 검사에서 제외됩니다\n",
    "    ERROR_DATES = ['2024-11-30', '2020-12-31']\n",
    "    \n",
    "    # 디버깅 모드 활성화\n",
    "    DEBUG_MODE = True\n",
    "    DEBUG_FILE = \"debug_log.txt\"\n",
    "    \n",
    "    # 디버깅 로그 함수\n",
    "    def log_debug(message):\n",
    "        if DEBUG_MODE:\n",
    "            with open(DEBUG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}\\n\")\n",
    "                \n",
    "    # 디버그 로그 파일 초기화\n",
    "    with open(DEBUG_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"=== 디버그 로그 시작: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\\n\")\n",
    "    \n",
    "    class AIEnhancedComplianceExtractor:\n",
    "        def __init__(self, api_key=None, use_ngram=True, use_ai=False):\n",
    "            self.api_key = api_key\n",
    "            self.use_ngram = use_ngram\n",
    "            self.use_ai = use_ai\n",
    "            \n",
    "            # N-gram 관련 설정\n",
    "            self.ngram_sizes = [2, 3, 4]  # 2-gram, 3-gram, 4-gram 사용\n",
    "            \n",
    "            # 키워드 설정\n",
    "            self.compliance_keywords = [\n",
    "                '준법감시', '준법감시인', '준법감사', '심의필', '제호', \n",
    "                '승인', '결재', '법규', '컴플라이언스'\n",
    "            ]\n",
    "            \n",
    "            self.validity_keywords = [\n",
    "                '유효기간', '만료일', '유효', '만료', '기간', \n",
    "                '까지', '효력', '사용기한'\n",
    "            ]\n",
    "        \n",
    "        def extract_ngrams(self, text):\n",
    "            \"\"\"텍스트에서 n-gram 추출\"\"\"\n",
    "            import re\n",
    "            from collections import Counter\n",
    "            \n",
    "            # 텍스트 전처리 (특수문자 제거 및 공백 정규화)\n",
    "            cleaned_text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "            cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "            \n",
    "            # 단어 목록 생성\n",
    "            words = cleaned_text.split()\n",
    "            \n",
    "            # n-gram 생성\n",
    "            all_ngrams = []\n",
    "            \n",
    "            for n in self.ngram_sizes:\n",
    "                if len(words) < n:\n",
    "                    continue\n",
    "                    \n",
    "                ngrams = [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "                all_ngrams.extend(ngrams)\n",
    "            \n",
    "            # n-gram 빈도 계산\n",
    "            ngram_freq = Counter(all_ngrams)\n",
    "            \n",
    "            return ngram_freq\n",
    "            \n",
    "        def score_text_for_compliance(self, text):\n",
    "            \"\"\"N-gram 기반 준법감시 관련 텍스트 점수 계산\"\"\"\n",
    "            score = 0\n",
    "            \n",
    "            # 키워드 기반 점수 계산\n",
    "            for keyword in self.compliance_keywords:\n",
    "                if keyword in text:\n",
    "                    score += 5  # 기본 키워드 발견 시 5점\n",
    "                    \n",
    "            for keyword in self.validity_keywords:\n",
    "                if keyword in text:\n",
    "                    score += 5  # 유효기간 키워드 발견 시 5점\n",
    "            \n",
    "            # N-gram 기반 점수 계산\n",
    "            if self.use_ngram:\n",
    "                ngrams = self.extract_ngrams(text)\n",
    "                \n",
    "                # N-gram에 키워드가 포함된 경우 점수 추가\n",
    "                for ngram, freq in ngrams.items():\n",
    "                    compliance_matches = sum(1 for keyword in self.compliance_keywords if keyword in ngram)\n",
    "                    validity_matches = sum(1 for keyword in self.validity_keywords if keyword in ngram)\n",
    "                    \n",
    "                    score += compliance_matches * 2 * freq  # 준법 키워드 포함 n-gram당 2점\n",
    "                    score += validity_matches * 2 * freq    # 유효기간 키워드 포함 n-gram당 2점\n",
    "            \n",
    "            return score\n",
    "            \n",
    "        def find_best_sections(self, text, window_size=200, step_size=100):\n",
    "            \"\"\"준법감시 관련 최적 섹션 찾기\"\"\"\n",
    "            if len(text) <= window_size:\n",
    "                return [text]\n",
    "                \n",
    "            # 텍스트를 섹션으로 분할\n",
    "            sections = []\n",
    "            for i in range(0, len(text) - window_size + 1, step_size):\n",
    "                section = text[i:i+window_size]\n",
    "                sections.append(section)\n",
    "            \n",
    "            # 각 섹션 점수 계산\n",
    "            section_scores = [(section, self.score_text_for_compliance(section)) for section in sections]\n",
    "            \n",
    "            # 점수 기준 정렬\n",
    "            section_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # 상위 5개 섹션 반환\n",
    "            top_sections = [section for section, score in section_scores[:5]]\n",
    "            \n",
    "            return top_sections\n",
    "        \n",
    "        def extract_with_regex(self, text):\n",
    "            \"\"\"정규식으로 준법감시 정보 추출\"\"\"\n",
    "            log_debug(\"정규식으로 준법감시 정보 추출 시작\")\n",
    "            result = {\"compliance_number\": None, \"expiry_date\": None}\n",
    "            \n",
    "            # 준법감시필 번호 추출\n",
    "            compliance_patterns = [\n",
    "                r'제(\\d{4})-(\\d+)호',  # 제2024-4806호\n",
    "                r'준법감시[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)',  # 준법감시-2024-123\n",
    "                r'심의필[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)',    # 심의필-2024-123\n",
    "                r'준법[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)'       # 준법-2024-123\n",
    "            ]\n",
    "            \n",
    "            for pattern in compliance_patterns:\n",
    "                match = re.search(pattern, text)\n",
    "                if match:\n",
    "                    try:\n",
    "                        year, number = match.groups()\n",
    "                        \n",
    "                        # 형식에 따라 준법감시필 번호 생성\n",
    "                        if pattern.startswith(r'제'):\n",
    "                            result[\"compliance_number\"] = f\"제{year}-{number}호\"\n",
    "                        elif pattern.startswith(r'준법감시'):\n",
    "                            result[\"compliance_number\"] = f\"준법감시-{year}-{number}\"\n",
    "                        elif pattern.startswith(r'심의필'):\n",
    "                            result[\"compliance_number\"] = f\"심의필-{year}-{number}\"\n",
    "                        else:\n",
    "                            result[\"compliance_number\"] = f\"준법-{year}-{number}\"\n",
    "                        \n",
    "                        log_debug(f\"정규식으로 준법감시필 번호 추출: {result['compliance_number']}\")\n",
    "                        break\n",
    "                    except:\n",
    "                        continue\n",
    "            \n",
    "            # 유효기간 추출\n",
    "            expiry_patterns = [\n",
    "                r'유효기간[^\\d]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?',  # 유효기간: 2025.08.20\n",
    "                r'만료일[^\\d]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?',   # 만료일: 2025.08.20\n",
    "                r'(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?[^\\d]*까지',  # 2025.08.20까지\n",
    "                r'(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?[^\\d]*만료',  # 2025.08.20 만료\n",
    "                r'유효[^\\d]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?'   # 유효: 2025.08.20\n",
    "            ]\n",
    "            \n",
    "            for pattern in expiry_patterns:\n",
    "                match = re.search(pattern, text)\n",
    "                if match:\n",
    "                    try:\n",
    "                        year, month, day = map(int, match.groups())\n",
    "                        if 2000 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                            date_str = f\"{year}-{month:02d}-{day:02d}\"\n",
    "                            \n",
    "                            # 오류 날짜 필터링\n",
    "                            if date_str in ERROR_DATES:\n",
    "                                log_debug(f\"오류 날짜 감지: {date_str}\")\n",
    "                                continue\n",
    "                            \n",
    "                            result[\"expiry_date\"] = date_str\n",
    "                            log_debug(f\"정규식으로 유효기간 추출: {date_str}\")\n",
    "                            break\n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "            return result\n",
    "        \n",
    "        def process_document(self, content):\n",
    "            \"\"\"문서 내용에서 준법감시필 번호와 유효기간 추출\"\"\"\n",
    "            log_debug(\"문서 내용 분석 시작\")\n",
    "            \n",
    "            # 기본 결과 초기화\n",
    "            result = {\"compliance_number\": None, \"expiry_date\": None}\n",
    "            \n",
    "            # 1. 관련성 높은 섹션 찾기\n",
    "            if len(content) > 1000:  # 긴 문서는 섹션으로 나누어 처리\n",
    "                log_debug(f\"긴 문서 감지: {len(content)} 자\")\n",
    "                sections = self.find_best_sections(content)\n",
    "                log_debug(f\"관련 섹션 {len(sections)}개 발견\")\n",
    "                \n",
    "                # 각 섹션에서 정보 추출\n",
    "                for section in sections:\n",
    "                    section_result = self.extract_with_regex(section)\n",
    "                    \n",
    "                    # 결과 통합\n",
    "                    if section_result[\"compliance_number\"] and not result[\"compliance_number\"]:\n",
    "                        result[\"compliance_number\"] = section_result[\"compliance_number\"]\n",
    "                        \n",
    "                    if section_result[\"expiry_date\"] and not result[\"expiry_date\"]:\n",
    "                        result[\"expiry_date\"] = section_result[\"expiry_date\"]\n",
    "                        \n",
    "                    # 모든 정보를 찾았으면 종료\n",
    "                    if result[\"compliance_number\"] and result[\"expiry_date\"]:\n",
    "                        break\n",
    "            else:\n",
    "                # 짧은 문서는 전체 분석\n",
    "                result = self.extract_with_regex(content)\n",
    "            \n",
    "            # AI 분석 (사용 설정된 경우)\n",
    "            if self.use_ai and self.api_key:\n",
    "                try:\n",
    "                    # 간단한 API 호출 구현 (실제 API 키가 없으므로 주석 처리)\n",
    "                    # ai_result = self.call_ai_api(content)\n",
    "                    # if ai_result:\n",
    "                    #     if ai_result.get(\"compliance_number\") and not result[\"compliance_number\"]:\n",
    "                    #         result[\"compliance_number\"] = ai_result[\"compliance_number\"]\n",
    "                    #     if ai_result.get(\"expiry_date\") and not result[\"expiry_date\"]:\n",
    "                    #         result[\"expiry_date\"] = ai_result[\"expiry_date\"]\n",
    "                    pass\n",
    "                except:\n",
    "                    log_debug(\"AI 분석 중 오류 발생\")\n",
    "            \n",
    "            log_debug(f\"문서 내용 분석 결과: {result}\")\n",
    "            return result\n",
    "    \n",
    "    # 파일명에서 유효기간 추출 함수 강화\n",
    "    def extract_expiry_date(filename):\n",
    "        \"\"\"파일명에서 유효기간을 추출하되, 오류 날짜는 필터링\"\"\"\n",
    "        log_debug(f\"파일명 분석 시작: {filename}\")\n",
    "        \n",
    "        expiry_date = None\n",
    "        expiry_patterns = [\n",
    "            r'유효기간\\((\\d{4})\\.(\\d{2})\\.(\\d{2})\\)',  # 유효기간(2025.08.20)\n",
    "            r'유효기간\\((\\d{4})-(\\d{2})-(\\d{2})\\)',   # 유효기간(2025-08-20)\n",
    "            r'유효기간\\((\\d{4})(\\d{2})(\\d{2})\\)',     # 유효기간(20250820)\n",
    "            r'유효기간[_\\s](\\d{4})[\\.\\-](\\d{2})[\\.\\-](\\d{2})',  # 유효기간_2025.08.20\n",
    "            r'(\\d{4})[\\.\\-](\\d{2})[\\.\\-](\\d{2})[_\\s]유효기간',  # 2025.08.20_유효기간\n",
    "            r'제\\d{4}-\\d+호\\([^)]+\\)\\s*유효기간\\((\\d{4})[\\.\\-](\\d{2})[\\.\\-](\\d{2})\\)'  # 제2024-4806호(날짜) 유효기간(2025.08.20)\n",
    "        ]\n",
    "        \n",
    "        # 각 패턴에 대해 개별 시도\n",
    "        for i, pattern in enumerate(expiry_patterns):\n",
    "            match = re.search(pattern, filename)\n",
    "            if match:\n",
    "                try:\n",
    "                    groups = match.groups()\n",
    "                    log_debug(f\"패턴 {i+1} 매치: {pattern} -> {groups}\")\n",
    "                    \n",
    "                    year, month, day = map(int, groups)\n",
    "                    if 2000 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                        date_str = f\"{year}-{month:02d}-{day:02d}\"\n",
    "                        \n",
    "                        # 오류 날짜 필터링\n",
    "                        if date_str in ERROR_DATES:\n",
    "                            log_debug(f\"오류 날짜 감지: {date_str}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # 성공한 패턴/날짜 로깅    \n",
    "                        log_debug(f\"유효기간 추출 성공: {date_str} (패턴 {i+1})\")\n",
    "                        expiry_date = date_str\n",
    "                        break\n",
    "                    else:\n",
    "                        log_debug(f\"유효하지 않은 날짜 값: {year}-{month}-{day}\")\n",
    "                except Exception as e:\n",
    "                    log_debug(f\"날짜 추출 오류: {pattern} -> {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        # 추출 실패 시 확장 패턴 시도 (날짜 형식이 다른 경우)\n",
    "        if expiry_date is None:\n",
    "            log_debug(\"기본 패턴 매치 실패, 확장 패턴 시도\")\n",
    "            extended_patterns = [\n",
    "                r'유효기간[:\\s]*([12]\\d{3})[년\\.\\-]?([01]?\\d)[월\\.\\-]?([0-3]?\\d)[일]?',  # 유효기간: 2025년6월3일\n",
    "                r'([12]\\d{3})년?[^0-9]+([01]?\\d)월?[^0-9]+([0-3]?\\d)일?[^0-9]*유효',  # 2025년 6월 3일 유효\n",
    "                r'유효[^0-9]*([12]\\d{3})년?[^0-9]+([01]?\\d)월?[^0-9]+([0-3]?\\d)일?'   # 유효 2025년 6월 3일\n",
    "            ]\n",
    "            \n",
    "            for i, pattern in enumerate(extended_patterns):\n",
    "                match = re.search(pattern, filename)\n",
    "                if match:\n",
    "                    try:\n",
    "                        groups = match.groups()\n",
    "                        log_debug(f\"확장 패턴 {i+1} 매치: {pattern} -> {groups}\")\n",
    "                        \n",
    "                        year, month, day = map(int, groups)\n",
    "                        if 2000 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                            date_str = f\"{year}-{month:02d}-{day:02d}\"\n",
    "                            \n",
    "                            if date_str in ERROR_DATES:\n",
    "                                log_debug(f\"오류 날짜 감지: {date_str}\")\n",
    "                                continue\n",
    "                                \n",
    "                            log_debug(f\"확장 패턴으로 유효기간 추출 성공: {date_str}\")\n",
    "                            expiry_date = date_str\n",
    "                            break\n",
    "                        else:\n",
    "                            log_debug(f\"유효하지 않은 날짜 값: {year}-{month}-{day}\")\n",
    "                    except Exception as e:\n",
    "                        log_debug(f\"확장 패턴 날짜 추출 오류: {str(e)}\")\n",
    "                        continue\n",
    "        \n",
    "        if expiry_date is None:\n",
    "            log_debug(f\"파일명에서 유효기간 추출 실패: {filename}\")\n",
    "        \n",
    "        return expiry_date\n",
    "    \n",
    "    # 파일명에서 준법감시필 번호 추출 함수 강화\n",
    "    def extract_compliance_number(filename):\n",
    "        \"\"\"파일명에서 준법감시필 번호 추출\"\"\"\n",
    "        log_debug(f\"준법감시필 번호 추출 시작: {filename}\")\n",
    "        \n",
    "        compliance_patterns = [\n",
    "            r'제(\\d{4})-(\\d+)호',  # 제2024-4806호\n",
    "            r'준법감시[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)',  # 준법감시-2024-123\n",
    "            r'심의필[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)',    # 심의필-2024-123\n",
    "            r'준법[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)'       # 준법-2024-123\n",
    "        ]\n",
    "        \n",
    "        for i, pattern in enumerate(compliance_patterns):\n",
    "            match = re.search(pattern, filename)\n",
    "            if match:\n",
    "                try:\n",
    "                    year, number = match.groups()\n",
    "                    \n",
    "                    # 형식에 따라 준법감시필 번호 생성\n",
    "                    if pattern.startswith(r'제'):\n",
    "                        compliance_number = f\"제{year}-{number}호\"\n",
    "                    elif pattern.startswith(r'준법감시'):\n",
    "                        compliance_number = f\"준법감시-{year}-{number}\"\n",
    "                    elif pattern.startswith(r'심의필'):\n",
    "                        compliance_number = f\"심의필-{year}-{number}\"\n",
    "                    else:\n",
    "                        compliance_number = f\"준법-{year}-{number}\"\n",
    "                    \n",
    "                    log_debug(f\"준법감시필 번호 추출 성공: {compliance_number} (패턴 {i+1})\")\n",
    "                    return compliance_number\n",
    "                except Exception as e:\n",
    "                    log_debug(f\"준법감시필 번호 추출 오류: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        log_debug(f\"파일명에서 준법감시필 번호 추출 실패: {filename}\")\n",
    "        return None\n",
    "    \n",
    "    # AI 및 N-gram을 활용한 파일 분석 함수 - 강화된 버전\n",
    "    def analyze_file(file_path):\n",
    "        \"\"\"파일 정보를 분석하여 결과 딕셔너리 반환 - 강화된 버전\"\"\"\n",
    "        try:\n",
    "            filename = file_path.name\n",
    "            file_index = target_files.index(file_path) if file_path in target_files else -1\n",
    "            \n",
    "            # 파일 순번 로깅\n",
    "            log_debug(f\"{'='*50}\")\n",
    "            log_debug(f\"파일 분석 시작 [{file_index+1}/{len(target_files)}]: {filename}\")\n",
    "            \n",
    "            # 파일명에서 유효기간 추출\n",
    "            expiry_date = extract_expiry_date(filename)\n",
    "            \n",
    "            # 파일명에서 준법감시필 번호 추출\n",
    "            compliance_number = extract_compliance_number(filename)\n",
    "            \n",
    "            # 파일명에서 유효기간 상태 결정\n",
    "            filename_days_to_expiry = None\n",
    "            filename_status = '상태 불명'\n",
    "            \n",
    "            if expiry_date:\n",
    "                today = datetime.now().date()\n",
    "                try:\n",
    "                    expiry_date_obj = datetime.strptime(expiry_date, '%Y-%m-%d').date()\n",
    "                    filename_days_to_expiry = (expiry_date_obj - today).days\n",
    "                    \n",
    "                    if filename_days_to_expiry < 0:\n",
    "                        filename_status = '만료됨'\n",
    "                    elif filename_days_to_expiry <= 30:\n",
    "                        filename_status = '30일 이내 만료'\n",
    "                    else:\n",
    "                        filename_status = '유효함'\n",
    "                    \n",
    "                    log_debug(f\"유효기간 상태: {filename_status} (남은 일수: {filename_days_to_expiry})\")\n",
    "                except:\n",
    "                    log_debug(f\"유효기간 상태 계산 오류\")\n",
    "            \n",
    "            # 파일 내용 확인 변수 초기화\n",
    "            compliance_info = None\n",
    "            content_date = None\n",
    "            content_days_to_expiry = None\n",
    "            content_status = '상태 불명'\n",
    "            \n",
    "            # 여기서 파일 확장자 변수를 정의 (이 부분이 누락됨)\n",
    "            ext = file_path.suffix.lower()  # 수정: 확장자 변수 정의\n",
    "            content = \"\"\n",
    "            \n",
    "            # 파일 크기 확인\n",
    "            try:\n",
    "                file_size = file_path.stat().st_size\n",
    "                is_large_file = file_size > 200 * 1024 * 1024  # 20MB 초과는 대용량\n",
    "                if is_large_file:\n",
    "                    log_debug(f\"대용량 파일 감지: {file_size/(1024*1024):.2f}MB - 내용 분석 스킵\")\n",
    "                    # 대용량 파일은 분석하지 않음\n",
    "                    return {\n",
    "                        '파일명': filename,\n",
    "                        '상태': filename_status if expiry_date else '상태 불명',\n",
    "                        '만료일': expiry_date or '알 수 없음',\n",
    "                        '남은 일수': filename_days_to_expiry,\n",
    "                        '파일명_준법감시필': compliance_number,\n",
    "                        '파일명_유효기간': expiry_date,\n",
    "                        '파일명_유효기간_상태': filename_status if expiry_date else '정보 없음',\n",
    "                        '파일명_남은일수': filename_days_to_expiry,\n",
    "                        '파일내_준법감시필_번호': None,\n",
    "                        '파일내_유효기간_날짜': None,\n",
    "                        '파일내_유효기간_상태': '정보 없음',\n",
    "                        '파일내_남은일수': None,\n",
    "                        '파일경로': str(file_path.parent),\n",
    "                        '파일인덱스': file_index + 1\n",
    "                    }\n",
    "            except:\n",
    "                log_debug(f\"파일 크기 확인 오류\")\n",
    "\n",
    "            # 텍스트 파일 처리\n",
    "            if ext == '.txt':\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                        content = f.read(100000)  # 최대 10만자만 읽기\n",
    "                except:\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='cp949', errors='replace') as f:\n",
    "                            content = f.read(100000)\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            # DOCX 파일 처리 - 개선된 버전\n",
    "            elif ext == '.docx':\n",
    "                try:\n",
    "                    import docx\n",
    "                    doc = docx.Document(file_path)\n",
    "                    \n",
    "                    # 모든 텍스트 추출 (단락, 테이블, 헤더/푸터)\n",
    "                    all_text = []\n",
    "                    \n",
    "                    # 1. 단락 추출\n",
    "                    for para in doc.paragraphs:\n",
    "                        if para.text.strip():\n",
    "                            all_text.append(para.text)\n",
    "                    \n",
    "                    # 2. 테이블 추출\n",
    "                    for table in doc.tables:\n",
    "                        for row in table.rows:\n",
    "                            row_text = ' | '.join([cell.text.strip() for cell in row.cells if cell.text.strip()])\n",
    "                            if row_text:\n",
    "                                all_text.append(row_text)\n",
    "                    \n",
    "                    # 3. 헤더/푸터 추출 (가능한 경우)\n",
    "                    try:\n",
    "                        for section in doc.sections:\n",
    "                            if section.header:\n",
    "                                for p in section.header.paragraphs:\n",
    "                                    if p.text.strip():\n",
    "                                        all_text.append(p.text)\n",
    "                            if section.footer:\n",
    "                                for p in section.footer.paragraphs:\n",
    "                                    if p.text.strip():\n",
    "                                        all_text.append(p.text)\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    content = \"\\n\".join(all_text)\n",
    "                    log_debug(f\"DOCX 파일 {file_path.name}에서 {len(all_text)}개 텍스트 블록 추출됨\")\n",
    "                except Exception as e:\n",
    "                    log_debug(f\"DOCX 처리 오류({file_path.name}): {str(e)}\")\n",
    "            \n",
    "            # Excel 파일 처리 - 개선된 버전\n",
    "            elif ext in ['.xlsx', '.xls']:\n",
    "                try:\n",
    "                    import pandas as pd\n",
    "                    import openpyxl\n",
    "                    xl = pd.ExcelFile(file_path, engine='openpyxl')\n",
    "                    sheet_names = xl.sheet_names[:5]  # 최대 5개 시트만 처리\n",
    "                    \n",
    "                    all_text = []\n",
    "                    for sheet_name in sheet_names:\n",
    "                        try:\n",
    "                            sheet_df = pd.read_excel(file_path, sheet_name=sheet_name, engine='openpyxl', nrows=1000)\n",
    "                            # 데이터프레임을 문자열로 변환할 때 좀 더 철저히 처리\n",
    "                            sheet_df = sheet_df.fillna('')  # NaN 값을 빈 문자열로 변환\n",
    "                            \n",
    "                            # 모든 데이터를 문자열화\n",
    "                            for col in sheet_df.columns:\n",
    "                                sheet_df[col] = sheet_df[col].astype(str)\n",
    "                                sheet_df[col] = sheet_df[col].str.strip()\n",
    "                            \n",
    "                            # 행별로 데이터 추출\n",
    "                            for _, row in sheet_df.iterrows():\n",
    "                                # 빈 값 제외하고 결합\n",
    "                                row_values = [val for val in row.values if val and val.strip()]\n",
    "                                if row_values:\n",
    "                                    all_text.append(' | '.join(row_values))\n",
    "                        except Exception as sheet_e:\n",
    "                            log_debug(f\"Excel 시트 '{sheet_name}' 처리 오류: {str(sheet_e)}\")\n",
    "                            continue\n",
    "                    \n",
    "                    content = '\\n'.join(all_text)\n",
    "                    log_debug(f\"Excel 파일 {file_path.name}에서 {len(all_text)}개 행 추출됨\")\n",
    "                except Exception as e:\n",
    "                    log_debug(f\"Excel 처리 오류({file_path.name}): {str(e)}\")\n",
    "            \n",
    "            # PowerPoint 파일 처리 - 개선된 버전\n",
    "            elif ext == '.pptx':\n",
    "                try:\n",
    "                    from pptx import Presentation\n",
    "                    prs = Presentation(file_path)\n",
    "                    slide_texts = []\n",
    "                    \n",
    "                    # 슬라이드별 처리\n",
    "                    for i, slide in enumerate(prs.slides):\n",
    "                        # 슬라이드 번호 추가\n",
    "                        slide_texts.append(f\"---슬라이드 {i+1}---\")\n",
    "                        \n",
    "                        # 모든 도형에서 텍스트 추출\n",
    "                        for shape in slide.shapes:\n",
    "                            # 텍스트가 있는 도형\n",
    "                            if hasattr(shape, \"text\") and shape.text.strip():\n",
    "                                slide_texts.append(shape.text)\n",
    "                            \n",
    "                            # 테이블 처리\n",
    "                            if hasattr(shape, \"has_table\") and shape.has_table:\n",
    "                                try:\n",
    "                                    for row in shape.table.rows:\n",
    "                                        row_text = ' | '.join([cell.text.strip() for cell in row.cells if cell.text.strip()])\n",
    "                                        if row_text:\n",
    "                                            slide_texts.append(row_text)\n",
    "                                except:\n",
    "                                    pass\n",
    "                    \n",
    "                    content = \"\\n\".join(slide_texts)\n",
    "                    log_debug(f\"PPTX 파일 {file_path.name}에서 {len(slide_texts)}개 텍스트 블록 추출됨\")\n",
    "                except Exception as e:\n",
    "                    log_debug(f\"PPTX 처리 오류({file_path.name}): {str(e)}\")\n",
    "            \n",
    "            # HWP 파일 처리 - 개선된 버전\n",
    "            elif ext == '.hwp':\n",
    "                try:\n",
    "                    import olefile\n",
    "                    if olefile.isOleFile(str(file_path)):\n",
    "                        hwp_content = []\n",
    "                        \n",
    "                        with olefile.OleFile(str(file_path)) as ole:\n",
    "                            # 스트림 목록 확인\n",
    "                            streams = ole.listdir()\n",
    "                            log_debug(f\"HWP 파일 {file_path.name} 스트림: {streams}\")\n",
    "                            \n",
    "                            # PrvText 스트림 처리 (미리보기 텍스트)\n",
    "                            if ole.exists('PrvText'):\n",
    "                                try:\n",
    "                                    prv_text = ole.openstream('PrvText')\n",
    "                                    prv_bytes = prv_text.read()\n",
    "                                    prv_text.close()\n",
    "                                    \n",
    "                                    # 여러 인코딩 시도\n",
    "                                    for encoding in ['utf-16-le', 'cp949', 'euc-kr']:\n",
    "                                        try:\n",
    "                                            decoded = prv_bytes.decode(encoding, errors='replace')\n",
    "                                            if decoded.strip():\n",
    "                                                hwp_content.append(decoded)\n",
    "                                                log_debug(f\"HWP 미리보기 추출 성공({encoding}): {len(decoded)}자\")\n",
    "                                                break\n",
    "                                        except:\n",
    "                                            continue\n",
    "                                except Exception as e:\n",
    "                                    log_debug(f\"HWP 미리보기 추출 오류: {str(e)}\")\n",
    "                            \n",
    "                            # 문서 요약 정보 처리\n",
    "                            if ole.exists('HwpSummaryInformation'):\n",
    "                                try:\n",
    "                                    summary = ole.openstream('HwpSummaryInformation')\n",
    "                                    summary_bytes = summary.read()\n",
    "                                    summary.close()\n",
    "                                    \n",
    "                                    # 가능한 인코딩으로 시도\n",
    "                                    for encoding in ['utf-16-le', 'cp949', 'euc-kr']:\n",
    "                                        try:\n",
    "                                            # 인코딩 변환 후 유효한 문자만 필터링\n",
    "                                            decoded = summary_bytes.decode(encoding, errors='replace')\n",
    "                                            valid_text = ''.join(ch for ch in decoded if ch.isprintable())\n",
    "                                            if valid_text.strip():\n",
    "                                                hwp_content.append(valid_text)\n",
    "                                                log_debug(f\"HWP 요약정보 추출 성공({encoding}): {len(valid_text)}자\")\n",
    "                                                break\n",
    "                                        except:\n",
    "                                            continue\n",
    "                                except Exception as e:\n",
    "                                    log_debug(f\"HWP 요약정보 추출 오류: {str(e)}\")\n",
    "                        \n",
    "                        # 결과 합치기\n",
    "                        content = \"\\n\".join(hwp_content)\n",
    "                        if content:\n",
    "                            log_debug(f\"HWP 파일 {file_path.name}에서 총 {len(content)}자 추출됨\")\n",
    "                    else:\n",
    "                        log_debug(f\"HWP 파일 {file_path.name}은 OLE 형식이 아님\")\n",
    "                except Exception as e:\n",
    "                    log_debug(f\"HWP 처리 오류({file_path.name}): {str(e)}\")\n",
    "            \n",
    "            # PDF 파일 처리 - 새로 추가됨\n",
    "            elif ext == '.pdf':\n",
    "                try:\n",
    "                    import PyPDF2\n",
    "                    with open(file_path, 'rb') as file:\n",
    "                        pdf_content = []\n",
    "                        \n",
    "                        try:\n",
    "                            # 엄격하지 않은 모드로 PDF 읽기\n",
    "                            reader = PyPDF2.PdfReader(file, strict=False)\n",
    "                            \n",
    "                            # 모든 페이지 처리\n",
    "                            for page_num, page in enumerate(reader.pages):\n",
    "                                try:\n",
    "                                    page_text = page.extract_text()\n",
    "                                    if page_text and page_text.strip():\n",
    "                                        pdf_content.append(f\"---페이지 {page_num+1}---\")\n",
    "                                        pdf_content.append(page_text)\n",
    "                                        log_debug(f\"PDF 페이지 {page_num+1} 추출 성공: {len(page_text)}자\")\n",
    "                                except Exception as page_e:\n",
    "                                    log_debug(f\"PDF 페이지 {page_num+1} 처리 오류: {str(page_e)}\")\n",
    "                                    continue\n",
    "                            \n",
    "                            content = \"\\n\".join(pdf_content)\n",
    "                            if len(pdf_content) > 0:\n",
    "                                log_debug(f\"PDF 파일 {file_path.name}에서 {len(pdf_content)}개 블록 추출됨\")\n",
    "                        except Exception as e:\n",
    "                            log_debug(f\"PDF 파일 구조 오류({file_path.name}): {str(e)}\")\n",
    "                except Exception as e:\n",
    "                    log_debug(f\"PDF 처리 오류({file_path.name}): {str(e)}\")\n",
    "            \n",
    "            # 내용이 추출되었는지 확인하고 준법감시 키워드 확인\n",
    "            if content:\n",
    "                keywords = ['준법감시', '심의필', '준법감사', '유효기간', '만료일']\n",
    "                found_keywords = [kw for kw in keywords if kw in content]\n",
    "\n",
    "                if found_keywords:\n",
    "                    log_debug(f\"파일 {file_path.name}에서 키워드 발견: {', '.join(found_keywords)}\")\n",
    "                else:\n",
    "                    log_debug(f\"파일 {file_path.name}에서 키워드 미발견 (내용 길이: {len(content)}자)\")\n",
    "            \n",
    "            # AI 및 N-gram을 활용한 분석\n",
    "            if content:\n",
    "                # AI 추출기 인스턴스 생성\n",
    "                extractor = AIEnhancedComplianceExtractor(\n",
    "                    api_key=\"yourkey\",  # 실제 API 키로 교체\n",
    "                    use_ngram=True,\n",
    "                    use_ai=False  # API 키가 없으면 AI 사용 안함\n",
    "                )\n",
    "                \n",
    "                # 문서 처리\n",
    "                result = extractor.process_document(content)\n",
    "                \n",
    "                # 결과 추출\n",
    "                compliance_info = result.get(\"compliance_number\")\n",
    "                content_date = result.get(\"expiry_date\")\n",
    "                \n",
    "                # 오류 날짜 필터링\n",
    "                if content_date in ERROR_DATES:\n",
    "                    content_date = None\n",
    "                \n",
    "                # 유효기간 상태 계산\n",
    "                if content_date:\n",
    "                    today = datetime.now().date()\n",
    "                    try:\n",
    "                        content_date_obj = datetime.strptime(content_date, '%Y-%m-%d').date()\n",
    "                        content_days_to_expiry = (content_date_obj - today).days\n",
    "                        \n",
    "                        if content_days_to_expiry < 0:\n",
    "                            content_status = '만료됨'\n",
    "                        elif content_days_to_expiry <= 30:\n",
    "                            content_status = '30일 이내 만료'\n",
    "                        else:\n",
    "                            content_status = '유효함'\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            # 정보 추출 로직 (파일명 우선, 내용 차선)\n",
    "            final_date = expiry_date or content_date\n",
    "            final_days_to_expiry = filename_days_to_expiry or content_days_to_expiry\n",
    "            final_status = filename_status if expiry_date else (content_status if content_date else '상태 불명')\n",
    "            \n",
    "            # 추가 필터링: 최종 날짜가 오류 날짜인 경우\n",
    "            if final_date in ERROR_DATES:\n",
    "                log_debug(f\"최종 날짜가 오류 날짜임: {final_date}\")\n",
    "                final_date = None\n",
    "                final_days_to_expiry = None\n",
    "                final_status = '상태 불명'\n",
    "            \n",
    "            # 분석 결과 요약 로깅\n",
    "            log_debug(f\"분석 결과: 상태={final_status}, 만료일={final_date}, 준법번호={compliance_number}\")\n",
    "            \n",
    "            # 결과 딕셔너리 반환\n",
    "            return {\n",
    "                '파일명': filename,\n",
    "                '상태': final_status,\n",
    "                '만료일': final_date or '알 수 없음',\n",
    "                '남은 일수': final_days_to_expiry,\n",
    "                \n",
    "                # 파일명 정보\n",
    "                '파일명_준법감시필': compliance_number,\n",
    "                '파일명_유효기간': expiry_date,\n",
    "                '파일명_유효기간_상태': filename_status if expiry_date else '정보 없음',\n",
    "                '파일명_남은일수': filename_days_to_expiry,\n",
    "                \n",
    "                # 파일 내용 정보\n",
    "                '파일내_준법감시필_번호': compliance_info,\n",
    "                '파일내_유효기간_날짜': content_date,\n",
    "                '파일내_유효기간_상태': content_status if content_date else '정보 없음',\n",
    "                '파일내_남은일수': content_days_to_expiry,\n",
    "                \n",
    "                '파일경로': str(file_path.parent),\n",
    "                '파일인덱스': file_index + 1  # 파일 인덱스 추가 (문제 파일 추적용)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            log_debug(f\"파일 분석 중 오류: {str(e)}\")\n",
    "            log_debug(traceback.format_exc())\n",
    "            # 오류 발생 시 기본 정보만 반환\n",
    "            return {\n",
    "                '파일명': file_path.name,\n",
    "                '상태': '상태 불명',\n",
    "                '만료일': '알 수 없음',\n",
    "                '남은 일수': None,\n",
    "                '파일명_준법감시필': None, \n",
    "                '파일명_유효기간': None,\n",
    "                '파일명_유효기간_상태': '정보 없음',\n",
    "                '파일명_남은일수': None,\n",
    "                '파일내_준법감시필_번호': None,\n",
    "                '파일내_유효기간_날짜': None,\n",
    "                '파일내_유효기간_상태': '정보 없음',\n",
    "                '파일내_남은일수': None,\n",
    "                '파일경로': str(file_path.parent),\n",
    "                '파일인덱스': target_files.index(file_path) + 1 if file_path in target_files else -1\n",
    "            }\n",
    "\n",
    "    # 오류 날짜 목록 - 이 날짜들은 검사에서 제외됩니다\n",
    "    ERROR_DATES = ['2024-11-30', '2020-12-31']\n",
    "\n",
    "    # 파일 확장자 목록 정의 (추가된 코드)\n",
    "    file_extensions = ['.docx', '.xlsx', '.pptx', '.hwp', '.txt', '.pdf', '.xls', '.doc', '.ppt']\n",
    "\n",
    "    # 디버깅 모드 활성화\n",
    "    DEBUG_MODE = True\n",
    "    DEBUG_FILE = \"debug_log.txt\"\n",
    "\n",
    "    # 병렬 파일 검색 - 간소화 버전\n",
    "    def search_files_in_directory(directory):\n",
    "        found_files = []\n",
    "        # 전역 변수 file_extensions 사용\n",
    "        for ext in file_extensions:\n",
    "            try:\n",
    "                for file_path in Path(directory).glob(f'**/*{ext}'):\n",
    "                    # 키워드 필터링 제거 - 모든 파일 추가\n",
    "                    found_files.append(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"디렉토리 {directory} 검색 중 오류: {e}\")\n",
    "        return found_files\n",
    "\n",
    "    # 디렉토리 목록 생성\n",
    "    all_dirs = []\n",
    "    try:\n",
    "        for d in base_path.iterdir():\n",
    "            if d.is_dir():\n",
    "                all_dirs.append(d)\n",
    "    except Exception as e:\n",
    "        print(f\"디렉토리 목록 생성 중 오류: {e}\")\n",
    "\n",
    "    if not all_dirs:  # 하위 디렉토리가 없으면 현재 디렉토리 검색\n",
    "        all_dirs = [base_path]\n",
    "\n",
    "    print(f\"총 {len(all_dirs)}개 디렉토리 검색 예정\")\n",
    "\n",
    "    # 파일 검색 (병렬 처리 단순화)\n",
    "    target_files = collect_target_files(BASE_PATH)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        search_results = list(executor.map(search_files_in_directory, all_dirs))\n",
    "        for result in search_results:\n",
    "            target_files.extend(result)\n",
    "\n",
    "    print(f\"총 {len(target_files)}개 파일을 찾았습니다. ({time.time() - start_time:.2f}초)\")\n",
    "\n",
    "    # 파일 분석 (배치 처리 방식으로 변경)\n",
    "    print(\"파일 분석 시작...\")\n",
    "    data = []\n",
    "\n",
    "    # 파일을 배치로 나누어 처리\n",
    "    batch_size = 1000  # 한 번에 처리할 파일 수\n",
    "    total_batches = (len(target_files) + batch_size - 1) // batch_size\n",
    "    print(f\"총 {total_batches}개 배치로 나누어 처리합니다.\")\n",
    "\n",
    "    # 배치별 처리 및 중간 결과 저장\n",
    "    for batch_idx in range(total_batches):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = min((batch_idx + 1) * batch_size, len(target_files))\n",
    "        batch_files = target_files[batch_start:batch_end]\n",
    "        \n",
    "        print(f\"\\n배치 {batch_idx + 1}/{total_batches} 처리 중 ({batch_end - batch_start}개 파일)...\")\n",
    "        \n",
    "        # 현재 배치 병렬 처리\n",
    "        batch_data = []\n",
    "        max_workers = min(os.cpu_count() or 4, 8)  # 최대 8개 워커\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # 각 파일별로 분석 작업 예약\n",
    "            future_to_file = {executor.submit(analyze_file, file_path): file_path for file_path in batch_files}\n",
    "            \n",
    "            # 완료된 작업 처리\n",
    "            for future in tqdm(concurrent.futures.as_completed(future_to_file), total=len(batch_files), desc=f\"배치 {batch_idx + 1} 분석 중\"):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result:\n",
    "                        batch_data.append(result)\n",
    "                except Exception as e:\n",
    "                    file_path = future_to_file[future]\n",
    "                    print(f\"\\n파일 {file_path.name} 처리 중 오류: {e}\")\n",
    "        \n",
    "        # 현재 배치 결과 저장\n",
    "        data.extend(batch_data)\n",
    "        print(f\"배치 {batch_idx + 1} 완료: {len(batch_data)}개 파일 처리됨\")\n",
    "        \n",
    "        # 메모리 정리\n",
    "        gc.collect()\n",
    "        \n",
    "        # 진행 상황 저장 (선택 사항)\n",
    "        #if batch_idx % 5 == 4 or batch_idx == total_batches - 1:  # 5개 배치마다 또는 마지막 배치\n",
    "        #    try:\n",
    "        #        interim_df = pd.DataFrame(data)\n",
    "        #        interim_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        #        interim_file = f\"interim_results_{interim_timestamp}.csv\"\n",
    "        #        interim_df.to_csv(interim_file, index=False, encoding='utf-8-sig')\n",
    "        #        print(f\"중간 결과 저장됨: {interim_file}\")\n",
    "        #    except Exception as e:\n",
    "        #        print(f\"중간 결과 저장 중 오류: {e}\")\n",
    "\n",
    "    print(f\"총 {len(data)}개 파일 분석 완료\")\n",
    "    \n",
    "    # 데이터프레임 생성\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # 유효기간 날짜 검증 및 오류 수정 - 강화된 검증\n",
    "        def validate_date(date_str):\n",
    "            \"\"\"유효기간 날짜 검증 함수\"\"\"\n",
    "            if not isinstance(date_str, str) or date_str == '알 수 없음':\n",
    "                return date_str\n",
    "                \n",
    "            # 오류 날짜 명시적으로 제거\n",
    "            if date_str in ERROR_DATES:\n",
    "                return None\n",
    "                \n",
    "            try:\n",
    "                # 날짜 형식 검증\n",
    "                date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "                \n",
    "                # 추가 유효성 검증 (너무 과거나 먼 미래의 날짜는 의심)\n",
    "                today = datetime.now()\n",
    "                five_years_ago = today.replace(year=today.year - 5)\n",
    "                five_years_future = today.replace(year=today.year + 5)\n",
    "                \n",
    "                if date_obj < five_years_ago or date_obj > five_years_future:\n",
    "                    # 너무 이상한 날짜는 로그로 기록\n",
    "                    print(f\"의심스러운 날짜 검출: {date_str} (허용 범위: {five_years_ago.strftime('%Y-%m-%d')} ~ {five_years_future.strftime('%Y-%m-%d')})\")\n",
    "                \n",
    "                return date_str\n",
    "            except:\n",
    "                return None\n",
    "        \n",
    "        # 모든 날짜 컬럼에 대한 검증 적용\n",
    "        for col in ['만료일', '파일명_유효기간', '파일내_유효기간_날짜']:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(validate_date)\n",
    "        \n",
    "        # 유효기간 날짜가 None인 경우 상태도 '상태 불명'으로 변경\n",
    "        df.loc[df['만료일'].isna() | (df['만료일'] == '알 수 없음'), '상태'] = '상태 불명'\n",
    "        \n",
    "        # 추가 확인: 오류 날짜를 포함하는 행 찾기\n",
    "        for error_date in ERROR_DATES:\n",
    "            problem_files = df[df.apply(lambda row: any(str(val) == error_date for val in row), axis=1)]\n",
    "            if not problem_files.empty:\n",
    "                print(f\"\\n경고: {error_date} 날짜가 여전히 {len(problem_files)}개 파일에서 발견됨\")\n",
    "                print(\"해당 파일:\")\n",
    "                for idx, row in problem_files.iterrows():\n",
    "                    print(f\"- {row['파일명']}\")\n",
    "        \n",
    "        # 결과 열 정리 - 불필요한 컬럼 제거\n",
    "        column_order = [\n",
    "            '파일명', '상태', '만료일', '남은 일수', \n",
    "            '파일명_준법감시필', '파일명_유효기간', '파일명_유효기간_상태', '파일명_남은일수',\n",
    "            '파일내_준법감시필_번호',\n",
    "            '파일내_유효기간_날짜', '파일내_유효기간_상태', '파일내_남은일수',\n",
    "            '파일경로'\n",
    "        ]\n",
    "        \n",
    "        # 존재하는 열만 선택\n",
    "        existing_columns = [col for col in column_order if col in df.columns]\n",
    "        df = df[existing_columns]\n",
    "        \n",
    "        # 결과 정렬 (상태별)\n",
    "        status_order = {'만료됨': 0, '30일 이내 만료': 1, '유효함': 2, '상태 불명': 3}\n",
    "        df['status_order'] = df['상태'].map(lambda x: status_order.get(x, 4))\n",
    "        df = df.sort_values(by=['status_order', '남은 일수'])\n",
    "        df = df.drop(columns=['status_order'])\n",
    "        \n",
    "        # 현재 디렉토리에 저장\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_file = f\"ibk_준법감시_유효기간_{timestamp}.csv\"\n",
    "        df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"결과 파일이 현재 디렉토리에 저장되었습니다: {output_file}\")\n",
    "        \n",
    "        # Excel 파일로 저장하고 열 너비 자동 조정\n",
    "        excel_file = f\"ibk_준법감시_유효기간_{timestamp}.xlsx\"\n",
    "\n",
    "        # ExcelWriter 사용\n",
    "        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "            # DataFrame을 Excel로 변환\n",
    "            df.to_excel(writer, index=False, sheet_name='준법감시')\n",
    "            \n",
    "            # 워크북과 워크시트 가져오기\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets['준법감시']\n",
    "            \n",
    "            # 열 너비 자동 조정\n",
    "            for i, column in enumerate(df.columns):\n",
    "                # 열 이름의 길이 확인\n",
    "                column_width = max(len(str(column)), 10)  # 최소 너비 10\n",
    "                \n",
    "                # 열의 데이터 중 가장 긴 값의 길이 확인 (최대 100행까지만 확인)\n",
    "                max_length = 0\n",
    "                for j in range(min(len(df), 100)):  # 처리 시간 단축을 위해 최대 100행까지만 확인\n",
    "                    cell_value = str(df.iloc[j, i])\n",
    "                    max_length = max(max_length, len(cell_value))\n",
    "                \n",
    "                # 최종 열 너비 결정 (최대 100자, 기본 폰트 기준)\n",
    "                column_width = min(max(column_width, max_length + 2), 100)  # +2는 여유 공간\n",
    "                \n",
    "                # 열 너비 설정\n",
    "                col_letter = openpyxl.utils.get_column_letter(i + 1)\n",
    "                worksheet.column_dimensions[col_letter].width = column_width\n",
    "            \n",
    "            # 헤더 행 스타일 설정\n",
    "            header_font = openpyxl.styles.Font(bold=True)\n",
    "            header_fill = openpyxl.styles.PatternFill(start_color='E6E6E6', end_color='E6E6E6', fill_type='solid')\n",
    "            \n",
    "            for cell in worksheet[1]:\n",
    "                cell.font = header_font\n",
    "                cell.fill = header_fill\n",
    "            \n",
    "            # 데이터 행에 조건부 서식 설정 (상태에 따른 색상)\n",
    "            status_colors = {\n",
    "                '만료됨': 'FFC7CE',  # 밝은 빨강\n",
    "                '30일 이내 만료': 'FFEB9C',  # 밝은 노랑\n",
    "                '유효함': 'C6EFCE',  # 밝은 녹색\n",
    "                '상태 불명': 'DDDDDD'  # 회색\n",
    "            }\n",
    "            \n",
    "            # 상태 열 인덱스 찾기\n",
    "            status_col_idx = df.columns.get_loc('상태') + 1  # Excel은 1부터 시작\n",
    "            status_col_letter = openpyxl.utils.get_column_letter(status_col_idx)\n",
    "            \n",
    "            # 각 상태별로 조건부 서식 설정\n",
    "            for status, color in status_colors.items():\n",
    "                rule = openpyxl.formatting.rule.CellIsRule(\n",
    "                    operator='equal',\n",
    "                    formula=[f'\"{status}\"'],\n",
    "                    stopIfTrue=True,\n",
    "                    fill=openpyxl.styles.PatternFill(start_color=color, end_color=color, fill_type='solid')\n",
    "                )\n",
    "                \n",
    "                # 조건부 서식 적용 범위 (상태 열만)\n",
    "                cell_range = f'{status_col_letter}2:{status_col_letter}{len(df) + 1}'\n",
    "                worksheet.conditional_formatting.add(cell_range, rule)\n",
    "\n",
    "        print(f\"Excel 파일이 자동 열 너비 조정과 서식을 적용하여 저장되었습니다: {excel_file}\")\n",
    "        \n",
    "        # 총 소요 시간\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"총 실행 시간: {total_time:.2f}초 (파일당 평균: {total_time/len(target_files):.2f}초)\")\n",
    "        \n",
    "        # 결과 통계\n",
    "        status_counts = df['상태'].value_counts().to_dict()\n",
    "        print(\"\\n=== 분석 결과 통계 ===\")\n",
    "        print(f\"- 만료됨: {status_counts.get('만료됨', 0)}개\")\n",
    "        print(f\"- 30일 이내 만료: {status_counts.get('30일 이내 만료', 0)}개\")\n",
    "        print(f\"- 유효함: {status_counts.get('유효함', 0)}개\")\n",
    "        print(f\"- 상태 불명: {status_counts.get('상태 불명', 0)}개\")\n",
    "        print(f\"- 총 파일 수: {len(df)}개\")\n",
    "        \n",
    "        # 정보 출처 통계\n",
    "        source_stats = {\n",
    "            '파일명에서만 발견': len(df[(df['파일명_유효기간'].notna()) & (df['파일내_유효기간_날짜'].isna())]),\n",
    "            '파일 내용에서만 발견': len(df[(df['파일명_유효기간'].isna()) & (df['파일내_유효기간_날짜'].notna())]),\n",
    "            '파일명과 내용 모두에서 발견': len(df[(df['파일명_유효기간'].notna()) & (df['파일내_유효기간_날짜'].notna())]),\n",
    "            '어디에서도 발견되지 않음': len(df[(df['파일명_유효기간'].isna()) & (df['파일내_유효기간_날짜'].isna())])\n",
    "        }\n",
    "        \n",
    "        print(\"\\n=== 정보 출처 통계 ===\")\n",
    "        for source, count in source_stats.items():\n",
    "            print(f\"- {source}: {count}개 ({count/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        # 결과 미리보기\n",
    "        print(\"\\n === 결과 데이터프레임 미리보기 ===\")\n",
    "        display(df.head())\n",
    "    \n",
    "    else:\n",
    "        print(\"분석할 파일이 없거나 모든 파일 처리 중 오류가 발생했습니다.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n",
    "    print(traceback.format_exc())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
