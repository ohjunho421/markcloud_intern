{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f44ff9",
   "metadata": {},
   "source": [
    "1. 필요한 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca2ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import hashlib\n",
    "import concurrent.futures\n",
    "import traceback\n",
    "import json\n",
    "import gc\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "from openpyxl.formatting.rule import CellIsRule\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# 경고 메시지 설정\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLTK 필요 패키지 다운로드\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# 기본 경로 설정\n",
    "BASE_PATH = Path(r\"C:\\Users\\markcloud\\Desktop\\오준호\\IBK\")\n",
    "\n",
    "# 디버깅 모드 활성화\n",
    "DEBUG_MODE = True\n",
    "DEBUG_FILE = \"debug_log.txt\"\n",
    "\n",
    "# 오류 날짜 목록 - 이 날짜들은 검사에서 제외됩니다\n",
    "ERROR_DATES = ['2024-11-30', '2020-12-31']\n",
    "\n",
    "# 디버깅 로그 함수\n",
    "def log_debug(message):\n",
    "    if DEBUG_MODE:\n",
    "        with open(DEBUG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}\\n\")\n",
    "            \n",
    "# 디버그 로그 파일 초기화\n",
    "with open(DEBUG_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"=== 디버그 로그 시작: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3affb0",
   "metadata": {},
   "source": [
    "2. 파일 이름 분석 및 사전 필터링 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec611213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_keywords_in_name(filename):\n",
    "    \"\"\"파일명에 준법감시 관련 키워드가 있는지 확인\"\"\"\n",
    "    keywords = ['유효기간', '준법감시', '심의필', '만료일', '법무', '결재', '승인']\n",
    "    return any(keyword in filename for keyword in keywords)\n",
    "\n",
    "def extract_expiry_from_filename_improved(filename):\n",
    "    \"\"\"파일명에서 유효기간 정보를 추출 - 개선된 버전\"\"\"\n",
    "    import re\n",
    "    from datetime import datetime\n",
    "    \n",
    "    log_debug(f\"파일명 분석 시작: {filename}\")\n",
    "    \n",
    "    # IBK 파일명 패턴에 맞는 정규식\n",
    "    ibk_patterns = [\n",
    "        r'유효기간\\(([0-9]{4})[\\.\\\\-]([0-9]{2})[\\.\\\\-]([0-9]{2})\\)',  # 유효기간(2025.08.20)\n",
    "        r'유효기간\\(([0-9]{4})([0-9]{2})([0-9]{2})\\)',  # 유효기간(20250820)\n",
    "        r'유효기간\\(([0-9]{4})[-/.]([0-9]{1,2})[-/.]([0-9]{1,2})\\)',  # 유효기간(2025-08-20)\n",
    "        r'제[0-9]{4}-[0-9]+호\\([^)]+\\)\\s*유효기간\\((\\d{4})[./-](\\d{1,2})[./-](\\d{1,2})\\)',  # 제2024-4806호(날짜) 유효기간(2025.08.20)\n",
    "        r'유효기간[_\\s]([0-9]{4})[./-]([0-9]{1,2})[./-]([0-9]{1,2})',  # 유효기간_2025.08.20\n",
    "        r'([0-9]{4})[./-]([0-9]{1,2})[./-]([0-9]{1,2})[_\\s]유효기간',  # 2025.08.20_유효기간\n",
    "        r'만료일[_\\s]([0-9]{4})[./-]([0-9]{1,2})[./-]([0-9]{1,2})'   # 만료일_2025.08.20\n",
    "    ]\n",
    "    \n",
    "    # 패턴 검색\n",
    "    for i, pattern in enumerate(ibk_patterns):\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            try:\n",
    "                # 패턴에 따라 그룹 인덱스 조정\n",
    "                if '제' in pattern and len(match.groups()) >= 3:  # 제2024-4806호 형식\n",
    "                    year, month, day = map(int, match.groups()[-3:])\n",
    "                else:  # 일반 형식\n",
    "                    year, month, day = map(int, match.groups())\n",
    "                    \n",
    "                if 2000 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                    expiry_date = datetime(year, month, day)\n",
    "                    log_debug(f\"유효기간 추출 성공: {expiry_date.strftime('%Y-%m-%d')} (패턴 {i+1})\")\n",
    "                    \n",
    "                    # 오류 날짜 필터링\n",
    "                    date_str = expiry_date.strftime('%Y-%m-%d')\n",
    "                    if date_str in ERROR_DATES:\n",
    "                        log_debug(f\"오류 날짜 감지: {date_str}\")\n",
    "                        continue\n",
    "                        \n",
    "                    return expiry_date\n",
    "            except (ValueError, IndexError) as e:\n",
    "                log_debug(f\"패턴 {i+1} 매칭 오류: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # 확장 패턴 시도 (날짜 형식이 다른 경우)\n",
    "    extended_patterns = [\n",
    "        r'유효기간[:\\s]*([12]\\d{3})[년\\.\\-]?([01]?\\d)[월\\.\\-]?([0-3]?\\d)[일]?',  # 유효기간: 2025년6월3일\n",
    "        r'([12]\\d{3})년?[^0-9]+([01]?\\d)월?[^0-9]+([0-3]?\\d)일?[^0-9]*유효',  # 2025년 6월 3일 유효\n",
    "        r'유효[^0-9]*([12]\\d{3})년?[^0-9]+([01]?\\d)월?[^0-9]+([0-3]?\\d)일?'   # 유효 2025년 6월 3일\n",
    "    ]\n",
    "    \n",
    "    for i, pattern in enumerate(extended_patterns):\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            try:\n",
    "                groups = match.groups()\n",
    "                log_debug(f\"확장 패턴 {i+1} 매치: {pattern} -> {groups}\")\n",
    "                \n",
    "                year, month, day = map(int, groups)\n",
    "                if 2000 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                    expiry_date = datetime(year, month, day)\n",
    "                    date_str = expiry_date.strftime('%Y-%m-%d')\n",
    "                    \n",
    "                    if date_str in ERROR_DATES:\n",
    "                        log_debug(f\"오류 날짜 감지: {date_str}\")\n",
    "                        continue\n",
    "                        \n",
    "                    log_debug(f\"확장 패턴으로 유효기간 추출 성공: {date_str}\")\n",
    "                    return expiry_date\n",
    "            except (ValueError, IndexError) as e:\n",
    "                log_debug(f\"확장 패턴 {i+1} 매칭 오류: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    log_debug(f\"파일명에서 유효기간 추출 실패: {filename}\")\n",
    "    return None\n",
    "\n",
    "def extract_info_from_filename(filename):\n",
    "    \"\"\"파일명에서 준법감시 정보 추출 (준법감시필 번호 + 유효기간)\"\"\"\n",
    "    # 유효기간 추출\n",
    "    expiry_date = extract_expiry_from_filename_improved(filename)\n",
    "    \n",
    "    # 준법감시필 번호 추출\n",
    "    compliance_number = extract_compliance_number(filename)\n",
    "    \n",
    "    # 유효기간 상태 계산\n",
    "    if expiry_date:\n",
    "        today = datetime.now().date()\n",
    "        expiry_date_obj = expiry_date.date()\n",
    "        days_to_expiry = (expiry_date_obj - today).days\n",
    "        \n",
    "        if days_to_expiry < 0:\n",
    "            status = '만료됨'\n",
    "        elif days_to_expiry <= 30:\n",
    "            status = '30일 이내 만료'\n",
    "        else:\n",
    "            status = '유효함'\n",
    "    else:\n",
    "        days_to_expiry = None\n",
    "        status = '상태 불명'\n",
    "    \n",
    "    return {\n",
    "        'filename': filename,\n",
    "        'expiry_date': expiry_date.strftime('%Y-%m-%d') if expiry_date else None,\n",
    "        'compliance_number': compliance_number,\n",
    "        'days_to_expiry': days_to_expiry,\n",
    "        'status': status,\n",
    "        'source': '파일명'\n",
    "    }\n",
    "\n",
    "def extract_compliance_number(filename):\n",
    "    \"\"\"파일명에서 준법감시필 번호 추출\"\"\"\n",
    "    log_debug(f\"준법감시필 번호 추출 시작: {filename}\")\n",
    "    \n",
    "    compliance_patterns = [\n",
    "        r'제(\\d{4})-(\\d+)호',  # 제2024-4806호\n",
    "        r'준법감시[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)',  # 준법감시-2024-123\n",
    "        r'심의필[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)',    # 심의필-2024-123\n",
    "        r'준법[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)'       # 준법-2024-123\n",
    "    ]\n",
    "    \n",
    "    for i, pattern in enumerate(compliance_patterns):\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            try:\n",
    "                year, number = match.groups()\n",
    "                \n",
    "                # 형식에 따라 준법감시필 번호 생성\n",
    "                if pattern.startswith(r'제'):\n",
    "                    compliance_number = f\"제{year}-{number}호\"\n",
    "                elif pattern.startswith(r'준법감시'):\n",
    "                    compliance_number = f\"준법감시-{year}-{number}\"\n",
    "                elif pattern.startswith(r'심의필'):\n",
    "                    compliance_number = f\"심의필-{year}-{number}\"\n",
    "                else:\n",
    "                    compliance_number = f\"준법-{year}-{number}\"\n",
    "                \n",
    "                log_debug(f\"준법감시필 번호 추출 성공: {compliance_number} (패턴 {i+1})\")\n",
    "                return compliance_number\n",
    "            except Exception as e:\n",
    "                log_debug(f\"준법감시필 번호 추출 오류: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    log_debug(f\"파일명에서 준법감시필 번호 추출 실패: {filename}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8f71a",
   "metadata": {},
   "source": [
    "3. 문서 로드 및 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f37cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_content(file_path):\n",
    "    \"\"\"다양한 파일 형식에서 텍스트 추출 - 성능 개선\"\"\"\n",
    "    content = \"\"\n",
    "    ext = file_path.suffix.lower()\n",
    "    \n",
    "    try:\n",
    "        # 1. 파일 크기 확인 - 대용량 파일은 제한적으로 처리\n",
    "        file_size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "        if file_size_mb > 200:  # 200MB 이상은 최소한만 처리\n",
    "            log_debug(f\"대용량 파일 감지: {file_path.name} ({file_size_mb:.2f}MB) - 제한적 처리\")\n",
    "            \n",
    "            # 텍스트 파일일 경우 앞부분만 읽기\n",
    "            if ext == '.txt':\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                    return f.read(10000)  # 처음 1만자만 읽기\n",
    "            \n",
    "            # 다른 대용량 파일은 건너뛰기\n",
    "            return f\"[대용량 파일: {file_path.name} - 건너뜀]\"\n",
    "        \n",
    "        # Word 문서\n",
    "        elif ext == '.docx':\n",
    "            try:\n",
    "                import docx\n",
    "                doc = docx.Document(file_path)\n",
    "                paragraphs = doc.paragraphs[:100]  # 최대 100개 문단만 처리\n",
    "                content = \"\\n\".join([p.text for p in paragraphs if p.text])\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Excel 파일\n",
    "        elif ext in ['.xlsx', '.xls']:\n",
    "            try:\n",
    "                xl = pd.ExcelFile(file_path, engine='openpyxl')\n",
    "                sheet_names = xl.sheet_names[:3]  # 최대 3개 시트만 처리\n",
    "                \n",
    "                all_text = []\n",
    "                for sheet_name in sheet_names:\n",
    "                    try:\n",
    "                        sheet_df = pd.read_excel(file_path, sheet_name=sheet_name, engine='openpyxl', nrows=1000)\n",
    "                        # 텍스트 열만 추출\n",
    "                        text_cols = [col for col in sheet_df.columns if sheet_df[col].dtype == 'object']\n",
    "                        if text_cols:\n",
    "                            sheet_text = '\\n'.join(sheet_df[text_cols].fillna('').astype(str).apply(' '.join, axis=1).tolist())\n",
    "                            all_text.append(sheet_text)\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                content = '\\n'.join(all_text)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # PowerPoint 파일\n",
    "        elif ext == '.pptx':\n",
    "            try:\n",
    "                from pptx import Presentation\n",
    "                prs = Presentation(file_path)\n",
    "                slide_texts = []\n",
    "                for slide in list(prs.slides)[:20]:  # 최대 20개 슬라이드\n",
    "                    for shape in slide.shapes:\n",
    "                        if hasattr(shape, \"text\"):\n",
    "                            slide_texts.append(shape.text)\n",
    "                content = \"\\n\".join(slide_texts)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # HWP 파일\n",
    "        elif ext == '.hwp':\n",
    "            try:\n",
    "                import olefile\n",
    "                if olefile.isOleFile(str(file_path)):\n",
    "                    with olefile.OleFile(str(file_path)) as ole:\n",
    "                        if ole.exists('PrvText'):\n",
    "                            prv_text = ole.openstream('PrvText')\n",
    "                            content = prv_text.read().decode('utf-16-le', errors='replace')\n",
    "                            prv_text.close()\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        # PDF 파일\n",
    "        elif ext == '.pdf':\n",
    "            try:\n",
    "                import PyPDF2\n",
    "                with open(file_path, 'rb') as file:\n",
    "                    # 더 엄격한 오류 처리 추가\n",
    "                    try:\n",
    "                        reader = PyPDF2.PdfReader(file, strict=False)\n",
    "                        \n",
    "                        # 최대 5페이지만 처리 (빠른 처리를 위해)\n",
    "                        max_pages = min(5, len(reader.pages))\n",
    "                        for page_num in range(max_pages):\n",
    "                            try:\n",
    "                                page_text = reader.pages[page_num].extract_text()\n",
    "                                if page_text:\n",
    "                                    content += page_text + \"\\n\"\n",
    "                            except Exception as e:\n",
    "                                # 페이지별 오류 무시하고 계속 진행\n",
    "                                continue\n",
    "                    except Exception as e:\n",
    "                        # PDF 처리 오류 무시\n",
    "                        pass\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_debug(f\"파일 {file_path.name} 읽기 오류: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_hwp_safely(file_path):\n",
    "    \"\"\"HWP 파일을 안전하게 처리하는 함수\"\"\"\n",
    "    content = \"\"\n",
    "    \n",
    "    # 방법 1: olefile 사용\n",
    "    try:\n",
    "        import olefile\n",
    "        if olefile.isOleFile(str(file_path)):\n",
    "            try:\n",
    "                ole = olefile.OleFile(str(file_path))\n",
    "                try:\n",
    "                    if ole.exists('PrvText'):\n",
    "                        prv_text = ole.openstream('PrvText')\n",
    "                        content = prv_text.read().decode('utf-16-le', errors='replace')\n",
    "                        prv_text.close()\n",
    "                    else:\n",
    "                        content = f\"[HWP 파일: {file_path.name} - 미리보기 없음]\"\n",
    "                finally:\n",
    "                    ole.close()\n",
    "                if content:\n",
    "                    return content\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # 방법 2: hwp.txt 존재 확인\n",
    "    try:\n",
    "        txt_path = file_path.with_suffix('.txt')\n",
    "        if txt_path.exists():\n",
    "            with open(txt_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                content = f.read()\n",
    "                if content:\n",
    "                    return content\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # 방법 3: 파일명에서 메타데이터 추출\n",
    "    filename = file_path.name\n",
    "    expiry_date = extract_expiry_from_filename_improved(filename)\n",
    "    \n",
    "    if expiry_date:\n",
    "        content = f\"[파일명 메타데이터에서 추출] 유효기간: {expiry_date.strftime('%Y년 %m월 %d일')}\"\n",
    "        return content\n",
    "    \n",
    "    # 모든 방법 실패 시 기본 메시지\n",
    "    return f\"[HWP 파일: {file_path.name} - 컨텐츠 추출 실패]\"\n",
    "\n",
    "def collect_target_files(base_path):\n",
    "    \"\"\"타겟 파일 수집 - 병렬 처리 최적화\"\"\"\n",
    "    print(\"분석할 파일 찾는 중...\")\n",
    "    file_extensions = ['.docx', '.xlsx', '.pptx', '.hwp', '.txt', '.pdf']\n",
    "    \n",
    "    target_files = []\n",
    "    keywords = ['준법', '감시', '심의', '유효기간', '만료']\n",
    "    \n",
    "    # 디렉토리 목록 생성\n",
    "    all_dirs = []\n",
    "    try:\n",
    "        for d in Path(base_path).iterdir():\n",
    "            if d.is_dir():\n",
    "                all_dirs.append(d)\n",
    "    except Exception as e:\n",
    "        print(f\"디렉토리 목록 생성 중 오류: {e}\")\n",
    "    \n",
    "    if not all_dirs:  # 하위 디렉토리가 없으면 현재 디렉토리 검색\n",
    "        all_dirs = [Path(base_path)]\n",
    "    \n",
    "    print(f\"총 {len(all_dirs)}개 디렉토리 검색 예정\")\n",
    "    \n",
    "    # 병렬 파일 검색 - 간소화 버전\n",
    "    def search_files_in_directory(directory):\n",
    "        found_files = []\n",
    "        for ext in file_extensions:\n",
    "            try:\n",
    "                for file_path in Path(directory).glob(f'**/*{ext}'):\n",
    "                    if any(keyword in file_path.name for keyword in keywords):\n",
    "                        found_files.append(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"디렉토리 {directory} 검색 중 오류: {e}\")\n",
    "        return found_files\n",
    "    \n",
    "    # 파일 검색 (병렬 처리)\n",
    "    target_files = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        search_results = list(executor.map(search_files_in_directory, all_dirs))\n",
    "        for result in search_results:\n",
    "            target_files.extend(result)\n",
    "    \n",
    "    print(f\"총 {len(target_files)}개 파일을 찾았습니다.\")\n",
    "    return target_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc0513",
   "metadata": {},
   "source": [
    "4. 준법감시 정보 추출 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6720715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedComplianceExtractor:\n",
    "    def __init__(self, api_key=None, use_ngram=True, use_ai=False):\n",
    "        self.api_key = api_key\n",
    "        self.use_ngram = use_ngram\n",
    "        self.use_ai = use_ai\n",
    "        self.chunk_size = 1000  # 최적 청크 크기 (GPT API 토큰 한도 고려)\n",
    "        self.chunk_overlap = 200  # 맥락 유지를 위한 중첩 크기\n",
    "        \n",
    "        # 키워드 및 패턴 정의\n",
    "        self.compliance_keywords = [\n",
    "            '준법감시', '준법감시인', '준법감사', '심의필', '제호', \n",
    "            '승인', '결재', '법규', '컴플라이언스'\n",
    "        ]\n",
    "        \n",
    "        self.validity_keywords = [\n",
    "            '유효기간', '만료일', '유효', '만료', '기간', \n",
    "            '까지', '효력', '사용기한'\n",
    "        ]\n",
    "        \n",
    "    def create_semantic_chunks(self, text):\n",
    "        \"\"\"의미론적 청크 생성 - 문장/단락 단위 분할\"\"\"\n",
    "        if not text or len(text) < self.chunk_size:\n",
    "            return [text] if text else []\n",
    "        \n",
    "        # 단락 기반 분할 (더 의미있는 청크)\n",
    "        paragraphs = re.split(r'\\n\\s*\\n', text)\n",
    "        \n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for para in paragraphs:\n",
    "            # 단일 단락이 청크 크기보다 크면 문장으로 분할\n",
    "            if len(para) > self.chunk_size:\n",
    "                sentences = re.split(r'(?<=[.!?])\\s+', para)\n",
    "                for sentence in sentences:\n",
    "                    if len(current_chunk) + len(sentence) <= self.chunk_size:\n",
    "                        current_chunk += sentence + \" \"\n",
    "                    else:\n",
    "                        chunks.append(current_chunk.strip())\n",
    "                        current_chunk = sentence + \" \"\n",
    "            # 청크 크기 이내면 단락 단위로 추가\n",
    "            elif len(current_chunk) + len(para) <= self.chunk_size:\n",
    "                current_chunk += para + \"\\n\\n\"\n",
    "            else:\n",
    "                chunks.append(current_chunk.strip())\n",
    "                current_chunk = para + \"\\n\\n\"\n",
    "        \n",
    "        # 마지막 청크 추가\n",
    "        if current_chunk.strip():\n",
    "            chunks.append(current_chunk.strip())\n",
    "        \n",
    "        # 청크 중첩 처리로 맥락 유지\n",
    "        overlapped_chunks = []\n",
    "        for i in range(len(chunks)):\n",
    "            if i < len(chunks) - 1:\n",
    "                # 현재 청크와 다음 청크의 일부를 중첩\n",
    "                overlap_size = min(self.chunk_overlap, len(chunks[i]), len(chunks[i+1]))\n",
    "                \n",
    "                if i == 0:\n",
    "                    overlapped_chunks.append(chunks[i])\n",
    "                \n",
    "                # 중첩 청크: 현재 청크의 끝 + 다음 청크의 시작\n",
    "                current_end = chunks[i][-overlap_size:] if overlap_size > 0 else \"\"\n",
    "                next_start = chunks[i+1][:overlap_size] if overlap_size > 0 else \"\"\n",
    "                \n",
    "                overlapped_chunks.append(current_end + next_start)\n",
    "            \n",
    "            if i == len(chunks) - 1:\n",
    "                overlapped_chunks.append(chunks[i])\n",
    "        \n",
    "        return overlapped_chunks if overlapped_chunks else chunks\n",
    "        \n",
    "    def score_chunks_by_relevance(self, chunks):\n",
    "        \"\"\"준법감시 관련성 기준으로 청크 점수화 및 필터링\"\"\"\n",
    "        scored_chunks = []\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            # 키워드 기반 점수\n",
    "            keyword_score = 0\n",
    "            for keyword in self.compliance_keywords:\n",
    "                keyword_score += chunk.lower().count(keyword.lower()) * 5\n",
    "            \n",
    "            for keyword in self.validity_keywords:\n",
    "                keyword_score += chunk.lower().count(keyword.lower()) * 5\n",
    "            \n",
    "            # 정규식 패턴 기반 점수\n",
    "            pattern_score = 0\n",
    "            compliance_patterns = [\n",
    "                r'제\\d{4}-\\d+호',  # 제2024-4806호\n",
    "                r'준법감시[_\\-\\s]*\\d{4}[_\\-\\s]*\\d+',  # 준법감시-2024-123\n",
    "                r'심의필[_\\-\\s]*\\d{4}[_\\-\\s]*\\d+',    # 심의필-2024-123\n",
    "            ]\n",
    "            \n",
    "            date_patterns = [\n",
    "                r'유효기간[^0-9]*\\d{4}[-/.년\\s]\\d{1,2}[-/.월\\s]\\d{1,2}일?',\n",
    "                r'만료일[^0-9]*\\d{4}[-/.년\\s]\\d{1,2}[-/.월\\s]\\d{1,2}일?'\n",
    "            ]\n",
    "            \n",
    "            for pattern in compliance_patterns + date_patterns:\n",
    "                if re.search(pattern, chunk):\n",
    "                    pattern_score += 20\n",
    "            \n",
    "            # 종합 점수 및 저장\n",
    "            total_score = keyword_score + pattern_score\n",
    "            if total_score > 0:  # 관련성 있는 청크만 저장\n",
    "                scored_chunks.append((i, chunk, total_score))\n",
    "        \n",
    "        # 점수 기준 정렬 및 상위 청크 선택\n",
    "        scored_chunks.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # 상위 청크 반환 (최대 5개, 또는 점수 30 이상인 모든 청크)\n",
    "        top_chunks = [(idx, chunk) for idx, chunk, score in scored_chunks if score >= 30]\n",
    "        if len(top_chunks) > 5:\n",
    "            top_chunks = top_chunks[:5]\n",
    "        \n",
    "        return top_chunks\n",
    "    \n",
    "    def call_gpt_api(self, chunk):\n",
    "        \"\"\"GPT API 호출하여 준법감시 정보 추출\"\"\"\n",
    "        if not self.use_ai or not self.api_key:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            import openai\n",
    "            \n",
    "            # API 키 설정\n",
    "            openai.api_key = self.api_key\n",
    "            \n",
    "            # 프롬프트 작성\n",
    "            prompt = f\"\"\"\n",
    "            아래 텍스트에서 산업은행/기업은행(IBK) 문서의 준법감시필 번호와 유효기간 정보를 추출해주세요.\n",
    "            \n",
    "            준법감시필 번호는 다음 형식 중 하나일 수 있습니다:\n",
    "            - 제2024-4806호\n",
    "            - 준법감시-2024-123\n",
    "            - 심의필-2024-456\n",
    "            \n",
    "            유효기간은 다음 형식 중 하나일 수 있습니다:\n",
    "            - 유효기간: 2025.08.20\n",
    "            - 만료일: 2025년 8월 20일\n",
    "            - 2025.08.20까지 유효\n",
    "            - 2025년 8월 20일까지 효력이 유지됩니다\n",
    "            \n",
    "            텍스트:\n",
    "            {chunk[:1500]}  # 너무 긴 경우 앞부분만 전송\n",
    "            \n",
    "            JSON 형식으로 응답해주세요:\n",
    "            {{\n",
    "                \"compliance_number\": \"추출된 준법감시필 번호(모르면 null)\",\n",
    "                \"expiry_date\": \"추출된 유효기간을 YYYY-MM-DD 형식으로(모르면 null)\",\n",
    "                \"confidence\": 0.9, // 신뢰도 (0.0~1.0)\n",
    "                \"context\": \"정보가 발견된 문맥(한 문장)\"\n",
    "            }}\n",
    "            \"\"\"\n",
    "            \n",
    "            # GPT API 호출\n",
    "            try:\n",
    "                # ChatCompletion API 호출\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-4\", # 또는 \"gpt-3.5-turbo\"\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"당신은 금융 문서 분석 전문가입니다. 준법감시 관련 정보를 정확히 추출합니다.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0.1  # 결정적인 응답 위해 temperature 낮게 설정\n",
    "                )\n",
    "                \n",
    "                # 응답 추출\n",
    "                ai_response = response.choices[0].message['content']\n",
    "                \n",
    "            except AttributeError:\n",
    "                # 최신 OpenAI 패키지 버전(1.0.0 이상)에서는 다른 호출 방식 사용\n",
    "                client = openai.OpenAI(api_key=self.api_key)\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4\", # 또는 \"gpt-3.5-turbo\"\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"당신은 금융 문서 분석 전문가입니다. 준법감시 관련 정보를 정확히 추출합니다.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0.1\n",
    "                )\n",
    "                \n",
    "                # 응답 추출\n",
    "                ai_response = response.choices[0].message.content\n",
    "            \n",
    "            # JSON 파싱\n",
    "            import json\n",
    "            try:\n",
    "                log_debug(f\"GPT API 응답: {ai_response}\")\n",
    "                result = json.loads(ai_response)\n",
    "                return result\n",
    "            except json.JSONDecodeError:\n",
    "                log_debug(f\"JSON 파싱 오류: {ai_response}\")\n",
    "                \n",
    "                # 간단한 응답 구문 분석 시도\n",
    "                try:\n",
    "                    # 형식이 벗어난 경우 핵심 정보만 추출 시도\n",
    "                    compliance_pattern = r'\"compliance_number\":\\s*\"([^\"]*)\"'\n",
    "                    expiry_pattern = r'\"expiry_date\":\\s*\"([^\"]*)\"'\n",
    "                    confidence_pattern = r'\"confidence\":\\s*([\\d.]+)'\n",
    "                    \n",
    "                    compliance_match = re.search(compliance_pattern, ai_response)\n",
    "                    expiry_match = re.search(expiry_pattern, ai_response)\n",
    "                    confidence_match = re.search(confidence_pattern, ai_response)\n",
    "                    \n",
    "                    return {\n",
    "                        \"compliance_number\": compliance_match.group(1) if compliance_match else None,\n",
    "                        \"expiry_date\": expiry_match.group(1) if expiry_match else None,\n",
    "                        \"confidence\": float(confidence_match.group(1)) if confidence_match else 0.5,\n",
    "                        \"context\": None\n",
    "                    }\n",
    "                except:\n",
    "                    return {\n",
    "                        \"compliance_number\": None,\n",
    "                        \"expiry_date\": None,\n",
    "                        \"confidence\": 0.0,\n",
    "                        \"context\": None\n",
    "                    }\n",
    "                    \n",
    "        except Exception as e:\n",
    "            log_debug(f\"GPT API 호출 오류: {str(e)}\")\n",
    "            return {\n",
    "                \"compliance_number\": None,\n",
    "                \"expiry_date\": None,\n",
    "                \"confidence\": 0.0,\n",
    "                \"context\": None\n",
    "            }\n",
    "    \n",
    "    def extract_ngram_features(self, text, n=3):\n",
    "        \"\"\"N-gram 특성 추출\"\"\"\n",
    "        from nltk.util import ngrams\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        \n",
    "        # 토큰화\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        \n",
    "        # n-gram 생성\n",
    "        n_grams = list(ngrams(tokens, n))\n",
    "        return ['_'.join(gram) for gram in n_grams]\n",
    "    \n",
    "    def extract_with_regex(self, text):\n",
    "        \"\"\"정규식으로 준법감시 정보 추출 - 개선된 버전\"\"\"\n",
    "        log_debug(\"정규식으로 준법감시 정보 추출 시작\")\n",
    "        result = {\"compliance_number\": None, \"expiry_date\": None}\n",
    "        \n",
    "        if not text or len(text) < 10:\n",
    "            return result\n",
    "        \n",
    "        # 디버깅을 위한 로깅 강화\n",
    "        log_debug(f\"분석할 텍스트 길이: {len(text)} 자\")\n",
    "        if len(text) > 200:\n",
    "            log_debug(f\"텍스트 일부: {text[:200]}...\")\n",
    "        else:\n",
    "            log_debug(f\"텍스트 전체: {text}\")\n",
    "        \n",
    "        # 1. 준법감시필 번호 추출 - 패턴 추가\n",
    "        compliance_patterns = [\n",
    "            r'제(\\d{4})-(\\d+)호',                         # 제2024-4806호\n",
    "            r'준법감시[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)',      # 준법감시-2024-123\n",
    "            r'심의필[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)',        # 심의필-2024-123\n",
    "            r'준법[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)',          # 준법-2024-123\n",
    "            r'(감사|감수|검수)[_\\-\\s]*(\\d{4})[_\\-\\s]*(\\d+)', # 감사-2024-123\n",
    "            r'[^\\d](\\d{4})[_\\-](\\d{3,4})호',              # 2024-1234호\n",
    "            r'[^\\d](\\d{4})[\\s\\-]*(\\d{3,4})',              # 2024 1234 (앞뒤 문맥 확인 필요)\n",
    "        ]\n",
    "        \n",
    "        for pattern in compliance_patterns:\n",
    "            matches = re.finditer(pattern, text)\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    groups = match.groups()\n",
    "                    \n",
    "                    # 패턴에 맞는 준법감시필 번호 구성\n",
    "                    if '제' in pattern:\n",
    "                        result[\"compliance_number\"] = f\"제{groups[0]}-{groups[1]}호\"\n",
    "                    elif '준법감시' in pattern:\n",
    "                        result[\"compliance_number\"] = f\"준법감시-{groups[0]}-{groups[1]}\"\n",
    "                    elif '심의필' in pattern:\n",
    "                        result[\"compliance_number\"] = f\"심의필-{groups[0]}-{groups[1]}\"\n",
    "                    elif '감사' in pattern or '감수' in pattern or '검수' in pattern:\n",
    "                        result[\"compliance_number\"] = f\"{groups[0]}-{groups[1]}-{groups[2]}\"\n",
    "                    else:\n",
    "                        # 기본 형식\n",
    "                        year, number = groups[0], groups[1]\n",
    "                        # 문맥 기반 접두어 결정 (간단한 휴리스틱)\n",
    "                        context_before = text[max(0, match.start()-20):match.start()]\n",
    "                        if '준법' in context_before or '법규' in context_before:\n",
    "                            result[\"compliance_number\"] = f\"준법-{year}-{number}\"\n",
    "                        elif '심의' in context_before:\n",
    "                            result[\"compliance_number\"] = f\"심의필-{year}-{number}\"\n",
    "                        else:\n",
    "                            result[\"compliance_number\"] = f\"문서번호-{year}-{number}\"\n",
    "                    \n",
    "                    log_debug(f\"정규식으로 준법감시필 번호 추출: {result['compliance_number']}\")\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # 2. 유효기간 추출 - 패턴 추가\n",
    "        expiry_patterns = [\n",
    "            r'유효기간[^0-9]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?',  # 유효기간: 2025.08.20\n",
    "            r'만료일[^0-9]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?',   # 만료일: 2025.08.20\n",
    "            r'(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?[^0-9]*까지',     # 2025.08.20까지\n",
    "            r'(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?[^0-9]*만료',     # 2025.08.20 만료\n",
    "            r'유효[^0-9]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?',     # 유효: 2025.08.20\n",
    "            r'효력기간[^0-9]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?',  # 효력기간: 2025.08.20\n",
    "            r'([~-]|부터)[^0-9]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?', # ~2025.08.20\n",
    "            r'기간[^\\d]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?',       # 기간: 2025.08.20\n",
    "            r'사용기한[^\\d]*(\\d{4})[-/.년\\s](\\d{1,2})[-/.월\\s](\\d{1,2})일?',   # 사용기한: 2025.08.20\n",
    "        ]\n",
    "        \n",
    "        for pattern in expiry_patterns:\n",
    "            matches = re.finditer(pattern, text)\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    groups = match.groups()\n",
    "                    # 연, 월, 일 값 가져오기 (패턴에 따라 다름)\n",
    "                    if len(groups) >= 3:\n",
    "                        year, month, day = int(groups[0]), int(groups[1]), int(groups[2])\n",
    "                    else:\n",
    "                        # 그룹이 예상과 다를 경우 계속\n",
    "                        continue\n",
    "                    \n",
    "                    # 날짜 유효성 검사\n",
    "                    if 2000 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                        date_str = f\"{year}-{month:02d}-{day:02d}\"\n",
    "                        \n",
    "                        # 오류 날짜 필터링\n",
    "                        if date_str in ERROR_DATES:\n",
    "                            log_debug(f\"오류 날짜 감지: {date_str}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # 추가 검증: 과거 또는 먼 미래 날짜 검증\n",
    "                        today = datetime.now().date()\n",
    "                        date_obj = datetime(year, month, day).date()\n",
    "                        days_diff = (date_obj - today).days\n",
    "                        \n",
    "                        # 5년 이상 과거나 5년 이상 미래는 의심\n",
    "                        if abs(days_diff) > 365 * 5:\n",
    "                            log_debug(f\"의심스러운 날짜: {date_str} (차이: {days_diff}일)\")\n",
    "                            # 너무 과거나 먼 미래 날짜는 신뢰도 떨어짐 - 낮은 점수 부여\n",
    "                            continue\n",
    "                        \n",
    "                        result[\"expiry_date\"] = date_str\n",
    "                        log_debug(f\"정규식으로 유효기간 추출: {date_str}\")\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "                        \n",
    "        return result\n",
    "    \n",
    "    def combine_results(self, regex_result, gpt_result, ngram_features):\n",
    "        \"\"\"여러 추출 결과 통합 - 가중치 기반\"\"\"\n",
    "        # 초기화\n",
    "        final_result = {\n",
    "            \"compliance_number\": None,\n",
    "            \"expiry_date\": None,\n",
    "            \"confidence\": 0.0,\n",
    "            \"context\": None,\n",
    "            \"ngram_result\": {},\n",
    "            \"gpt_result\": {}\n",
    "        }\n",
    "        \n",
    "        # 정규식 결과 처리 (가중치: 0.6)\n",
    "        if regex_result:\n",
    "            final_result[\"compliance_number\"] = regex_result.get(\"compliance_number\")\n",
    "            final_result[\"expiry_date\"] = regex_result.get(\"expiry_date\")\n",
    "            final_result[\"confidence\"] = 0.6\n",
    "            final_result[\"ngram_result\"] = regex_result\n",
    "        \n",
    "        # GPT 결과 처리 (가중치: 0.8) - GPT API가 활성화된 경우\n",
    "        if gpt_result:\n",
    "            gpt_confidence = gpt_result.get(\"confidence\", 0.0) * 0.8\n",
    "            \n",
    "            # 신뢰도가 높은 경우에만 기존 결과 대체\n",
    "            if gpt_confidence > final_result[\"confidence\"]:\n",
    "                final_result[\"compliance_number\"] = gpt_result.get(\"compliance_number\")\n",
    "                final_result[\"expiry_date\"] = gpt_result.get(\"expiry_date\")\n",
    "                final_result[\"confidence\"] = gpt_confidence\n",
    "                final_result[\"context\"] = gpt_result.get(\"context\")\n",
    "            \n",
    "            # 일치하는 경우 신뢰도 상승\n",
    "            elif (final_result[\"compliance_number\"] == gpt_result.get(\"compliance_number\") or\n",
    "                  final_result[\"expiry_date\"] == gpt_result.get(\"expiry_date\")):\n",
    "                final_result[\"confidence\"] += 0.2\n",
    "                \n",
    "            final_result[\"gpt_result\"] = gpt_result\n",
    "        \n",
    "        # N-gram 결과 활용 (신뢰도 미세 조정)\n",
    "        if ngram_features and (final_result[\"compliance_number\"] or final_result[\"expiry_date\"]):\n",
    "            final_result[\"confidence\"] = min(1.0, final_result[\"confidence\"] + 0.1)\n",
    "        \n",
    "        return final_result\n",
    "    \n",
    "    def process_document(self, content):\n",
    "        \"\"\"문서 내용에서 준법감시필 번호와 유효기간 추출\"\"\"\n",
    "        log_debug(\"문서 내용 분석 시작\")\n",
    "        \n",
    "        if not content or not isinstance(content, str):\n",
    "            return {\"compliance_number\": None, \"expiry_date\": None, \"confidence\": 0.0}\n",
    "        \n",
    "        # 1. 텍스트 청크 분할\n",
    "        chunks = self.create_semantic_chunks(content)\n",
    "        \n",
    "        # 2. 관련성 높은 청크 선별\n",
    "        relevant_chunks = self.score_chunks_by_relevance(chunks)\n",
    "        \n",
    "        # 청크가 없으면 전체 텍스트에 대해 간단 분석\n",
    "        if not relevant_chunks and content:\n",
    "            mini_chunk = content[:500]\n",
    "            regex_result = self.extract_with_regex(mini_chunk)\n",
    "            ai_result = self.call_gpt_api(mini_chunk) if self.use_ai else None\n",
    "            ngram_features = self.extract_ngram_features(mini_chunk) if self.use_ngram else None\n",
    "            return self.combine_results(regex_result, ai_result, ngram_features)\n",
    "        \n",
    "        # 청크별 결과 저장\n",
    "        chunk_results = []\n",
    "        \n",
    "        # 3. 각 청크별 분석\n",
    "        for idx, chunk in relevant_chunks:\n",
    "            regex_result = self.extract_with_regex(chunk)\n",
    "            ai_result = self.call_gpt_api(chunk) if self.use_ai else None\n",
    "            ngram_features = self.extract_ngram_features(chunk) if self.use_ngram else None\n",
    "            \n",
    "            combined = self.combine_results(regex_result, ai_result, ngram_features)\n",
    "            combined[\"chunk_index\"] = idx\n",
    "            chunk_results.append(combined)\n",
    "        \n",
    "        # 결과가 없으면 빈 결과 반환\n",
    "        if not chunk_results:\n",
    "            return {\"compliance_number\": None, \"expiry_date\": None, \"confidence\": 0.0}\n",
    "        \n",
    "        # 4. 최종 결과 선택 (신뢰도 기준)\n",
    "        chunk_results.sort(key=lambda x: x.get(\"confidence\", 0.0), reverse=True)\n",
    "        return chunk_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618572a",
   "metadata": {},
   "source": [
    "5. 파일 분석 및 결과 처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98ebabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_file(file_path):\n",
    "    \"\"\"파일 정보를 분석하여 결과 딕셔너리 반환 - 강화된 버전\"\"\"\n",
    "    try:\n",
    "        filename = file_path.name\n",
    "        file_index = target_files.index(file_path) if file_path in target_files else -1\n",
    "        \n",
    "        # 파일 순번 로깅\n",
    "        log_debug(f\"{'='*50}\")\n",
    "        log_debug(f\"파일 분석 시작 [{file_index+1}/{len(target_files)}]: {filename}\")\n",
    "        \n",
    "        # 파일명에서 정보 추출\n",
    "        filename_info = extract_info_from_filename(filename)\n",
    "        \n",
    "        # 파일 내용 확인 변수 초기화\n",
    "        content_result = {\n",
    "            \"compliance_number\": None,\n",
    "            \"expiry_date\": None,\n",
    "            \"confidence\": 0.0,\n",
    "            \"context\": None\n",
    "        }\n",
    "        \n",
    "        content = \"\"  # 파일 내용 저장 변수\n",
    "        \n",
    "        # 파일 확장자 확인\n",
    "        ext = file_path.suffix.lower()\n",
    "        \n",
    "        # 파일 크기 확인\n",
    "        try:\n",
    "            file_size = file_path.stat().st_size / (1024 * 1024)  # MB 단위\n",
    "            is_large_file = file_size > 10  # 10MB 초과\n",
    "            \n",
    "            if is_large_file:\n",
    "                log_debug(f\"대용량 파일 감지: {file_size:.2f}MB - 내용 분석 제한\")\n",
    "                content = read_file_content(file_path)[:20000]  # 처음 2만자만 분석\n",
    "            else:\n",
    "                content = read_file_content(file_path)\n",
    "                \n",
    "            # 내용이 있는 경우 분석\n",
    "            if content:\n",
    "                # AI 추출기 인스턴스 생성\n",
    "                extractor = EnhancedComplianceExtractor(\n",
    "                    api_key=None,  # 실제 API 키로 교체\n",
    "                    use_ngram=True,\n",
    "                    use_ai=False  # API 키가 없으면 AI 사용 안함\n",
    "                )\n",
    "                \n",
    "                # 문서 처리\n",
    "                content_result = extractor.process_document(content)\n",
    "        except Exception as e:\n",
    "            log_debug(f\"파일 크기 확인 또는 내용 분석 오류: {str(e)}\")\n",
    "        \n",
    "        # 결과 통합 - 파일 경로와 내용 미리보기 추가\n",
    "        combined_result = combine_file_results(\n",
    "            filename=filename,\n",
    "            content_result=content_result,\n",
    "            filename_result=filename_info,\n",
    "            file_path=file_path,\n",
    "            content_preview=content[:500] if content else None  # 최대 500자 미리보기\n",
    "        )\n",
    "        \n",
    "        return combined_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_debug(f\"파일 분석 중 오류: {str(e)}\")\n",
    "        log_debug(traceback.format_exc())\n",
    "        # 오류 발생 시 기본 정보만 반환\n",
    "        return {\n",
    "            '파일명': file_path.name,\n",
    "            '상태': '상태 불명',\n",
    "            '만료일': '알 수 없음',\n",
    "            '남은 일수': None,\n",
    "            '파일명_준법감시필': None, \n",
    "            '파일명_유효기간': None,\n",
    "            '파일명_유효기간_상태': '정보 없음',\n",
    "            '파일명_남은일수': None,\n",
    "            '파일내_준법감시필_번호': None,\n",
    "            '파일내_유효기간_날짜': None,\n",
    "            '파일내_유효기간_상태': '정보 없음',\n",
    "            '파일내_남은일수': None,\n",
    "            '파일경로': str(file_path.parent),\n",
    "            '내용_미리보기': None,\n",
    "            '파일인덱스': target_files.index(file_path) + 1 if file_path in target_files else -1\n",
    "        }\n",
    "\n",
    "def combine_file_results(filename, content_result, filename_result, file_path=None, content_preview=None):\n",
    "    \"\"\"파일명과 내용에서 추출한 결과 통합\"\"\"\n",
    "    # 기본값 설정\n",
    "    result = {\n",
    "        '파일명': filename,\n",
    "        '상태': '상태 불명',\n",
    "        '만료일': '알 수 없음',\n",
    "        '남은 일수': None,\n",
    "        \n",
    "        # 파일명 정보\n",
    "        '파일명_준법감시필': filename_result.get('compliance_number'),\n",
    "        '파일명_유효기간': filename_result.get('expiry_date'),\n",
    "        '파일명_유효기간_상태': filename_result.get('status', '정보 없음'),\n",
    "        '파일명_남은일수': filename_result.get('days_to_expiry'),\n",
    "        \n",
    "        # 파일 내용 정보\n",
    "        '파일내_준법감시필_번호': content_result.get('compliance_number'),\n",
    "        '파일내_유효기간_날짜': content_result.get('expiry_date'),\n",
    "        '파일내_유효기간_상태': '정보 없음',\n",
    "        '파일내_남은일수': None,\n",
    "        \n",
    "        '신뢰도': content_result.get('confidence', 0.0),\n",
    "        '파일경로': str(file_path) if file_path else None,\n",
    "        '내용_미리보기': content_preview[:200] + '...' if content_preview and len(content_preview) > 200 else content_preview\n",
    "    }\n",
    "    \n",
    "    # 파일 내용에서 유효기간 상태 계산\n",
    "    content_expiry = content_result.get('expiry_date')\n",
    "    if content_expiry:\n",
    "        try:\n",
    "            today = datetime.now().date()\n",
    "            content_date_obj = datetime.strptime(content_expiry, '%Y-%m-%d').date()\n",
    "            content_days_left = (content_date_obj - today).days\n",
    "            \n",
    "            result['파일내_남은일수'] = content_days_left\n",
    "            \n",
    "            if content_days_left < 0:\n",
    "                result['파일내_유효기간_상태'] = '만료됨'\n",
    "            elif content_days_left <= 30:\n",
    "                result['파일내_유효기간_상태'] = '30일 이내 만료'\n",
    "            else:\n",
    "                result['파일내_유효기간_상태'] = '유효함'\n",
    "        except Exception as e:\n",
    "            log_debug(f\"내용 유효기간 상태 계산 오류: {e}\")\n",
    "    \n",
    "    # 최종 만료일 및 상태 결정 (파일명 우선, 내용 차선)\n",
    "    if filename_result.get('expiry_date'):\n",
    "        result['만료일'] = filename_result.get('expiry_date')\n",
    "        result['상태'] = filename_result.get('status')\n",
    "        result['남은 일수'] = filename_result.get('days_to_expiry')\n",
    "    elif content_expiry:\n",
    "        result['만료일'] = content_expiry\n",
    "        result['상태'] = result['파일내_유효기간_상태']\n",
    "        result['남은 일수'] = result['파일내_남은일수']\n",
    "    \n",
    "    return result\n",
    "\n",
    "def save_interim_results(results, batch_idx):\n",
    "    \"\"\"중간 결과 저장 함수\"\"\"\n",
    "    try:\n",
    "        interim_df = pd.DataFrame(results)\n",
    "        interim_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        interim_file = f\"interim_results_{batch_idx}_{interim_timestamp}.csv\"\n",
    "        interim_df.to_csv(interim_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"중간 결과 저장됨: {interim_file}\")\n",
    "        return interim_file\n",
    "    except Exception as e:\n",
    "        print(f\"중간 결과 저장 중 오류: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_formatted_excel(df, excel_file):\n",
    "    \"\"\"결과를 서식이 적용된 Excel로 저장 - 최적화 버전\"\"\"\n",
    "    try:\n",
    "        # 대용량 데이터 처리를 위한 최적화 설정\n",
    "        options = {'strings_to_urls': False, 'strings_to_formulas': False}\n",
    "        \n",
    "        with pd.ExcelWriter(excel_file, engine='openpyxl', options=options) as writer:\n",
    "            # 기본 저장 (서식 없이)\n",
    "            df.to_excel(writer, index=False, sheet_name='준법감시')\n",
    "            \n",
    "            # 워크북과 워크시트 가져오기\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets['준법감시']\n",
    "            \n",
    "            # 간소화된 서식 (속도 개선)\n",
    "            # 헤더 행만 서식 적용\n",
    "            header_font = Font(bold=True)\n",
    "            header_fill = PatternFill(start_color='E6E6E6', end_color='E6E6E6', fill_type='solid')\n",
    "            \n",
    "            for cell in worksheet[1]:\n",
    "                cell.font = header_font\n",
    "                cell.fill = header_fill\n",
    "            \n",
    "            # 열 너비는 최소한으로만 설정\n",
    "            for i, column in enumerate(df.columns):\n",
    "                col_letter = get_column_letter(i + 1)\n",
    "                worksheet.column_dimensions[col_letter].width = max(len(str(column)), 15)\n",
    "            \n",
    "        print(f\"Excel 파일이 저장되었습니다: {excel_file}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Excel 저장 오류: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e3a4fb",
   "metadata": {},
   "source": [
    "6. 메인 실행 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe80ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_enhanced_compliance_analysis(directory_path):\n",
    "    \"\"\"IBK 준법감시 문서 향상된 분석 - 메인 실행 함수\"\"\"\n",
    "    global target_files\n",
    "    \n",
    "    # 초기 설정\n",
    "    start_time = time.time()\n",
    "    print(f\"현재 디렉토리: {os.getcwd()}\")\n",
    "    \n",
    "    # 1. 파일 수집\n",
    "    target_files = collect_target_files(directory_path)\n",
    "    print(f\"파일 분석 시작...\")\n",
    "    \n",
    "    max_files = 1000  # 처리할 최대 파일 수\n",
    "    if len(target_files) > max_files:\n",
    "        target_files = target_files[:max_files]\n",
    "        print(f\"처리할 파일 수를 {max_files}개로 제한합니다.\")\n",
    "\n",
    "    # 2. 배치 처리 설정\n",
    "    batch_size = 200  # 한 번에 처리할 파일 수\n",
    "    total_batches = (len(target_files) + batch_size - 1) // batch_size\n",
    "    print(f\"총 {total_batches}개 배치로 나누어 처리합니다.\")\n",
    "    \n",
    "    # 3. 배치별 처리 및 중간 결과 저장\n",
    "    all_results = []\n",
    "    for batch_idx in range(total_batches):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = min((batch_idx + 1) * batch_size, len(target_files))\n",
    "        batch_files = target_files[batch_start:batch_end]\n",
    "        \n",
    "        print(f\"\\n배치 {batch_idx + 1}/{total_batches} 처리 중 ({batch_end - batch_start}개 파일)...\")\n",
    "        \n",
    "        # 병렬 처리\n",
    "        batch_results = []\n",
    "        max_workers = min(os.cpu_count() or 2, 4)  # 최대 8개 워커\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # 각 파일별로 분석 작업 예약\n",
    "            future_to_file = {executor.submit(analyze_file, file_path): file_path for file_path in batch_files}\n",
    "            \n",
    "            # 완료된 작업 처리\n",
    "            for future in tqdm(concurrent.futures.as_completed(future_to_file), total=len(batch_files), desc=f\"배치 {batch_idx + 1} 분석 중\"):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result:\n",
    "                        batch_results.append(result)\n",
    "                except Exception as e:\n",
    "                    file_path = future_to_file[future]\n",
    "                    print(f\"\\n파일 {file_path.name} 처리 중 오류: {e}\")\n",
    "        \n",
    "        # 현재 배치 결과 저장\n",
    "        all_results.extend(batch_results)\n",
    "        print(f\"배치 {batch_idx + 1} 완료: {len(batch_results)}개 파일 처리됨\")\n",
    "        \n",
    "        # 메모리 정리\n",
    "        gc.collect()\n",
    "        \n",
    "        # 중간 결과 저장\n",
    "        if batch_idx % 2 == 1 or batch_idx == total_batches - 1:  # 2개 배치마다 또는 마지막 배치\n",
    "            save_interim_results(all_results, batch_idx)\n",
    "    \n",
    "    # 4. 최종 결과 데이터프레임 생성\n",
    "    print(f\"총 {len(all_results)}개 파일 분석 완료\")\n",
    "    \n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # 유효기간 날짜 검증 및 오류 수정\n",
    "        def validate_date(date_str):\n",
    "            \"\"\"유효기간 날짜 검증 함수\"\"\"\n",
    "            if not isinstance(date_str, str) or date_str == '알 수 없음':\n",
    "                return date_str\n",
    "                \n",
    "            # 오류 날짜 명시적으로 제거\n",
    "            if date_str in ERROR_DATES:\n",
    "                return None\n",
    "                \n",
    "            try:\n",
    "                # 날짜 형식 검증\n",
    "                date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "                \n",
    "                # 추가 유효성 검증 (너무 과거나 먼 미래의 날짜는 의심)\n",
    "                today = datetime.now()\n",
    "                five_years_ago = today.replace(year=today.year - 5)\n",
    "                five_years_future = today.replace(year=today.year + 5)\n",
    "                \n",
    "                if date_obj < five_years_ago or date_obj > five_years_future:\n",
    "                    # 너무 이상한 날짜는 로그로 기록\n",
    "                    print(f\"의심스러운 날짜 검출: {date_str} (허용 범위: {five_years_ago.strftime('%Y-%m-%d')} ~ {five_years_future.strftime('%Y-%m-%d')})\")\n",
    "                \n",
    "                return date_str\n",
    "            except:\n",
    "                return None\n",
    "        \n",
    "        # 모든 날짜 컬럼에 대한 검증 적용\n",
    "        for col in ['만료일', '파일명_유효기간', '파일내_유효기간_날짜']:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(validate_date)\n",
    "        \n",
    "        # 유효기간 날짜가 None인 경우 상태도 '상태 불명'으로 변경\n",
    "        df.loc[df['만료일'].isna() | (df['만료일'] == '알 수 없음'), '상태'] = '상태 불명'\n",
    "        \n",
    "        # 결과 열 정리 - 필요한 컬럼만 선택\n",
    "        column_order = [\n",
    "            '파일명', '상태', '만료일', '남은 일수', \n",
    "            '파일명_준법감시필', '파일명_유효기간', '파일명_유효기간_상태', '파일명_남은일수',\n",
    "            '파일내_준법감시필_번호', '파일내_유효기간_날짜', '파일내_유효기간_상태', '파일내_남은일수',\n",
    "            '파일경로', '내용_미리보기'\n",
    "        ]\n",
    "        \n",
    "        # 존재하는 열만 선택\n",
    "        existing_columns = [col for col in column_order if col in df.columns]\n",
    "        df = df[existing_columns]\n",
    "        \n",
    "        # 결과 정렬 (상태별)\n",
    "        status_order = {'만료됨': 0, '30일 이내 만료': 1, '유효함': 2, '상태 불명': 3}\n",
    "        df['status_order'] = df['상태'].map(lambda x: status_order.get(x, 4))\n",
    "        df = df.sort_values(by=['status_order', '남은 일수'])\n",
    "        df = df.drop(columns=['status_order'])\n",
    "        \n",
    "        # 5. 결과 저장\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        csv_file = f\"ibk_준법감시_유효기간_{timestamp}.csv\"\n",
    "        excel_file = f\"ibk_준법감시_유효기간_{timestamp}.xlsx\"\n",
    "        \n",
    "        df.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"결과 파일이 현재 디렉토리에 저장되었습니다: {csv_file}\")\n",
    "        \n",
    "        save_formatted_excel(df, excel_file)\n",
    "        \n",
    "        # 6. 결과 통계\n",
    "        status_counts = df['상태'].value_counts().to_dict()\n",
    "        print(\"\\n=== 분석 결과 통계 ===\")\n",
    "        print(f\"- 만료됨: {status_counts.get('만료됨', 0)}개\")\n",
    "        print(f\"- 30일 이내 만료: {status_counts.get('30일 이내 만료', 0)}개\")\n",
    "        print(f\"- 유효함: {status_counts.get('유효함', 0)}개\")\n",
    "        print(f\"- 상태 불명: {status_counts.get('상태 불명', 0)}개\")\n",
    "        print(f\"- 총 파일 수: {len(df)}개\")\n",
    "        \n",
    "        # 정보 출처 통계\n",
    "        source_stats = {\n",
    "            '파일명에서만 발견': len(df[(df['파일명_유효기간'].notna()) & (df['파일내_유효기간_날짜'].isna())]),\n",
    "            '파일 내용에서만 발견': len(df[(df['파일명_유효기간'].isna()) & (df['파일내_유효기간_날짜'].notna())]),\n",
    "            '파일명과 내용 모두에서 발견': len(df[(df['파일명_유효기간'].notna()) & (df['파일내_유효기간_날짜'].notna())]),\n",
    "            '어디에서도 발견되지 않음': len(df[(df['파일명_유효기간'].isna()) & (df['파일내_유효기간_날짜'].isna())])\n",
    "        }\n",
    "        \n",
    "        print(\"\\n=== 정보 출처 통계 ===\")\n",
    "        for source, count in source_stats.items():\n",
    "            print(f\"- {source}: {count}개 ({count/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        # 총 소요 시간\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\n총 실행 시간: {total_time:.2f}초 (파일당 평균: {total_time/len(target_files):.2f}초)\")\n",
    "        \n",
    "        # 결과 미리보기\n",
    "        print(\"\\n=== 결과 데이터프레임 미리보기 ===\")\n",
    "        display(df.head())\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print(\"분석할 파일이 없거나 모든 파일 처리 중 오류가 발생했습니다.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bcf275",
   "metadata": {},
   "source": [
    "7. 실행 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae53bc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 디렉토리: c:\\Users\\markcloud\\Desktop\\오준호\\IBK\n",
      "분석할 파일 찾는 중...\n",
      "총 7개 디렉토리 검색 예정\n",
      "총 659개 파일을 찾았습니다.\n",
      "파일 분석 시작...\n",
      "총 4개 배치로 나누어 처리합니다.\n",
      "\n",
      "배치 1/4 처리 중 (200개 파일)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e9cbbf8a8647cab3cce8b687274685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "배치 1 분석 중:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 1 완료: 200개 파일 처리됨\n",
      "\n",
      "배치 2/4 처리 중 (200개 파일)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493edec0380141ccb7bc7f39b79fea0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "배치 2 분석 중:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 2 완료: 200개 파일 처리됨\n",
      "중간 결과 저장됨: interim_results_1_20250516_150145.csv\n",
      "\n",
      "배치 3/4 처리 중 (200개 파일)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643c3731d9e54fe0b5c68719b52bd10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "배치 3 분석 중:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 3 완료: 200개 파일 처리됨\n",
      "\n",
      "배치 4/4 처리 중 (59개 파일)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843108415c344f50b382f29001603c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "배치 4 분석 중:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n"
     ]
    }
   ],
   "source": [
    "# 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 분석 실행\n",
    "        result_df = run_enhanced_compliance_analysis(BASE_PATH)\n",
    "    except Exception as e:\n",
    "        print(f\"실행 중 오류 발생: {e}\")\n",
    "        print(traceback.format_exc())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
